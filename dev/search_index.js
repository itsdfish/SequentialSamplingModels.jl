var documenterSearchIndex = {"docs":
[{"location":"plot_model/#Basic-Example","page":"Plot Model Process","title":"Basic Example","text":"","category":"section"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"The function plot_model illustrates the evidence accumulation process of a given model. The code block below illustrates the decision dynamics of the racing diffusion model (RDM). ","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(77)\n\ndist = RDM()\ndensity_kwargs=(;t_range=range(.20, 1.0, length=100),)\nplot_model(dist; n_sim=1, density_kwargs, xlims=(0,1.0))","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"On each trial, the starting point z of the evidence accummulation process follows a uniform distribution: ","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"z sim mathrmUniform(0A)","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"The starting point distribution is represented as the height of the rectangle located at the origin of the plot above. Non-decision time tau, a constant representing the sum of percetual and motor processes, is represented as the width of the rectangle. The dashed horizontal line represents the decision threshold, alpha, which is defined as ","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"alpha = A + k","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"where k is the distance between the maximum starting point A and the threshold. The black lines extending from the starting point rectangle represent the noisy accumulation of evidence for each option. The accumulator whose evidence reaches the theshold first determines which option is selected.   ","category":"page"},{"location":"plot_model/#Add-Density-Plot","page":"Plot Model Process","title":"Add Density Plot","text":"","category":"section"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"In some cases, it is desirable to include the implied probability density of reaction times. The probability density can be included by setting the keyword add_density=true. By default, the probability density is rescaled to have a maximum value equal to the threshold alpha = A + k. Setting the keyword density_scale=nothing via density_kwargs will prevent rescaling. You may also pass your own desired maximum density value. ","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(77)\n\ndist = RDM()\ndensity_kwargs=(;t_range=range(.20, 1.0, length=100),)\nplot_model(dist; n_sim=1, add_density=true, density_kwargs, xlims=(0,1.0))","category":"page"},{"location":"plot_model/#Animate","page":"Plot Model Process","title":"Animate","text":"","category":"section"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"You can animate the evidence accumulation process with the plotting function animate, which works similarly to plot_model.  ","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(77)\n\ndist = RDM()\nanimate(dist)","category":"page"},{"location":"plot_model/","page":"Plot Model Process","title":"Plot Model Process","text":"(Image: )","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"using LinearAlgebra\nusing Plots\nusing SequentialSamplingModels\nusing Plots \nusing Random\nusing Revise\n\nmodel = CDDM(;\n    ν=[5,5.0],\n    η = [.50,.50],\n    σ = 1.0,\n    α = 4.0,\n    τ = .30\n)\n\nRandom.seed!(5874)\n\nplot_model(model)\nsavefig(\"cddm_plot.png\")","category":"page"},{"location":"cddm/#Circular-Drift-Diffusion-Model","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The Circular Drift Diffusion Model (CDDM; Smith, 2016) is a sequential sampling model for continuous responding on a circular domain. The CDDM is often used to model visual working memory. In these visual working memory tasks, subjects are briefly presented with a variable number of squares of different colors. After the stimuli are removed, subjects are prompted to use a color wheel to judge the color of a randomly selected square. Currently, the model is restricted to a 2D disk, but future versions may support modeling diffusion processes in hyperspheres. ","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The figure below illustrates the evidence accumulation process of the CDDM. At the begining of the trial, the evidence accumulation process starts at the center of the circle. As time progresses, the state of the system moves towards the the decision threshold depicted by the circle. Each step is perturbed with some degree of randomness. Once the system reaches the decision threshold, a response based on the position on the circle is given.   (Image: )","category":"page"},{"location":"cddm/#Example","page":"Circular Drift Diffusion Model (CDDM)","title":"Example","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"In this example, we will demonstrate how to use the CDDM in a generic two alternative forced choice task. ","category":"page"},{"location":"cddm/#Load-Packages","page":"Circular Drift Diffusion Model (CDDM)","title":"Load Packages","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The first step is to load the required packages.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"using LinearAlgebra\nusing SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(5874)","category":"page"},{"location":"cddm/#Create-Model-Object","page":"Circular Drift Diffusion Model (CDDM)","title":"Create Model Object","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"In the code below, we will define parameters for the CDDM and create a model object to store the parameter values. ","category":"page"},{"location":"cddm/#Drift-Rates","page":"Circular Drift Diffusion Model (CDDM)","title":"Drift Rates","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The mean drift rates boldsymbolnu control the speed with which information accumulates in the x and y direction.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"ν = [5.5,5.0]","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The magnitude of the mean drift rate vector boldsymbolnu is interpreted as the mean accumulation rate.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"norm(ν)","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The average direction of the accumulation process is given by mathrmarctan(fracnu_2nu_1):","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"atan(ν[2], ν[1])","category":"page"},{"location":"cddm/#Drift-Rate-Standard-Deviation","page":"Circular Drift Diffusion Model (CDDM)","title":"Drift Rate Standard Deviation","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The standard deviation of the drift rate boldsymboleta is inteprpreted as variability in the evidence accumulation across trials. ","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"η = [.50,.50]","category":"page"},{"location":"cddm/#Threshold","page":"Circular Drift Diffusion Model (CDDM)","title":"Threshold","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Evidence starts at the center of a circle (00) and terminates at a threshold defined by the circumference of the circle. The distance between the starting point and any point on the circumference is given by the radius alpha:","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"α = 4.0","category":"page"},{"location":"cddm/#Diffusion","page":"Circular Drift Diffusion Model (CDDM)","title":"Diffusion","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Intra-trial variability in the accumulation process is governed by parameter sigma","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"σ = 1.0","category":"page"},{"location":"cddm/#Non-Decision-Time","page":"Circular Drift Diffusion Model (CDDM)","title":"Non-Decision Time","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"τ = 0.30","category":"page"},{"location":"cddm/#CDDM-Constructor","page":"Circular Drift Diffusion Model (CDDM)","title":"CDDM Constructor","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Now that values have been asigned to the parameters, we will pass them to CDDM to generate the model object.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"dist = CDDM(; ν, η, σ, α, τ)","category":"page"},{"location":"cddm/#Simulate-Model","page":"Circular Drift Diffusion Model (CDDM)","title":"Simulate Model","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand.  The simulated data is a 2D array in which the first column contains the observed angular responses and the second column contains the corresponding reaction times.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":" data = rand(dist, 10_000)","category":"page"},{"location":"cddm/#Compute-PDF","page":"Circular Drift Diffusion Model (CDDM)","title":"Compute PDF","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"pdf(dist, data)","category":"page"},{"location":"cddm/#Compute-Log-PDF","page":"Circular Drift Diffusion Model (CDDM)","title":"Compute Log PDF","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"logpdf(dist, data)","category":"page"},{"location":"cddm/#Plot-Simulation","page":"Circular Drift Diffusion Model (CDDM)","title":"Plot Simulation","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"The code below overlays the PDF on the marginal histograms for angle and reaction time.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"histogram(dist)\nplot!(dist)","category":"page"},{"location":"cddm/#References","page":"Circular Drift Diffusion Model (CDDM)","title":"References","text":"","category":"section"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Smith, P. L. (2016). Diffusion theory of decision making in continuous report. Psychological Review, 123(4), 425.","category":"page"},{"location":"cddm/","page":"Circular Drift Diffusion Model (CDDM)","title":"Circular Drift Diffusion Model (CDDM)","text":"Smith, P. L., Garrett, P. M., & Zhou, J. (2023). Obtaining Stable Predicted Distributions of Response Times and Decision Outcomes for the Circular Diffusion Model.  Computational Brain & Behavior, 1-13.","category":"page"},{"location":"shifted_lognormal/#Shifted-Lognormal-Model","page":"Shifted Log Normal","title":"Shifted Lognormal Model","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"The shifted lognormal model a sequential sampling model for single choice decisions in which the first passage time follows a lognormal distribution. The decision time distribution is shifted by a constant representing encoding and response execution processing time. Note that the shifted lognormal model is a special case of the log normal race model with a single accumulator. ","category":"page"},{"location":"shifted_lognormal/#Example","page":"Shifted Log Normal","title":"Example","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"In this example, we will demonstrate how to use the shifted lognormal model in a generic single choice decision task. ","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"shifted_lognormal/#Load-Packages","page":"Shifted Log Normal","title":"Load Packages","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"The first step is to load the required packages.","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"shifted_lognormal/#Create-Model-Object","page":"Shifted Log Normal","title":"Create Model Object","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"shifted_lognormal/#\\nu","page":"Shifted Log Normal","title":"nu","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"We will set the parameter nu = -1.","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"ν = -1","category":"page"},{"location":"shifted_lognormal/#\\sigma","page":"Shifted Log Normal","title":"sigma","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"We will set the parameter sigma = 50 ","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"σ = .50","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"The lognormal has the following relationship to the normal distribution:","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"X sim mathrmlognormal(nu sigma) iff log(X) sim mathrmnormal(nu sigma)","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":". ","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"This means that Elog(X) = nu and mathrmVarlog(X) = sigma^2. Note that nu and sigma affect both the mean and variance of the lognormal distribution. See ACT-R for a possible theoretical intepretation of parameters nu and sigma.","category":"page"},{"location":"shifted_lognormal/#Non-Decision-Time","page":"Shifted Log Normal","title":"Non-Decision Time","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"Non-decision time is an additive constant representing encoding and motor response time.","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"τ = 0.30","category":"page"},{"location":"shifted_lognormal/#Shifted-Lognormal-Constructor","page":"Shifted Log Normal","title":"Shifted Lognormal Constructor","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"Now that values have been asigned to the parameters, we will pass them to shifted lognormal to generate the model object.","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"dist = ShiftedLogNormal(ν, σ, τ)","category":"page"},{"location":"shifted_lognormal/#Simulate-Model","page":"Shifted Log Normal","title":"Simulate Model","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"rts = rand(dist, 1000)","category":"page"},{"location":"shifted_lognormal/#Compute-PDF","page":"Shifted Log Normal","title":"Compute  PDF","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"pdf.(dist, rts)","category":"page"},{"location":"shifted_lognormal/#Compute-Log-PDF","page":"Shifted Log Normal","title":"Compute Log PDF","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"logpdf.(dist, rts)","category":"page"},{"location":"shifted_lognormal/#Compute-CDF","page":"Shifted Log Normal","title":"Compute CDF","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"The cumulative probability density Pr(T leq t) is computed by passing the model and a value t to cdf.","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"cdf(dist, .75)","category":"page"},{"location":"shifted_lognormal/#Plot-Simulation","page":"Shifted Log Normal","title":"Plot Simulation","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"The code below overlays the PDF on reaction time histogram.","category":"page"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"histogram(dist)\nplot!(dist; t_range=range(.130, 1.5, length=100))","category":"page"},{"location":"shifted_lognormal/#References","page":"Shifted Log Normal","title":"References","text":"","category":"section"},{"location":"shifted_lognormal/","page":"Shifted Log Normal","title":"Shifted Log Normal","text":"Heathcote, A., & Bohlscheid, E. Analysis and Modeling of Response Time using the Shifted Lognormal Distribution.","category":"page"},{"location":"turing_advanced/#Estimate-Effect-on-Drift-Rate","page":"Advanced Model Specification","title":"Estimate Effect on Drift Rate","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"This advanced example illustrates how to estimate the effect of an experimental condition on the drift rate parameter. The drift rate could be manipulated in various ways. For example, the drift rate could be manipulated by varying the similarity of visual stimuli, or emphasizing speed or accuracy in task instructions.","category":"page"},{"location":"turing_advanced/#Generate-Data","page":"Advanced Model Specification","title":"Generate Data","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"In this example, we will get closer to real use-cases by starting with the data stored in a DataFrame. This dataframe will be a combination of data generated from two different distributions with different parameters, corresponding to two experimental conditions (e.g., Speed vs. Accuracy).","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"using Turing\nusing SequentialSamplingModels\nusing Random\nusing LinearAlgebra\nusing Distributions\nusing DataFrames\nusing StatsPlots\nusing StatsModels\nusing KernelDensity\n\n# Generate data with different drifts for two conditions A vs. B\nRandom.seed!(6)\n\nn_obs = 50\ndf1 = DataFrame(rand(LBA(ν=[1.5, 0.5], A=0.5, k=0.2, τ=0.3), n_obs))\ndf2 = DataFrame(rand(LBA(ν=[2.5, 1.5], A=0.5, k=0.2, τ=0.3), n_obs))\ndf = vcat(df1, df2)\ndf.condition = repeat([\"A\", \"B\"], inner=n_obs)","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"These 2 conditions A and B differ on their drift rates ([1.5, 0.5] vs. [2.5, 1.5]). In other words, the effect of condition B over condition A (the baseline condition, i.e., the intercept) is [1, 1] (because both drift rates increase by 1 between condition A and B).","category":"page"},{"location":"turing_advanced/#Exclude-Outliers","page":"Advanced Model Specification","title":"Exclude Outliers","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Next, we are going to remove outliers, i.e., implausible RTs (RTs that likely do not reflect the processes of interest). In our case, we consider that RTs shorter than 0.2 seconds are too short for the cognitive process of interest to unfold, and that RTs longer than 3 seconds are too long to carry meaningful information.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"# Remove outliers\ndf = df[(df.rt .> 0.2).&(df.rt .< 3), :]\nfirst(df)","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Note that standard outlier detection methods, such as z-scores (mean +- SD), are not necessarily appropriate for RTs, given the skewed nature of their distribution. Their asymmetric distribution is in fact accounted for by the models that we use. The outlier exclusion done here is more theory-driven (i.e., excluding extreme trials that likely do not reflect well the cognitive processes of interest) than data-driven (to better fit the model). That said, outlier exclusion should always be explicitly documented and justified.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"note: Note\nFor users coming from other languages, note the usage of the vectorization dot . in front of the < and > symbols. This means that we want to apply the logical test for all individual elements of the rt vector.","category":"page"},{"location":"turing_advanced/#Visualize-Data","page":"Advanced Model Specification","title":"Visualize Data","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"We can visualize the RT distribution for each response choice by looping through the conditions.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"# Make histogram\nhistogram(layout=(2, 1), xlabel=\"Reaction Time\", ylims=(0, 60), xlims=(0, 2), legend=false)\nfor (i, cond) in enumerate([\"A\", \"B\"])\n    histogram!(df.rt[(df.choice.==1).&(df.condition.==cond)], subplot=1, color=[:blue, :red][i], alpha=0.5, bins=range(0, 3, length=25))\n    histogram!(df.rt[(df.choice.==2).&(df.condition.==cond)], subplot=2, color=[:blue, :red][i], alpha=0.5, bins=range(0, 2, length=25))\nend\nplot!()","category":"page"},{"location":"turing_advanced/#Format-Predictors","page":"Advanced Model Specification","title":"Format Predictors","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"One additional step that we need to do here is to transform the dataframe into an input suited for modelling with Turing. For that, we will leverage the features of StatsModels to build an input matrix based on a formula.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"# Format input data\nf = @formula(rt ~ 1 + condition)\nf = apply_schema(f, schema(f, df))\n\n_, predictors = coefnames(f)\nX = modelmatrix(f, df)","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"In this case, the model matrix is pretty simple: the key part is the second column that is simply a binary vector indicating whenever condition == \"B\". However, using formulas is a good way of dealing with more complex model specifications.","category":"page"},{"location":"turing_advanced/#Specify-Turing-Model","page":"Advanced Model Specification","title":"Specify Turing Model","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"In this model, the priors for the parameters that we want to vary between conditions are split, with one prior for their intercept (condition A) and another for the effect of condition B (relative to the intercept).","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Because the drift parameters is a vector of length 2, the priors for both the intercept and condition effect drifts have themselves to be a vector of 2 distributions, which is done via filldist(prior_distribution, 2).","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Next, we need to specify these parameters as the result of a (linear) equation. Note that:","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"We have added a keyword argument, condition, to let the user pass the condition data vector.\nSince we're computing parameters as the results of an equation, we need to use a for loop that loops through all the observations.\nBecause the priors for the drift is a filldist (i.e., a vector of distributions), we need to broadcast the addition (.+ instead of +).","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"@model function model_lba(data; min_rt=0.2, condition=nothing)\n    # Priors for auxiliary parameters\n    A ~ truncated(Normal(0.8, 0.4), 0.0, Inf)\n    k ~ truncated(Normal(0.2, 0.2), 0.0, Inf)\n    tau ~ Uniform(0.0, min_rt)\n\n    # Priors for coefficients\n    drift_intercept ~ filldist(Normal(0, 1), 2)\n    drift_condition ~ filldist(Normal(0, 1), 2)\n\n    for i in 1:length(data)\n        drifts = drift_intercept .+ drift_condition * condition[i]\n        data[i] ~ LBA(; τ=tau, A=A, k=k, ν=drifts)\n    end\nend","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Importantly, although we have the data as a dataframe, we will need to convert to a tuple, as it is the shape that the LBA() distribution expects. However, since we're iterating on each observation, we need to come up with an indexable version of the data: a vector of tuples.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"# Format the data to match the input type\ndata = [(choice=df.choice[i], rt=df.rt[i]) for i in 1:nrow(df)]","category":"page"},{"location":"turing_advanced/#Prior-Predictive-Check","page":"Advanced Model Specification","title":"Prior Predictive Check","text":"","category":"section"},{"location":"turing_advanced/#Sample-from-Priors","page":"Advanced Model Specification","title":"Sample from Priors","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Before we fit the model, we want to inspect our priors to make sure that they are okay. To do that, we sample the model parameters from priors only. Note that condition is supplied as the 2nd column of the model matrix.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"chain = sample(model_lba(data; min_rt=minimum(df.rt), condition=X[:, 2]), Prior(), 1000)\nplot(chain; size=(800, 1200))","category":"page"},{"location":"turing_advanced/#Plot-Prior-Predictive-Check","page":"Advanced Model Specification","title":"Plot Prior Predictive Check","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"The next step is to generate predictions from this model (i.e., from the priors). For this, we need to pass a dataset with empty (missing) values. Since the data used above was a vector (of tuples) of length 1000, we will create a vector of (missing) of the same length.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"We can then use the predict() method to generate predictions from this model. However, because the most of SequentialSamplingModels distributions return a tuple (choice and RT), the predicted output has the two types of variables mixed together. We can delineate the two by taking every 2nd values to get the predicted choice and RTs, respectively.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"datamissing = [(missing) for i in 1:nrow(df)]\n\npred = predict(model_lba(datamissing; min_rt=minimum(df.rt), condition=X[:, 2]), chain)\n\npriorpred_choice = Array(pred)[:, 1:2:end]\npriorpred_rt = Array(pred)[:, 2:2:end]","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"These objects have arrays of size 10,000 x 1000 : with 10,000 draws for each of the 1000 observations.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"We can plot the predicted distributions by looping through a number of draws (e.g., 100), and then plotting the density for each condition and each choice.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"plot(layout=(2, 1), xlabel=\"Reaction Time\", xlims = (0, 3), ylim=(0, 5), legend = false)\nfor i in 1:100\n    choice = priorpred_choice[i, :]\n    rt = priorpred_rt[i, :]\n    for (j, cond) in enumerate([0, 1])\n        U1 = kde(rt[(choice .== 1) .& (X[:, 2] .== cond)], boundary=(0, 5))\n        plot!(U1.x, U1.density, subplot=1, color = [:red, :blue][j], alpha=0.1)\n        U2 = kde(rt[(choice .== 2) .& (X[:, 2] .== cond)], boundary=(0, 5))\n        plot!(U2.x, U2.density, subplot=2, color = [:red, :blue][j], alpha=0.1)\n    end\nend\nplot!()","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"We can see that the bulk of the predicted RTs fall within 0 - 1.5 seconds, which is realistic, but that the same time it's all over the place, which means that the priors are not too informative.","category":"page"},{"location":"turing_advanced/#Parameters-Estimation","page":"Advanced Model Specification","title":"Parameters Estimation","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"chain = sample(model_lba(data; min_rt=minimum(df.rt), condition=X[:, 2]), NUTS(), 1000)\n\nsummarystats(chain)","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"plot(chain; size = (800,1200))","category":"page"},{"location":"turing_advanced/#Posterior-Predictive-Check","page":"Advanced Model Specification","title":"Posterior Predictive Check","text":"","category":"section"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Next, we will run a posterior predictive check by first sampling from the posteriors. For that, we will re-use the code for the prior predictive check, including the datamissing empty data.","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"# Sample from posteriors\npred = predict(model_lba(datamissing; min_rt=minimum(df.rt), condition=X[:, 2]), chain)\npred_choice = Array(pred)[:, 1:2:end]\npred_rt = Array(pred)[:, 2:2:end]","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"Next, we will plot the predicted distributions on top of the observed distribution of data (the thick black lines).","category":"page"},{"location":"turing_advanced/","page":"Advanced Model Specification","title":"Advanced Model Specification","text":"# Observed density\nplot(layout=(2, 1), xlabel=\"Reaction Time\", xlims=(0, 2.5), legend=false)\nfor cond in [\"A\", \"B\"]\n    d_A = kde(df.rt[(df.choice.==1).&(df.condition.==cond)], boundary=(0, 5))\n    plot!(d_A.x, d_A.density, subplot=1, color=:black, linewidth=3)\n    d_B = kde(df.rt[(df.choice.==2).&(df.condition.==cond)], boundary=(0, 5))\n    plot!(d_B.x, d_B.density, subplot=2, color=:black, linewidth=3)\nend\n\n# Predicted densities\nfor i in 1:100\n    choice = pred_choice[i, :]\n    rt = pred_rt[i, :]\n    for (j, cond) in enumerate([0, 1])\n        U1 = kde(rt[(choice.==1).&(X[:, 2].==cond)], boundary=(0, 5))\n        plot!(U1.x, U1.density, subplot=1, color=[:red, :blue][j], alpha=0.05)\n        U2 = kde(rt[(choice.==2).&(X[:, 2].==cond)], boundary=(0, 5))\n        plot!(U2.x, U2.density, subplot=2, color=[:red, :blue][j], alpha=0.05)\n    end\nend\nplot!()","category":"page"},{"location":"bayes_factor/#Computing-the-Bayes-Factor","page":"Bayes Factors","title":"Computing the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/#Overview","page":"Bayes Factors","title":"Overview","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"In this tutorial, we will use the Bayes factor to compare the evidence for one model relative to another reference model. Computing the Bayes factor is challenging because it requires integrating the log likelihood over the model parameters. One method for approximating this complex integral is non-reversible parallel tempering (Bouchard-Côté et al., 2022) using  Pigeons.jl. ","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"In the tutorial below, we will compare two models which differ only in terms of assumptions about drift rate variability: the LBA and the RDM. The LBA assumes that the drift rate varies across trials and is otherwise deterministic, whereas the RDM assumes the drift rate varies within a trial as Gaussian noise, but not across trials. The difference between the models can be visualized with Plots.jl:","category":"page"},{"location":"bayes_factor/#RDM","page":"Bayes Factors","title":"RDM","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"using Random\nusing SequentialSamplingModels\nusing Plots","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"using SequentialSamplingModels\nusing Plots\nusing Random\nRandom.seed!(77)\n\ndist = RDM()\ndensity_kwargs=(;t_range=range(.20, 1.0, length=100),)\nplot_model(dist; n_sim=1, density_kwargs, xlims=(0,1.0))","category":"page"},{"location":"bayes_factor/#LBA","page":"Bayes Factors","title":"LBA","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\ndist = LBA()\ndensity_kwargs=(;t_range=range(.20, 1.0, length=100),)\nplot_model(dist; n_sim=1, density_kwargs, xlims=(0,1.0))","category":"page"},{"location":"bayes_factor/#Load-Packages","page":"Bayes Factors","title":"Load Packages","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"Before proceeding, we will load the required packages.","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"using LinearAlgebra\nusing Pigeons\nusing Random\nusing SequentialSamplingModels\nusing Turing","category":"page"},{"location":"bayes_factor/#Data-Generating-Model","page":"Bayes Factors","title":"Data-Generating Model","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"The next step is to generate simulated data for comparing the models. Here, we will assume that the LBA is the true data generating model:","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"Random.seed!(654)\ndist = LBA(ν=[3.0, 2.0], A=0.8, k=0.2, τ=0.3)\ndata = rand(dist, 100)","category":"page"},{"location":"bayes_factor/#Define-Models","page":"Bayes Factors","title":"Define Models","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"The following code blocks define the models along with their prior distributions using Turing.jl. Notice that the models are identical except for the log likelihood function.","category":"page"},{"location":"bayes_factor/#RDM-2","page":"Bayes Factors","title":"RDM","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"@model function rdm(data; min_rt=minimum(data.rt))\n    ν ~ MvNormal(fill(2.0, 2), I * 3)\n    A ~ truncated(Normal(0.8, 0.8), 0.0, Inf)\n    k ~ truncated(Normal(0.2, 0.2), 0.0, Inf)\n    τ ~ Uniform(0.0, min_rt)\n    data ~ RDM(; ν, A, k, τ)\nend","category":"page"},{"location":"bayes_factor/#LBA-2","page":"Bayes Factors","title":"LBA","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"@model function lba(data; min_rt=minimum(data.rt))\n    ν ~ MvNormal(fill(2.0, 2), I * 3)\n    A ~ truncated(Normal(0.8, 0.8), 0.0, Inf)\n    k ~ truncated(Normal(0.2, 0.2), 0.0, Inf)\n    τ ~ Uniform(0.0, min_rt)\n    data ~ LBA(; ν, A, k, τ)\nend","category":"page"},{"location":"bayes_factor/#Estimate-Marginal-Log-Likelihood","page":"Bayes Factors","title":"Estimate Marginal Log Likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"The next step is to run the pigeons function to estimate the marginal log likelihood for each model. ","category":"page"},{"location":"bayes_factor/#LBA-3","page":"Bayes Factors","title":"LBA","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"pt_lba = pigeons(target=TuringLogPotential(lba(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"────────────────────────────────────────────────────────────────────────────\n  #scans       Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2        3.3      -24.5   4.43e-56      0.634          1          1 \n        4       1.88       42.2      0.331      0.791          1          1 \n        8       3.05       40.2     0.0393      0.661          1          1 \n       16       3.33       41.1      0.364       0.63          1          1 \n       32       3.05       41.3      0.396      0.662          1          1 \n       64       3.52       40.6      0.423      0.609          1          1 \n      128       3.26       41.4       0.56      0.638          1          1 \n      256       3.45       40.8      0.564      0.617          1          1 \n      512       3.48       40.8      0.578      0.613          1          1 \n 1.02e+03       3.33       40.9      0.596      0.629          1          1 \n────────────────────────────────────────────────────────────────────────────","category":"page"},{"location":"bayes_factor/#RDM-3","page":"Bayes Factors","title":"RDM","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"pt_rdm = pigeons(target=TuringLogPotential(rdm(data)), record=[traces])","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"────────────────────────────────────────────────────────────────────────────\n  #scans       Λ      log(Z₁/Z₀)   min(α)     mean(α)    min(αₑ)   mean(αₑ) \n────────── ────────── ────────── ────────── ────────── ────────── ──────────\n        2       4.73       31.6   0.000606      0.475          1          1 \n        4       2.83       43.1       0.42      0.686          1          1 \n        8       3.05       39.8    0.00128      0.661          1          1 \n       16       3.46       41.2      0.268      0.615          1          1 \n       32       3.81       40.9      0.328      0.577          1          1 \n       64       3.16       40.6      0.404      0.649          1          1 \n      128       3.26       41.3      0.569      0.638          1          1 \n      256        3.3       40.6       0.56      0.633          1          1 \n      512       3.38       40.9       0.55      0.625          1          1 \n 1.02e+03       3.45       40.7      0.589      0.617          1          1","category":"page"},{"location":"bayes_factor/#Extract-marginal-log-likelihood","page":"Bayes Factors","title":"Extract marginal log likelihood","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"In the following code block, the function stepping_stone extracts that marginal log likelihood:","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"mll_lba = stepping_stone(pt_lba)\nmll_rdm = stepping_stone(pt_rdm)","category":"page"},{"location":"bayes_factor/#Compute-the-Bayes-Factor","page":"Bayes Factors","title":"Compute the Bayes Factor","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"The bayes factor is obtained by exponentiating the difference between marginal log likelihoods. The value of 1.21 indicates that the data are 1.21 times more likely under the LBA than the RDM. ","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"bf = exp(mll_lba - mll_rdm)","category":"page"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"1.2070298459526883","category":"page"},{"location":"bayes_factor/#References","page":"Bayes Factors","title":"References","text":"","category":"section"},{"location":"bayes_factor/","page":"Bayes Factors","title":"Bayes Factors","text":"Syed, S., Bouchard-Côté, A., Deligiannidis, G., & Doucet, A. (2022). Non-reversible parallel tempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society Series B: Statistical Methodology, 84(2), 321-350.","category":"page"},{"location":"Ratcliff_DDM/#Ratcliff-Diffusion-Model","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The Ratcliff Diffusion Model (Ratcliff DDM; Ratcliff et al., 2016) is similar to the DDM. Like the DDM, the model assumes that evidence accumulates over time, starting from a certain position, until it crosses one of two boundaries and triggers the corresponding response (Ratcliff & McKoon, 2008; Ratcliff & Rouder, 1998; Ratcliff & Smith, 2004). The drift rate (ν) determines the rate at which the accumulation process approaches a decision boundary, representing the relative evidence for or against a specific response. The distance between the two decision boundaries (referred to as the evidence threshold, α) influences the amount of evidence required before executing a response. Non-decision-related components, including perceptual encoding, movement initiation, and execution, are accounted for in the DDM and reflected in the τ parameter. Lastly, the model incorporates a bias in the evidence accumulation process through the parameter z, affecting the starting point of the drift process in relation to the two boundaries. The z parameter in DDM is relative to a (i.e. it ranges from 0 to 1).","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"However, the model differs in the inclusion of across-trial variability parameters. These parameters were developed to explain specific discrepancies between the DDM and experimental data (Anderson, 1960; Laming, 1968; Blurton et al., 2017). The data exhibited a difference in mean RT between correct and error responses that could not be captured by the DDM. As a result, two parameters for across-trial variability were introduced to explain this difference: across-trial variability in the starting point to explain fast errors (Laming, 1968), and across-trial variability in drift rate to explain slow errors (Ratcliff, 1978; Ratcliff and Rouder, 1998). Additionally, the DDM also showed a sharper rise in the leading edge of the response time distribution than observed in the data. To capture this leading edge effect, across-trial variability in non-decision time was introduced. ","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Previous work has validated predictions of these across-trial variability parameters (Wagenmakers et al., 2009). When compared to the DDM, the Ratcliff DDM improves the fit to the data. Researchers now often assume that the core parameters of sequential sampling models, such as drift rates, non-decision times, and starting points vary between trials.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"One last parameter is the within-trial variability in drift rate (σ), or the diffusion coefficient. The diffusion coefficient is the standard deviation of the evidence accumulation process within one trial. It is a scaling parameter and by convention it is kept fixed. Following Navarro & Fuss, (2009), we use the σ = 1 version.","category":"page"},{"location":"Ratcliff_DDM/#Example","page":"Ratcliff Diffusion Model","title":"Example","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"In this example, we will demonstrate how to use the DDM in a generic two alternative forced choice task.","category":"page"},{"location":"Ratcliff_DDM/#Load-Packages","page":"Ratcliff Diffusion Model","title":"Load Packages","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The first step is to load the required packages.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"Ratcliff_DDM/#Create-Model-Object","page":"Ratcliff Diffusion Model","title":"Create Model Object","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"In the code below, we will define parameters for the DDM and create a model object to store the parameter values. ","category":"page"},{"location":"Ratcliff_DDM/#Drift-Rate","page":"Ratcliff Diffusion Model","title":"Drift Rate","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The average slope of the information accumulation process. The drift gives information about the speed and direction of the accumulation of information. Typical range: -5 < ν < 5","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Across-trial-variability of drift rate. Standard deviation of a normal distribution with mean v describing the distribution of actual drift rates from specific trials. Values different from 0 can predict slow errors. Typical range: 0 < η < 2. Default is 0.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"ν=1.0\nη = 0.16","category":"page"},{"location":"Ratcliff_DDM/#Boundary-Separation","page":"Ratcliff Diffusion Model","title":"Boundary Separation","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The amount of information that is considered for a decision. Large values indicates response caution. Typical range: 0.5 < α < 2","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"α = 0.80","category":"page"},{"location":"Ratcliff_DDM/#Non-Decision-Time","page":"Ratcliff Diffusion Model","title":"Non-Decision Time","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The duration for a non-decisional processes (encoding and response execution). Typical range: 0.1 < τ < 0.5 ","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Across-trial-variability of non-decisional components. Range of a uniform distribution with mean τ + st/2 describing the distribution of actual τ values across trials. Accounts for response times below t0. Reduces skew of predicted RT distributions. Typical range: 0 < τ < 0.2. Default is 0.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"τ = 0.30\nst = 0.10","category":"page"},{"location":"Ratcliff_DDM/#Starting-Point","page":"Ratcliff Diffusion Model","title":"Starting Point","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"An indicator of an an initial bias towards a decision. The z parameter is relative to a (i.e. it ranges from 0 to 1).","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Across-trial-variability of starting point. Range of a uniform distribution with mean z describing the distribution of actual starting points from specific trials. Values different from 0 can predict fast errors. Typical range: 0 < sz < 0.5. Default is 0.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"z = 0.25\nsz = 0.05","category":"page"},{"location":"Ratcliff_DDM/#Ratcliff-Diffusion-Model-Constructor","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model Constructor","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Now that values have been assigned to the parameters, we will pass them to RatcliffDDM to generate the model object.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"dist = DDM(ν, α, τ, z)","category":"page"},{"location":"Ratcliff_DDM/#Simulate-Model","page":"Ratcliff Diffusion Model","title":"Simulate Model","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"Ratcliff_DDM/#Compute-PDF","page":"Ratcliff Diffusion Model","title":"Compute PDF","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"Ratcliff_DDM/#Compute-Log-PDF","page":"Ratcliff Diffusion Model","title":"Compute Log PDF","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"Ratcliff_DDM/#Plot-Simulation","page":"Ratcliff Diffusion Model","title":"Plot Simulation","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"# rts for option 1\nrts1 = rts[choices .== 1]\n# rts for option 2 \nrts2 = rts[choices .== 2]\n# probability of choosing 1\np1 = length(rts1) / length(rts)\nt_range = range(.30, 2, length=100)\n# pdf for choice 1\npdf1 = pdf.(dist, (1,), t_range)\n# pdf for choice 2\npdf2 = pdf.(dist, (2,), t_range)\n# histogram of retrieval times\nhist = histogram(layout=(2,1), leg=false, grid=false,\n     xlabel=\"Reaction Time\", ylabel=\"Density\", xlims = (0,1.5))\nhistogram!(rts1, subplot=1, color=:grey, bins = 200, norm=true, title=\"Choice 1\")\nplot!(t_range, pdf1, subplot=1, color=:darkorange, linewidth=2)\nhistogram!(rts2, subplot=2, color=:grey, bins = 150, norm=true, title=\"Choice 2\")\nplot!(t_range, pdf2, subplot=2, color=:darkorange, linewidth=2)\n# weight histogram according to choice probability\nhist[1][1][:y] *= p1\nhist[2][1][:y] *= (1 - p1)\nhist","category":"page"},{"location":"Ratcliff_DDM/#References","page":"Ratcliff Diffusion Model","title":"References","text":"","category":"section"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Navarro, D., & Fuss, I. (2009). Fast and accurate calculations for first-passage times in Wiener diffusion models. https://doi.org/10.1016/J.JMP.2009.02.003","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Ratcliff, R., & McKoon, G. (2008). The Diffusion Decision Model: Theory and Data for Two-Choice Decision Tasks. Neural Computation, 20(4), 873–922. https://doi.org/10.1162/neco.2008.12-06-420","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Ratcliff, R., & Rouder, J. N. (1998). Modeling Response Times for Two-Choice Decisions. Psychological Science, 9(5), 347–356. https://doi.org/10.1111/1467-9280.00067","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Ratcliff, R., & Smith, P. L. (2004). A comparison of sequential sampling models for two-choice reaction time. Psychological Review, 111 2, 333–367. https://doi.org/10.1037/0033-295X.111.2.333","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Ratcliff, R., Smith, P. L., Brown, S. D., & McKoon, G. (2016). Diffusion Decision Model: Current Issues and History. Trends in Cognitive Sciences, 20(4), 260–281. https://doi.org/10.1016/j.tics.2016.01.007","category":"page"},{"location":"Ratcliff_DDM/","page":"Ratcliff Diffusion Model","title":"Ratcliff Diffusion Model","text":"Wagenmakers, E.-J. (2009). Methodological and empirical developments for the Ratcliff diffusion model of response times and accuracy. European Journal of Cognitive Psychology, 21(5), 641-671.","category":"page"},{"location":"layout/#Changing-the-Layout","page":"Changing the Layout","title":"Changing the Layout","text":"","category":"section"},{"location":"layout/","page":"Changing the Layout","title":"Changing the Layout","text":"As the example below demonstrates, densities are paneled according choice by default:","category":"page"},{"location":"layout/","page":"Changing the Layout","title":"Changing the Layout","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(85)\n\nν = [1.0,0.50]\nk = 0.50\nA = 1.0\nτ = 0.30\n\ndist = RDM(;ν, k, A, τ)\nplot(dist; t_range=range(.301, 2.5, length=100))","category":"page"},{"location":"layout/","page":"Changing the Layout","title":"Changing the Layout","text":"In some cases, one might prefer combining both density lines in the same plot. The code block below demonstrates how this can be achieved:","category":"page"},{"location":"layout/","page":"Changing the Layout","title":"Changing the Layout","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(85)\n\nν = [1.0,0.50]\nk = 0.50\nA = 1.0\nτ = 0.30\n\ndist = RDM(;ν, k, A, τ)\nt_range=range(.301, 2.5, length=100)\nplot(dist; \n    t_range, \n    layout=(1,1), \n    leg=true, \n    label=[\"1\" \"2\"], \n    color=[:blue :red], \n    title=\"\", \n    labeltitle=\"choice\"\n)","category":"page"},{"location":"ex_gaussian/#Ex-Gaussian-Model","page":"Ex-Gaussian","title":"Ex-Gaussian Model","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The Ex-Gaussian is the convolution of a Gaussian and exponential distribution sometimes used to model reaction time distributions:","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"mathrmrt sim mathrmnormal(musigma) + mathrmexponential(tau)","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"When the Ex-Gaussian was initially developed, some researchers thought that the Gaussian and exponential components represented motor and decision processes, respectively. More recent evidence casts doubt on this interpretation and shows that the parameters do not have a simple mapping to psychologically distinct processes in the drift diffusion model (Matzke & Wagenmakers, 2009). Perhaps this is unsurprising given that the models do not have the same number of parameters. Although the Ex-Gaussian is not technically a sequential sampling model, it is included in the package due to its historical role in reaction time modeling and its simple implementation. ","category":"page"},{"location":"ex_gaussian/#Example","page":"Ex-Gaussian","title":"Example","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"In this example, we will demonstrate how to use the Ex-Gaussian for a simulated detection task in which a stimulus appears and the subject responds as quickly as possible.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"ex_gaussian/#Load-Packages","page":"Ex-Gaussian","title":"Load Packages","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The first step is to load the required packages.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(21095)","category":"page"},{"location":"ex_gaussian/#Create-Model-Object","page":"Ex-Gaussian","title":"Create Model Object","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values.","category":"page"},{"location":"ex_gaussian/#Mean-of-Gaussian-Component","page":"Ex-Gaussian","title":"Mean of Gaussian Component","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The parameter mu represents the mean processing time in log space.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"μ = .80","category":"page"},{"location":"ex_gaussian/#Standard-Deviation-of-Gaussian-Component","page":"Ex-Gaussian","title":"Standard Deviation of Gaussian Component","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The parameter sigma represents the standard deviation of the Gaussian component.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"σ = .20","category":"page"},{"location":"ex_gaussian/#Mean-of-Exponential-Component","page":"Ex-Gaussian","title":"Mean of Exponential Component","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The parameter tau represents the mean of the exponential component.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"τ = 0.30","category":"page"},{"location":"ex_gaussian/#Ex-Gaussian-Constructor","page":"Ex-Gaussian","title":"Ex-Gaussian Constructor","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"Now that values have been assigned to the parameters, we will pass them to ExGaussian to generate the model object.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"dist = ExGaussian(μ, σ, τ)","category":"page"},{"location":"ex_gaussian/#Simulate-Model","page":"Ex-Gaussian","title":"Simulate Model","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"rts = rand(dist, 10_000)","category":"page"},{"location":"ex_gaussian/#Compute-PDF","page":"Ex-Gaussian","title":"Compute PDF","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"pdf.(dist, rts)","category":"page"},{"location":"ex_gaussian/#Compute-Log-PDF","page":"Ex-Gaussian","title":"Compute Log PDF","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"logpdf.(dist, rts)","category":"page"},{"location":"ex_gaussian/#Compute-CDF","page":"Ex-Gaussian","title":"Compute CDF","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The cumulative probability density Pr(T leq t) is computed by passing the model and a value t to cdf.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"cdf(dist, .4)","category":"page"},{"location":"ex_gaussian/#Plot-Simulation","page":"Ex-Gaussian","title":"Plot Simulation","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"histogram(dist)\nplot!(dist; t_range=range(.301, 2.5, length=100))","category":"page"},{"location":"ex_gaussian/#References","page":"Ex-Gaussian","title":"References","text":"","category":"section"},{"location":"ex_gaussian/","page":"Ex-Gaussian","title":"Ex-Gaussian","text":"Matzke, D., & Wagenmakers, E. J. (2009). Psychological interpretation of the ex-Gaussian and shifted Wald parameters: A diffusion model analysis. Psychonomic bulletin & review, 16, 798-817.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Introduction","page":"Bayesian Parameter Estimation","title":"Introduction","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The purpose of this example is to illustrate how to perform Bayesian parameter estimation with a neural parameter estimation. Neural parameter estimation learns the mapping between simulated data and the parameters of a model (Zammit-Mangion et al., 2024; Sainsbury-Dale et al., 2024; Radev et al., 2023). Neural parameter estimation constitutes a method of amortized inference, whereby a large upfront computational cost is incurred during training to enable rapid parameter estimation with the trained neural network. One benefit of amortized inference is that the neural network can be saved and reused to estimate parameters on multiple datasets. Additionally, neural estimator  estimator called normalizing flows. Normalizing flows are a special type of invertible neural network which can learn the posterior distribution by learning the mapping between parameters and the corresponding simulated data. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Overview","page":"Bayesian Parameter Estimation","title":"Overview","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In the example below, we estimate the parameters of the lognormal race model (LNR; Heathcote et al., 2012; Rounder et al., 2015) with the package NeuralEstimators.jl. We will use a normalising flow network in order to estimate the full posterior distribution of the LRN parameters. Generally speaking, neural parameter estimation is most useful for models with an intractible likelihood function, such as the leaky competing accumulator (Usher, M., & McClelland ). However, some of its key parameters are notoriously difficult to recover. As an alterntaive, we will use the LNR because its parameters have good estimation properties and can be easily recovered (Rounder et al., 2015).","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Full-Code","page":"Bayesian Parameter Estimation","title":"Full Code","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"You can reveal copy-and-pastable version of the full code by clicking the ▶ below. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"<details>\n<summary><b>Show Full Code</b></summary>","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using AlgebraOfGraphics\nusing CairoMakie\nusing Distributions\nusing Flux\nusing NeuralEstimators\nusing Plots\nusing Random\nusing SequentialSamplingModels\n\nRandom.seed!(544)\n\nn = 2           # dimension of each data replicate \nm = 100         # number of independent replicates \nd = 4           # dimension of the parameter vector θ\nw = 128         # width of each hidden layer \n\nfunction sample_prior(K)\n    ν = rand(Normal(-2, 3), K, 2)\n    σ = rand(truncated(Normal(1, 3), 0, Inf), K)\n    τ = rand(Uniform(0.100, 0.300), K)\n    θ = vcat(ν', σ', τ')\n    return θ\nend\n\nto_array(x) = Float32[x.choice'; x.rt']\nsimulate(θ, m) = [to_array(rand(LNR(ϑ[1:2], ϑ[3], ϑ[4]), m)) for ϑ ∈ eachcol(θ)]\n\n# Approximate distribution\napprox_dist = NormalisingFlow(d, 2d)\n\n# Neural network mapping data to summary statistics (of the same dimension used in the approximate distribution)\nψ = Chain(x -> log.(x), Dense(n, w, relu), Dense(w, w, relu))\nϕ = Chain(Dense(w, w, relu), Dense(w, 2d))\nnetwork = DeepSet(ψ, ϕ)\n\n# Initialise a neural posterior estimator\nestimator = PosteriorEstimator(approx_dist, network)\n\n# Train the estimator\nestimator = train(\n    estimator, \n\tsample_prior, \n\tsimulate; \n\tm, \n\tK = 25_000\n)\n\n# Assess the estimator\nθ_test = sample_prior(1000)\ndata_test = simulate(θ_test, m)\nassessment = assess(estimator, θ_test, data_test; parameter_names = [\"ν₁\", \"ν₂\", \"σ\", \"τ\"])\nbias(assessment)\nrmse(assessment)\nrecovery_plot = AlgebraOfGraphics.plot(assessment)\n\n# perform Bayesian parameter estimation on simulated data \nθ = [-1.5, 0, 0.75, 0.250]       \ndata = simulate(θ, m)        \npost_samples = sampleposterior(estimator, data)\nPlots.histogram(\n    post_samples',\n    layout = (4, 1),\n    color = :grey,\n    norm = true,\n    leg = false,\n    grid = false,\n    xlabel = [\"ν₁\" \"ν₂\" \"σ\" \"τ\"]\n)\nvline!([θ'], color = :darkred, linewidth = 2)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"</details>","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Load-Dependencies","page":"Bayesian Parameter Estimation","title":"Load Dependencies","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The first step is to load the dependencies. NeuralEstimators and Flux are the primary packages for performing Bayesian parameter estimation with normalizing flows. We will also load AlgebraOfGraphics, CairoMakie, and Plots to visualize the parameter recovery and posterior distributions. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using AlgebraOfGraphics\nusing CairoMakie\nusing Distributions\nusing Flux\nusing NeuralEstimators\nusing Plots\nusing Random\nusing SequentialSamplingModels","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In the code block below, we set the seed for the random number generator so that the results are reproducible. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Random.seed!(544)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Simulation-Functions","page":"Bayesian Parameter Estimation","title":"Simulation Functions","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"As previously noted, normalizing flow neural networks learn the mapping between the prior distribution and simulated data. Once that mapping is learned, the network is inverted to allow one to sample from posterior distribution. We define two functions to generate training data–-one to sample from the prior distribution, and another to sample data from the model, given a sampled parameter vector from the prior distribution.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Sample-from-Prior-Distribution","page":"Bayesian Parameter Estimation","title":"Sample from Prior Distribution","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In the code block below, the K samples are generated from each prior and concatonated into a 4 times K array. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"function sample_prior(K)\n    ν = rand(Normal(-2, 3), K, 2)\n    σ = rand(truncated(Normal(1, 3), 0, Inf), K)\n    τ = rand(Uniform(0.100, 0.300), K)\n    θ = vcat(ν', σ', τ')\n    return θ\nend","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Sample-from-Model","page":"Bayesian Parameter Estimation","title":"Sample from Model","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"The code block below specifies the function simulate to sample simulated data from the model. In this function, theta is a 4 times K array, with each column representing an independent sample from the prior distribution, and m is the number of trials sampled from the model per sample from the prior. The helper function to_array transforms the data into the required format: an m times 2 array in which the first column consists of choice indices, and the second column consists of reaction times. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"to_array(x) = Float32[x.choice'; x.rt']\nsimulate(θ, m) = [to_array(rand(LNR(ϑ[1:2], ϑ[3], ϑ[4]), m)) for ϑ ∈ eachcol(θ)]","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Configure-Neural-Network","page":"Bayesian Parameter Estimation","title":"Configure Neural Network","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"In this section, we will configure the neural network to perform Bayesian parameter estimation. At a high level, the neural network has two primary components. The first component is the DeepSet neural network, which compresses the data by learning summary statistics describing the distribution of data. The second component is an invertible neural network called a NormalisingFlow. A normalising flow transforms a set of simple base distributions to approximate a complex distribution (see below). Importantly, because normalising flows are invertible, they can be used to sample from the posterior distribution. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(Image: )  The sequential transformation process of a normalising flow. Credit. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"# Approximate distribution\napprox_dist = NormalisingFlow(d, 2d)\n\n# Neural network mapping data to summary statistics (of the same dimension used in the approximate distribution)\nψ = Chain(x -> log.(x), Dense(n, w, relu), Dense(w, w, relu))\nϕ = Chain(Dense(w, w, relu), Dense(w, 2d))\nnetwork = DeepSet(ψ, ϕ)\n\n# Initialise a neural posterior estimator\nestimator = PosteriorEstimator(approx_dist, network)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Train-the-Neural-Network","page":"Bayesian Parameter Estimation","title":"Train the Neural Network","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Next, to train the neural estimator, we pass the estimator, the function sample_prior, and the function simulate to the function train. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"estimator = train(\n    estimator, \n    sample_prior, \n    simulate; \n    # the sample size\n    m, \n    # the number of training examples\n    K = 25_000\n)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Assess-the-Accuracy-of-the-Neural-Network","page":"Bayesian Parameter Estimation","title":"Assess the Accuracy of the Neural Network","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"As shown in the code block below, the package NeuralEstimators provides three ways to assess the accuracy of the neural network: bias, rmse, and scatter plots of the parameer recovery. The parameter recovery plots below indicate that the neural network learned the mapping well. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"θ_test = sample_prior(1000)\ndata_test = simulate(θ_test, m)\nassessment = assess(estimator, θ_test, data_test; parameter_names = [\"ν₁\", \"ν₂\", \"σ\", \"τ\"])\nbias(assessment)\nrmse(assessment)\nrecovery_plot = AlgebraOfGraphics.plot(assessment)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(Image: )","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Perform-Bayesian-Parameter-Estimation","page":"Bayesian Parameter Estimation","title":"Perform Bayesian Parameter Estimation","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Now that the neural network has been trained, we can perform Bayesian parameter estimation. In the example below, we simulate data from the model using parameters defined in the vector theta. The estimator and data are passed to sampleposterior, which generates samples from the posterior distribution of parameters. As expected, the histogram shows that the posterior distributions are near the true parameter values, displayed as red vertical lines.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"θ = [-1.5, 0, 0.75, 0.150]       \ndata = simulate(θ, m)        \npost_samples = sampleposterior(estimator, data)\nPlots.histogram(\n    post_samples',\n    layout = (4, 1),\n    color = :grey,\n    norm = true,\n    leg = false,\n    grid = false,\n    xlabel = [\"ν₁\" \"ν₂\" \"σ\" \"τ\"]\n)\nvline!([θ'], color = :darkred, linewidth = 2)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"(Image: )","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#Save-the-Trained-Neural-Network","page":"Bayesian Parameter Estimation","title":"Save the Trained Neural Network","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using BSON: @save \nusing Flux\n\nmodel_state = Flux.state(estimator)\n@save \"lnr_estimator.bson\" model_state","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"You can load the trained neural network into a new Julia session with the @load macro from BSON. In order to successfully reuse the trained neural network, you will need to initialize the neural network before passing the trained parameters. You can reveal copy-and-pastable version of the full code by clicking the ▶ below. ","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"<details>\n<summary><b>Show Full Code</b></summary>","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"using BSON: @load\nusing Distributions\nusing Flux\nusing NeuralEstimators\nusing SequentialSamplingModels\n\nRandom.seed!(544)\n\nn = 2           # dimension of each data replicate \nm = 100         # number of independent replicates \nd = 4           # dimension of the parameter vector θ\nw = 128         # width of each hidden layer \n\n# Approximate distribution\napprox_dist = NormalisingFlow(d, 2d)\n\n# Neural network mapping data to summary statistics (of the same dimension used in the approximate distribution)\nψ = Chain(x -> log.(x), Dense(n, w, relu), Dense(w, w, relu))\nϕ = Chain(Dense(w, w, relu), Dense(w, 2d))\nnetwork = DeepSet(ψ, ϕ)\n\n# Initialise a neural posterior estimator\nestimator = PosteriorEstimator(approx_dist, network)\n\n# load the weights\n@load \"lnr_estimator.bson\" model_state\nFlux.loadmodel!(estimator, model_state)","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"</details>","category":"page"},{"location":"amortized_bayesian_parameter_estimation/#References","page":"Bayesian Parameter Estimation","title":"References","text":"","category":"section"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Heathcote, A., & Love, J. (2012). Linear deterministic accumulator models of simple choice. Frontiers in psychology, 3, 292.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Sainsbury-Dale, Matthew, Andrew Zammit-Mangion, and Raphaël Huser. \"Likelihood-free parameter estimation with neural Bayes estimators.\" The American Statistician 78.1 (2024): 1-14.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Radev, S. T., Schmitt, M., Schumacher, L., Elsemüller, L., Pratz, V., Schälte, Y., ... & Bürkner, P. C. (2023). BayesFlow: Amortized Bayesian workflows with neural networks. arXiv preprint arXiv:2306.16015.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Rouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015). The lognormal race: A cognitive-process model of choice and latency with desirable psychometric properties. Psychometrika, 80(2), 491-513.","category":"page"},{"location":"amortized_bayesian_parameter_estimation/","page":"Bayesian Parameter Estimation","title":"Bayesian Parameter Estimation","text":"Zammit-Mangion, Andrew, Matthew Sainsbury-Dale, and Raphaël Huser. \"Neural methods for amortized inference.\" Annual Review of Statistics and Its Application 12 (2024).","category":"page"},{"location":"lba/#Linear-Ballistic-Accumulator","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The Linear Ballistic Accumulator (LBA; Brown & Heathcote, 2008) is a sequential sampling model in which evidence for options races independently. The LBA makes an additional simplification that evidence accumulates in a linear and ballistic fashion, meaning there is no intra-trial noise. Instead, evidence accumulates deterministically and linearly until it hits the threshold.","category":"page"},{"location":"lba/#Example","page":"Linear Ballistic Accumulator (LBA)","title":"Example","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"In this example, we will demonstrate how to use the LBA in a generic two alternative forced choice task. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"lba/#Load-Packages","page":"Linear Ballistic Accumulator (LBA)","title":"Load Packages","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The first step is to load the required packages.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"lba/#Create-Model-Object","page":"Linear Ballistic Accumulator (LBA)","title":"Create Model Object","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"lba/#Mean-Drift-Rates","page":"Linear Ballistic Accumulator (LBA)","title":"Mean Drift Rates","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The drift rates control the speed with which evidence accumulates for each option. In the standard LBA, drift rates vary across trials according to a normal distribution with mean nu:","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"ν = [2.75,1.75]","category":"page"},{"location":"lba/#Standard-Deviation-of-Drift-Rates","page":"Linear Ballistic Accumulator (LBA)","title":"Standard Deviation of Drift Rates","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The standard deviation of the drift rate distribution is given by sigma, which is commonly fixed to 1 for each accumulator.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"σ = [1.0,1.0]","category":"page"},{"location":"lba/#Maximum-Starting-Point","page":"Linear Ballistic Accumulator (LBA)","title":"Maximum Starting Point","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The starting point of each accumulator is sampled uniformly between 0A.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"A = 0.80","category":"page"},{"location":"lba/#Threshold-Maximum-Starting-Point","page":"Linear Ballistic Accumulator (LBA)","title":"Threshold - Maximum Starting Point","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"Evidence accumulates until accumulator reaches a threshold alpha = k +A. The threshold is parameterized this way to faciliate parameter estimation and to ensure that A le alpha.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"k = 0.50","category":"page"},{"location":"lba/#Non-Decision-Time","page":"Linear Ballistic Accumulator (LBA)","title":"Non-Decision Time","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"τ = 0.30","category":"page"},{"location":"lba/#LBA-Constructor","page":"Linear Ballistic Accumulator (LBA)","title":"LBA Constructor","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"Now that values have been asigned to the parameters, we will pass them to LBA to generate the model object.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"dist = LBA(; ν, A, k, τ) ","category":"page"},{"location":"lba/#Simulate-Model","page":"Linear Ballistic Accumulator (LBA)","title":"Simulate Model","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"lba/#Compute-PDF","page":"Linear Ballistic Accumulator (LBA)","title":"Compute PDF","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"lba/#Compute-Log-PDF","page":"Linear Ballistic Accumulator (LBA)","title":"Compute Log PDF","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"lba/#Compute-Choice-Probability","page":"Linear Ballistic Accumulator (LBA)","title":"Compute Choice Probability","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"cdf(dist, 1, Inf)","category":"page"},{"location":"lba/#Plot-Simulation","page":"Linear Ballistic Accumulator (LBA)","title":"Plot Simulation","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"histogram(dist)\nplot!(dist; t_range=range(.3,2.5, length=100), xlims=(0, 2.5))\n","category":"page"},{"location":"lba/#References","page":"Linear Ballistic Accumulator (LBA)","title":"References","text":"","category":"section"},{"location":"lba/","page":"Linear Ballistic Accumulator (LBA)","title":"Linear Ballistic Accumulator (LBA)","text":"Brown, S. D., & Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive psychology, 57(3), 153-178.","category":"page"},{"location":"lca/#Leaky-Competing-Accumulator","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The Leaky Competing Accumulator (LCA; Usher & McClelland, 2001) is a sequential sampling model in which evidence for options races independently. The LCA is similar to the Linear Ballistic Accumulator (LBA), but additionally assumes an intra-trial noise and leakage (in contrast, the LBA assumes that evidence accumulates in a ballistic fashion, i.e., linearly and deterministically until it hits the threshold).","category":"page"},{"location":"lca/#Example","page":"Leaky Competing Accumulator (LCA)","title":"Example","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"In this example, we will demonstrate how to use the LCA in a generic two alternative forced choice task. ","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"lca/#Load-Packages","page":"Leaky Competing Accumulator (LCA)","title":"Load Packages","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The first step is to load the required packages.","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"lca/#Create-Model-Object","page":"Leaky Competing Accumulator (LCA)","title":"Create Model Object","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values. ","category":"page"},{"location":"lca/#Drift-Rates","page":"Leaky Competing Accumulator (LCA)","title":"Drift Rates","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The drift rates control the speed with which information accumulates. Typically, there is one drift rate per option. ","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"ν = [2.5,2.0]","category":"page"},{"location":"lca/#Threshold","page":"Leaky Competing Accumulator (LCA)","title":"Threshold","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The threshold alpha represents the amount of evidence required to make a decision.","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"α = 1.5","category":"page"},{"location":"lca/#Lateral-Inhibition","page":"Leaky Competing Accumulator (LCA)","title":"Lateral Inhibition","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The parameter beta inhibits evidence of competing options proportionally to their evidence value.","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"β = 0.20","category":"page"},{"location":"lca/#Leak-Rate","page":"Leaky Competing Accumulator (LCA)","title":"Leak Rate","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The parameter lambda controls the rate with which evidence decays or \"leaks\".","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"λ = 0.10 ","category":"page"},{"location":"lca/#Diffusion-Noise","page":"Leaky Competing Accumulator (LCA)","title":"Diffusion Noise","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"Diffusion noise is the amount of within trial noise in the evidence accumulation process. ","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"σ = 1.0","category":"page"},{"location":"lca/#Non-Decision-Time","page":"Leaky Competing Accumulator (LCA)","title":"Non-Decision Time","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"τ = 0.30","category":"page"},{"location":"lca/#LCA-Constructor","page":"Leaky Competing Accumulator (LCA)","title":"LCA Constructor","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"Now that values have been asigned to the parameters, we will pass them to LCA to generate the model object.","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"dist = LCA(; ν, α, β, λ, τ, σ)","category":"page"},{"location":"lca/#Simulate-Model","page":"Leaky Competing Accumulator (LCA)","title":"Simulate Model","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"In the code block above, rand has a keyword argument Δt which controls the precision of the discrete approximation. The default value is Δt = .001.","category":"page"},{"location":"lca/#Compute-Choice-Probability","page":"Leaky Competing Accumulator (LCA)","title":"Compute Choice Probability","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"cdf(dist, 1, Inf)","category":"page"},{"location":"lca/#Plot-Simulation","page":"Leaky Competing Accumulator (LCA)","title":"Plot Simulation","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"The code below plots a histogram for each option.","category":"page"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"histogram(dist)","category":"page"},{"location":"lca/#References","page":"Leaky Competing Accumulator (LCA)","title":"References","text":"","category":"section"},{"location":"lca/","page":"Leaky Competing Accumulator (LCA)","title":"Leaky Competing Accumulator (LCA)","text":"Usher, M., & McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. Psychological Review, 108 3, 550–592. https://doi.org/10.1037/0033-295X.108.3.550","category":"page"},{"location":"lnr/#Lognormal-Race-Model","page":"Log Normal Race (LNR)","title":"Lognormal Race Model","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"The Lognormal Race model (LNR) assumes evidence for each option races independently and that the first passage time for each option is lognormally distributed. One way in which the LNR has been used is to provide a likelihood function for the ACT-R cognitive architecture. An example of such an application can be found in ACTRModels.jl. We will present a simplified version below.","category":"page"},{"location":"lnr/#Example","page":"Log Normal Race (LNR)","title":"Example","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"In this example, we will demonstrate how to use the LNR in a generic two alternative forced choice task.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"lnr/#Load-Packages","page":"Log Normal Race (LNR)","title":"Load Packages","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"The first step is to load the required packages.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"lnr/#Create-Model-Object","page":"Log Normal Race (LNR)","title":"Create Model Object","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"In the code below, we will define parameters for the LBA and create a model object to store the parameter values.","category":"page"},{"location":"lnr/#\\nu","page":"Log Normal Race (LNR)","title":"nu","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"We will set nu -1-15.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"ν = [-1,-1.5]","category":"page"},{"location":"lnr/#\\sigma","page":"Log Normal Race (LNR)","title":"sigma","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"We will set the parameter sigma = -1-15 ","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"σ = [0.50,0.50]","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"The lognormal has the following relationship to the normal distribution:","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"X sim mathrmlognormal(nu sigma) iff log(X) sim mathrmnormal(nu sigma)","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":". ","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"This means that Elog(X) = nu and mathrmVarlog(X) = sigma^2. Note that nu and sigma affect both the mean and variance of the lognormal distribution. See ACT-R for a possible theoretical intepretation of parameters nu and sigma.","category":"page"},{"location":"lnr/#Non-Decision-Time","page":"Log Normal Race (LNR)","title":"Non-Decision Time","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"Non-decision time is an additive constant representing encoding and motor response time.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"τ = 0.30","category":"page"},{"location":"lnr/#LNR-Constructor","page":"Log Normal Race (LNR)","title":"LNR Constructor","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"Now that values have been asigned to the parameters, we will pass them to LNR to generate the model object.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"dist = LNR(ν, σ, τ)","category":"page"},{"location":"lnr/#Simulate-Model","page":"Log Normal Race (LNR)","title":"Simulate Model","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"lnr/#Compute-PDF","page":"Log Normal Race (LNR)","title":"Compute PDF","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"lnr/#Compute-Log-PDF","page":"Log Normal Race (LNR)","title":"Compute Log PDF","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"lnr/#Compute-Choice-Probability","page":"Log Normal Race (LNR)","title":"Compute Choice Probability","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"cdf(dist, 1, Inf)","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"To compute the joint probability of choosing c within t seconds, i.e., Pr(T leq t wedge C=c), pass a third argument for t.","category":"page"},{"location":"lnr/#Plot-Simulation","page":"Log Normal Race (LNR)","title":"Plot Simulation","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"histogram(dist)\nplot!(dist; t_range=range(.301, 1, length=100))","category":"page"},{"location":"lnr/#References","page":"Log Normal Race (LNR)","title":"References","text":"","category":"section"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"Heathcote, A., & Love, J. (2012). Linear deterministic accumulator models of simple choice. Frontiers in psychology, 3, 292.","category":"page"},{"location":"lnr/","page":"Log Normal Race (LNR)","title":"Log Normal Race (LNR)","text":"Rouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015). The lognormal race: A cognitive-process model of choice and latency with desirable psychometric properties. Psychometrika, 80, 491-513.","category":"page"},{"location":"performance_tips/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"performance_tips/#General-Tips","page":"Performance Tips","title":"General Tips","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"In Julia, high performance can be achieved by following a small set of principles, such as avoiding global variables, avoding heterogenous containers, and placing performance critical code in a function. The same basic principles apply when using SequentialSamplingModels.jl. See the Julia documentation for more details.","category":"page"},{"location":"performance_tips/#Turing","page":"Performance Tips","title":"Turing","text":"","category":"section"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Turing provides three general recommendations for developing performant code:","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"Ensure types are inferable using principles defined in the Julia documentation\nUse Multivariate distributions in place of Univariate distributions when applicable. \nUse forward mode automatic differentiation when your model has a small number of parameters (i.e., 5-10), and use reverse mode automatic differentiation for larger models. ","category":"page"},{"location":"performance_tips/","page":"Performance Tips","title":"Performance Tips","text":"See the Turing documentation for more details. Note that the Turing ecosystem provides a benchmarking package, TuringBenchmarking.jl to aid in the selection of an automatic differentiation backend. ","category":"page"},{"location":"mode_estimation/#Mode-Estimation","page":"Mode Estimation","title":"Mode Estimation","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"Mode estimation can be useful when full Bayesian inference is not desired, or when one wishes to initialize an MCMC sampling algorithm near the mode of the posterior distribution. Below, we show how to estimate the mode of a posterior distribution using Turing's capabilities for maximum likelihood estimation (MLE) and maximum a postiori (MAP).","category":"page"},{"location":"mode_estimation/#Example","page":"Mode Estimation","title":"Example","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"For this simple example, we will estimate the mode of the posterior distribution of the Wald model. In the code block below, we will load the required packages. ","category":"page"},{"location":"mode_estimation/#Load-Packages","page":"Mode Estimation","title":"Load Packages","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"using Turing\nusing SequentialSamplingModels\nusing Random\nRandom.seed!(654)","category":"page"},{"location":"mode_estimation/#Generate-Data","page":"Mode Estimation","title":"Generate Data","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"We will generate 50 simulated reaction times from the Wald model. ","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"n_samples = 50\nrts = rand(Wald(ν=1.5, α=.8, τ=.3), n_samples)","category":"page"},{"location":"mode_estimation/#Define-Turing-Model","page":"Mode Estimation","title":"Define Turing Model","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"Below, we define a Turing model with prior distributions specified. Note that the prior  distributions are only applicable to MAP.","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"@model function model(rts; min_rt = minimum(rts))\n    ν ~ truncated(Normal(1.5, 1), 0, Inf)\n    α ~ truncated(Normal(.8, 1), 0, Inf)\n    τ ~ Uniform(0, min_rt)\n    rts ~ Wald(ν, α, τ)\n    return (;ν, α, τ)\nend","category":"page"},{"location":"mode_estimation/#Set-Parameter-Bounds","page":"Mode Estimation","title":"Set Parameter Bounds","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"Specifying lower and upper bounds for the parameters is necessary to prevent the MLE and MAP  estimators from searching invalid regions of the parameter space. ","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"lb = [0,0,0]\nub = [10, 10, minimum(rts)]","category":"page"},{"location":"mode_estimation/#MLE","page":"Mode Estimation","title":"MLE","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"MLE is performed via the function maximum_likelihood.","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"mle_estimate = maximum_likelihood(model(rts); lb, ub)","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"ModeResult with maximized lp of -7.62\n[1.441581500744421, 0.6990063775377103, 0.32611139519154697]","category":"page"},{"location":"mode_estimation/#MAP","page":"Mode Estimation","title":"MAP","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"MAP is performed via the function maximum_a_posteriori.","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"map_estimate = maximum_a_posteriori(model(rts); lb, ub)","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"ModeResult with maximized lp of -8.20\n[1.4488716348067334, 0.7022870580892082, 0.3255810892442324]","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"In both cases, the estimates are in the proximity of the data-generating values. ","category":"page"},{"location":"mode_estimation/#Accessing-Estimates","page":"Mode Estimation","title":"Accessing Estimates","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"The estimates are located in the field values, which can be accessed as follows:","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"map_estimate.values","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"which returns a named vector. To obtain a regular vector, append .array to the code above.","category":"page"},{"location":"mode_estimation/#Seeding-MCMC-Sampler","page":"Mode Estimation","title":"Seeding MCMC Sampler","text":"","category":"section"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"You can seed the MCMC sampler as illustrated below:","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"chain = sample(model(rts), NUTS(), 1_000; initial_params=map_estimate.values.array)","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"┌ Info: Found initial step size\n└   ϵ = 0.05\nChains MCMC chain (1000×15×1 Array{Float64, 3}):\n\nIterations        = 501:1:1500\nNumber of chains  = 1\nSamples per chain = 1000\nWall duration     = 3.97 seconds\nCompute duration  = 3.97 seconds\nparameters        = ν, α, τ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse   ess_bulk   ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64    Float64    Float64   Float64       Float64 \n\n           ν    1.5597    0.3184    0.0228   202.3201   154.0195    1.0087       50.9366\n           α    0.8230    0.2030    0.0185   163.9590    80.6732    1.0096       41.2787\n           τ    0.2937    0.0474    0.0043   174.7682   106.7551    1.0117       44.0000\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n           ν    0.9220    1.3475    1.5532    1.7466    2.2150\n           α    0.5375    0.6884    0.7853    0.9231    1.3999\n           τ    0.1533    0.2720    0.3055    0.3261    0.3516","category":"page"},{"location":"mode_estimation/","page":"Mode Estimation","title":"Mode Estimation","text":"Additional details can be found in the Turing documentation","category":"page"},{"location":"DDM/#Diffusion-Decision-Model","page":"Drift Diffusion Model (DDM)","title":"Diffusion Decision Model","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The Diffusion Decision Model (DDM; Ratcliff et al., 2016) is a model of speeded decision-making in two-choice tasks. The DDM assumes that evidence accumulates over time, starting from a certain position, until it crosses one of two boundaries and triggers the corresponding response (Ratcliff & McKoon, 2008; Ratcliff & Rouder, 1998; Ratcliff & Smith, 2004). Like other Sequential Sampling Models, the DDM comprises psychologically interpretable parameters that collectively form a generative model for reaction time distributions of both responses.","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The drift rate (ν) determines the rate at which the accumulation process approaches a decision boundary, representing the relative evidence for or against a specific response. The distance between the two decision boundaries (referred to as the evidence threshold, α) influences the amount of evidence required before executing a response. Non-decision-related components, including perceptual encoding, movement initiation, and execution, are accounted for in the DDM and reflected in the τ parameter. Lastly, the model incorporates a bias in the evidence accumulation process through the parameter z, affecting the starting point of the drift process in relation to the two boundaries. The z parameter in DDM is relative to a (i.e. it ranges from 0 to 1).","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"One last parameter is the within-trial variability in drift rate (σ), or the diffusion coefficient. The diffusion coefficient is the standard deviation of the evidence accumulation process within one trial. It is a scaling parameter and by convention it is kept fixed. Following Navarro & Fuss, (2009), we use the σ = 1 version.","category":"page"},{"location":"DDM/#Example","page":"Drift Diffusion Model (DDM)","title":"Example","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"In this example, we will demonstrate how to use the DDM in a generic two alternative forced choice task.","category":"page"},{"location":"DDM/#Load-Packages","page":"Drift Diffusion Model (DDM)","title":"Load Packages","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The first step is to load the required packages.","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"DDM/#Create-Model-Object","page":"Drift Diffusion Model (DDM)","title":"Create Model Object","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"In the code below, we will define parameters for the DDM and create a model object to store the parameter values. ","category":"page"},{"location":"DDM/#Drift-Rate","page":"Drift Diffusion Model (DDM)","title":"Drift Rate","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The average slope of the information accumulation process. The drift gives information about the speed and direction of the accumulation of information. Typical range: -5 < ν < 5","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"ν=1.0","category":"page"},{"location":"DDM/#Boundary-Separation","page":"Drift Diffusion Model (DDM)","title":"Boundary Separation","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The amount of information that is considered for a decision. Large values indicates response caution. Typical range: 0.5 < α < 2","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"α = 0.80","category":"page"},{"location":"DDM/#Non-Decision-Time","page":"Drift Diffusion Model (DDM)","title":"Non-Decision Time","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The duration for a non-decisional processes (encoding and response execution). Typical range: 0.1 < τ < 0.5 ","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"τ = 0.30","category":"page"},{"location":"DDM/#Starting-Point","page":"Drift Diffusion Model (DDM)","title":"Starting Point","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"An indicator of an an initial bias towards a decision. The z parameter is relative to a (i.e. it ranges from 0 to 1).","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"z = 0.50","category":"page"},{"location":"DDM/#DDM-Constructor","page":"Drift Diffusion Model (DDM)","title":"DDM Constructor","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Now that values have been assigned to the parameters, we will pass them to DDM to generate the model object.","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"dist = DDM(ν, α, τ, z)","category":"page"},{"location":"DDM/#Simulate-Model","page":"Drift Diffusion Model (DDM)","title":"Simulate Model","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"DDM/#Compute-PDF","page":"Drift Diffusion Model (DDM)","title":"Compute PDF","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"DDM/#Compute-Log-PDF","page":"Drift Diffusion Model (DDM)","title":"Compute Log PDF","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"DDM/#Compute-Choice-Probability","page":"Drift Diffusion Model (DDM)","title":"Compute Choice Probability","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"cdf(dist, 1, 10)","category":"page"},{"location":"DDM/#Plot-Simulation","page":"Drift Diffusion Model (DDM)","title":"Plot Simulation","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"histogram(dist)\nplot!(dist; t_range=range(.301, 1, length=100))","category":"page"},{"location":"DDM/#References","page":"Drift Diffusion Model (DDM)","title":"References","text":"","category":"section"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Navarro, D., & Fuss, I. (2009). Fast and accurate calculations for first-passage times in Wiener diffusion models. https://doi.org/10.1016/J.JMP.2009.02.003","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Ratcliff, R., & McKoon, G. (2008). The Diffusion Decision Model: Theory and Data for Two-Choice Decision Tasks. Neural Computation, 20(4), 873–922. https://doi.org/10.1162/neco.2008.12-06-420","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Ratcliff, R., & Rouder, J. N. (1998). Modeling Response Times for Two-Choice Decisions. Psychological Science, 9(5), 347–356. https://doi.org/10.1111/1467-9280.00067","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Ratcliff, R., & Smith, P. L. (2004). A comparison of sequential sampling models for two-choice reaction time. Psychological Review, 111 2, 333–367. https://doi.org/10.1037/0033-295X.111.2.333","category":"page"},{"location":"DDM/","page":"Drift Diffusion Model (DDM)","title":"Drift Diffusion Model (DDM)","text":"Ratcliff, R., Smith, P. L., Brown, S. D., & McKoon, G. (2016). Diffusion Decision Model: Current Issues and History. Trends in Cognitive Sciences, 20(4), 260–281. https://doi.org/10.1016/j.tics.2016.01.007","category":"page"},{"location":"wald_mixture/#Wald-Mixture-Model","page":"Wald Mixture","title":"Wald Mixture Model","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The Wald mixture model is a sequential sampling model for single choice decisions. It extends the Wald model by allowing the drift rate to vary randomly across trials. ","category":"page"},{"location":"wald_mixture/#Example","page":"Wald Mixture","title":"Example","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"In this example, we will demonstrate how to use the Wald mixture model in a generic single choice decision task. ","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"wald_mixture/#Load-Packages","page":"Wald Mixture","title":"Load Packages","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The first step is to load the required packages.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"wald_mixture/#Create-Model-Object","page":"Wald Mixture","title":"Create Model Object","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"In the code below, we will define parameters for the WaldMixture and create a model object to store the parameter values. ","category":"page"},{"location":"wald_mixture/#Drift-Rate","page":"Wald Mixture","title":"Drift Rate","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The parameter nu represents the evidence accumulation rate.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"ν = 3.0","category":"page"},{"location":"wald_mixture/#Drift-Rate-Variability","page":"Wald Mixture","title":"Drift Rate Variability","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The parameter eta represents the standard deviation of the evidence accumulation rate across trials.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"η = 0.20","category":"page"},{"location":"wald_mixture/#Threshold","page":"Wald Mixture","title":"Threshold","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The parameter alpha the amount of evidence required to make a decision.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"α = 0.50","category":"page"},{"location":"wald_mixture/#Non-Decision-Time","page":"Wald Mixture","title":"Non-Decision Time","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"τ = 0.130","category":"page"},{"location":"wald_mixture/#Wald-Constructor","page":"Wald Mixture","title":"Wald Constructor","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"Now that values have been asigned to the parameters, we will pass them to WaldMixture to generate the model object.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"dist = WaldMixture(ν, η, α, τ)","category":"page"},{"location":"wald_mixture/#Simulate-Model","page":"Wald Mixture","title":"Simulate Model","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"rts = rand(dist, 1000)","category":"page"},{"location":"wald_mixture/#Compute-PDF","page":"Wald Mixture","title":"Compute PDF","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"pdf.(dist, rts)","category":"page"},{"location":"wald_mixture/#Compute-Log-PDF","page":"Wald Mixture","title":"Compute Log PDF","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"logpdf.(dist, rts)","category":"page"},{"location":"wald_mixture/#Compute-CDF","page":"Wald Mixture","title":"Compute CDF","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The cumulative probability density Pr(T leq t) is computed by passing the model and a value t to cdf.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"cdf(dist, .4)","category":"page"},{"location":"wald_mixture/#Plot-Simulation","page":"Wald Mixture","title":"Plot Simulation","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"The code below overlays the PDF on reaction time histogram.","category":"page"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"histogram(dist)\nplot!(dist; t_range=range(.130, 1, length=100))","category":"page"},{"location":"wald_mixture/#References","page":"Wald Mixture","title":"References","text":"","category":"section"},{"location":"wald_mixture/","page":"Wald Mixture","title":"Wald Mixture","text":"Steingroever, H., Wabersich, D., & Wagenmakers, E. J. (2021). Modeling across-trial variability in the Wald drift rate parameter. Behavior Research Methods, 53, 1060-1076.","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [SequentialSamplingModels]\nOrder   = [:type, :function]\nPrivate = false","category":"page"},{"location":"api/#SequentialSamplingModels.AbstractDDM","page":"API","title":"SequentialSamplingModels.AbstractDDM","text":"AbstractDDM <: SSM2D\n\nAn abstract type for the drift diffusion model.  \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractLBA","page":"API","title":"SequentialSamplingModels.AbstractLBA","text":"AbstractLBA{T, T1} <: SSM2D\n\nAn abstract type for the linear ballistic accumulator model.  \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractLCA","page":"API","title":"SequentialSamplingModels.AbstractLCA","text":"AbstractLCA <: SSM2D\n\nAn abstract type for the leaky competing accumulator model\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractLNR","page":"API","title":"SequentialSamplingModels.AbstractLNR","text":"AbstractLNR{T, T1} <: SSM2D\n\nAn abstract type for the lognormal race model\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractMDFT","page":"API","title":"SequentialSamplingModels.AbstractMDFT","text":"AbstractMDFT <: SSM2D\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractMLBA","page":"API","title":"SequentialSamplingModels.AbstractMLBA","text":"AbstractMLBA{T, T1} <: AbstractLBA\n\nAn abstract type for the multi-attribute linear ballistic accumulator\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractPoissonRace","page":"API","title":"SequentialSamplingModels.AbstractPoissonRace","text":"AbstractPoissonRace <: SSM2D\n\nAn abstract type for the Poisson race model.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractRDM","page":"API","title":"SequentialSamplingModels.AbstractRDM","text":"AbstractRDM <: SSM2D\n\nAn abstract type for the racing diffusion model.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractShiftedLogNormal","page":"API","title":"SequentialSamplingModels.AbstractShiftedLogNormal","text":"AbstractShiftedLogNormal <: SSM1D\n\nAn abstract type for the shifted lognormal model.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractWald","page":"API","title":"SequentialSamplingModels.AbstractWald","text":"AbstractWald <: SSM1D\n\nAn abstract type for the Wald model.  \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractaDDM","page":"API","title":"SequentialSamplingModels.AbstractaDDM","text":"AbstractaDDM <: SSM2D\n\nAn abstract type for the attentional drift diffusion model.  \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.AbstractstDDM","page":"API","title":"SequentialSamplingModels.AbstractstDDM","text":"AbstractstDDM <: SSM2D\n\nAn abstract type for the starting-time diffusion decision model.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.CDDM","page":"API","title":"SequentialSamplingModels.CDDM","text":"CDDM{T<:Real} <: AbstractCDDM\n\nA circular drift diffusion model (CDDM) for continous responding. CCDM is typically applied to continous report of color in visual working memory tasks. Currently supports the 2D case. \n\nParameters\n\nν::T: a vector drift rates. ν₁ is the mean drift rate along the x-axis; ν₂ is the mean drift rate along the y-axis. ν ∈ ℝⁿ.\nσ::T: intra-trial drift rate variability. σ ∈ ℝ.\nη::T: a vector across-trial standard deviations of  drift rates. η₁ is the standard deviation of drift rate along the x-axis;    η₂ is the standard deviation of drift rate along the y-axis. η ∈ ℝⁿ⁺.\nα::T: response boundary as measured by the radius of a circle. α ∈ ℝ⁺.\nτ::T: mean non-decision time. τ ∈ [0, min_rt]. \n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nCDDM(ν, σ, η, α, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nCDDM(; ν=[1,.5], η=[1,1], σ=1, α=1.5, τ=0.30)\n\nExample\n\nusing SequentialSamplingModels\ndist = CDDM(;ν=[1,.5], η=[1,1], σ=1, α=1.5, τ=0.30)\ndata = rand(dist, 10)\nlike = pdf(dist, data)\nloglike = logpdf(dist, data)\n\nReferences\n\nSmith, P. L. (2016). Diffusion theory of decision making in continuous report. Psychological Review, 123(4), 425.\n\nSmith, P. L., Garrett, P. M., & Zhou, J. (2023). Obtaining Stable Predicted Distributions of Response Times and Decision Outcomes for the Circular Diffusion Model.  Computational Brain & Behavior, 1-13.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.ClassicMDFT","page":"API","title":"SequentialSamplingModels.ClassicMDFT","text":"ClassicMDFT{T <: Real} <: AbstractMDFT\n\nA model type for Multiattribute Decision Field Theory. \n\nParameters\n\nσ::T = 1.0: diffusion noise. σ ∈ ℝ⁺. \nα::T = 15.0: evidence threshold. α  ∈ ℝ⁺.\nτ::T = .30: non-decision time. τ ∈ [0, min_rt].\nw::Vector{T}: attention weights vector where each element corresponds to the attention given to the corresponding dimension. wᵢ ∈ [0,1], ∑wᵢ = 1.\nS::Array{T, 2}: feedback matrix allowing self-connections and interconnections between alternatives. Self-connections range from zero to 1, where sij < 1 represents decay. Interconnections     between options i and j  where i ≠ j are inhibatory if sij < 0.\nC::Array{T, 2}: contrast weight matrix where c_ij is the contrast weight when comparing options i and j.\n\nConstructors\n\nClassicMDFT(σ, α, τ, w, S, C)\n\nClassicMDFT(σ, α, τ, w, S, C = make_default_contrast(S))\n\nExample\n\nAn example of the similarity effect. When choosing between options 1 and 2, the model predicts equal preference  because the options fall along the diagonal of attribute space, signifying a 1 to 1 trade-off of equally weighted  attributes. Option 3 is introduced to the choice set, which is similar to (and competitive with) option 1 and disimilar to option 2. In this case, the model predicts an increase the choice probability for option 2 relative to option 1.\n\n# value matrix where rows correspond to alternatives, and columns correspond to attributes\nM = [\n    1.0 3.0\n    3.0 1.0\n    0.9 3.1\n]\n\nmodel = ClassicMDFT(;\n    # non-decision time \n    τ = 0.300,\n    # diffusion noise \n    σ = 1.0,\n    # decision threshold\n    α = 17.5,\n    # attribute attention weights \n    w = [0.5, 0.5],\n    # feedback matrix \n    S = [\n        0.9500000 -0.0122316 -0.04999996\n        -0.0122316 0.9500000 -0.00903030\n        -0.0499996 -0.0090303 0.95000000\n    ],\n)\nchoices, rts = rand(model, 10_000, M; Δt = 1.0)\nmap(c -> mean(choices .== c), 1:3)\n\nReferences\n\nRoe, Robert M., Jermone R. Busemeyer, and James T. Townsend. \"Multiattribute Decision Field Theory: A dynamic connectionst model of decision making.\" Psychological review 108.2 (2001): 370.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.ContinuousMultivariateSSM","page":"API","title":"SequentialSamplingModels.ContinuousMultivariateSSM","text":"ContinuousMultivariateSSM <: ContinuousMultivariateDistribution\n\nAn abstract type for continuous multivariate sequential sampling models e.g., a circular drift diffusion model.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.DDM","page":"API","title":"SequentialSamplingModels.DDM","text":"DDM{T<:Real} <: SSM2D\n\nModel object for the standard Drift Diffusion Model.\n\nParameters\n\nν::T: drift rate. Average slope of the information accumulation process. The drift gives information about the speed and direction of the accumulation of information. ν ∈ ℝ. Typical range: ν ∈ [-5,5].\nα::T: boundary threshold separation. The amount of information that is considered for a decision. α ∈ ℝ⁺. Typical range: α ∈ [.5, 2].\nz::T: starting point. Indicator of an an initial bias towards a decision. The z ∈ [0,1] parameter is relative to α.\nτ::T: non-decision time. The duration for a non-decisional processes (encoding and response execution). τ ∈ [0, min_rt]. Typical range: τ ∈ [.1,.5].\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nDDM(ν, α, z, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nDDM(; ν = 1.00, α = 0.80, τ = 0.30, z = 0.50)\n\nExample\n\nusing SequentialSamplingModels\ndist = DDM(ν = 1.0, α = 0.8, τ = 0.3, z = 0.25) \nchoice,rt = rand(dist, 10)\nlike = pdf.(dist, choice, rt)\nloglike = logpdf.(dist, choice, rt)\n\nReferences\n\nRatcliff, R., & McKoon, G. (2008). The Diffusion Decision Model: Theory and Data for Two-Choice Decision Tasks. Neural Computation, 20(4), 873–922.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.ExGaussian","page":"API","title":"SequentialSamplingModels.ExGaussian","text":"ExGaussian{T<:Real} <: SSM1D\n\nThe Ex-Gaussian is a convolution of the Gaussian and exponential distribution sometimes used  to model reaction time distributions. Note that this is not technically a sequential sampling model. \n\nParameters\n\nμ::T: mean of Gaussian component. μ ∈ ℝ⁺.\nσ::T: standard deviation of Gaussian component. σ ∈ ℝ⁺\nτ::T: mean of exponential component. τ ∈ [0, min_rt]\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nExGaussian(μ, σ, τ)\n\nThe second constructor uses kewords, and is not order dependent: \n\nExGaussian(;μ=.5, σ=.20, τ=.20)\n\nExample\n\nusing SequentialSamplingModels\ndist = ExGaussian(;μ=.5, σ=.20, τ=.20) \nrt = rand(dist, 10)\nlike = pdf.(dist, rt)\nloglike = logpdf.(dist, rt)\n\nReferences\n\nMatzke, D., & Wagenmakers, E. J. (2009). Psychological interpretation of the ex-Gaussian and shifted Wald parameters:  A diffusion model analysis. Psychonomic Bulletin & Review, 16, 798-817.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.LBA","page":"API","title":"SequentialSamplingModels.LBA","text":"LBA{T <: Real, T1 <: Union{<: T, Vector{<: T}}} <: AbstractLBA\n\nA model object for the linear ballistic accumulator.\n\nParameters\n\nν::Vector{T}: a vector of drift rates. α ∈ ℝ⁺.\nσ::T1: a scalar or vector of drift rate standard deviation. σ ∈ ℝ⁺.\nA::T: max start point. A ∈ ℝ⁺.\nk::T: A + k = b, where b is the decision threshold. k ∈ ℝ⁺.\nτ::T: an encoding-response offset. τ ∈ [0, min_rt].\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nLBA(ν, σ, A, k, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nLBA(;τ = .3, A = .8, k = .5, ν = [2.0,1.75], σ = 1)\n\nExample\n\nusing SequentialSamplingModels\ndist = LBA(ν=[3.0,2.0], A = .8, k = .2, τ = .3) \nchoice,rt = rand(dist, 10)\nlike = pdf.(dist, choice, rt)\nloglike = logpdf.(dist, choice, rt)\n\nReferences\n\nBrown, S. D., & Heathcote, A. (2008). The simplest complete model of choice response time: Linear ballistic accumulation. Cognitive psychology, 57(3), 153-178.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.LCA","page":"API","title":"SequentialSamplingModels.LCA","text":"LCA{T<:Real} <: AbstractLCA\n\nA model type for the Leaky Competing Accumulator. \n\nParameters\n\nν::Vector{T}: drift rates \nσ::T: diffusion noise \nβ::T: lateral inhabition \nλ::T: leak rate\nα::T: evidence threshold \nτ::T: non-decision time. τ ∈ [0, min_rt] \n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nLCA(ν, σ, β, λ, α, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nLCA(; ν = [2.5, 2.0], σ = 1.0, β = 0.20, λ = 0.10, α = 1.5, τ = 0.30)\n\nExample\n\nusing SequentialSamplingModels \nν = [2.5,2.0]\nα = 1.5\nβ = 0.20\nλ = 0.10 \nσ = 1.0\nτ = 0.30\n\ndist = LCA(; ν, α, β, λ, τ, σ)\nchoices,rts = rand(dist, 500)\n\nReferences\n\nUsher, M., & McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. Psychological Review, 108 3, 550–592. https://doi.org/10.1037/0033-295X.108.3.550\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.LNR","page":"API","title":"SequentialSamplingModels.LNR","text":"LNR{T <: Real, T1 <: Union{<:T, Vector{<:T}}} <: AbstractLNR{T, T1}\n\nParameters\n\nν::Vector{T}: a vector of means in log-space. ν ∈ ℝⁿ.\nσ::T1: a scalar or vector of standard deviation parameter in log-space. σ ∈ ℝ⁺.\nτ::T: a encoding-response offset. τ ∈ [0, min_rt].\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nLNR(ν, σ, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nLNR(; ν = [-1, -2], σ = 1, τ = 0.20)\n\nExample\n\nusing SequentialSamplingModels\ndist = LNR(ν = [-2,-3], σ = 1, τ = .3)\nchoice,rt = rand(dist, 10)\nlike = pdf.(dist, choice, rt)\nloglike = logpdf.(dist, choice, rt)\n\nReferences\n\nRouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015).  The lognormal race: A cognitive-process model of choice and latency with desirable  psychometric properties. Psychometrika, 80(2), 491-513.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.MDFT","page":"API","title":"SequentialSamplingModels.MDFT","text":"MDFT{T <: Real} <: AbstractMDFT\n\nA model type for simulating Multi-attribute Decision Field Theory (MDFT) as an Stochastic Differential Equation (SDE). \n\nParameters\n\nσ::T = 1.0: diffusion noise. σ ∈ ℝ⁺. \nα::T = 15.0: evidence threshold. α ∈ ℝ⁺.\nτ::T = .30: non-decision time. τ ∈ [0, min_rt].\nγ::T: scales the valance, CMW, functioning like a drift rate. γ ∈ ℝ⁺.\nκ::Vector{T}: exponential rate parameters for switching attention between attributes. Currently, limited to two    attributes. κ ∈ ℝ⁺.\nϕ1::T: controls the sensitivity of lateral inhibition to distance in the distance function for creating the feedback matrix, S. ϕ1 ∈ ℝ⁺.\nϕ2::T: controls evidence decay and maximum inhibition in the distance function for creating the feedback matrix, S. ϕ2 ∈ ℝ⁺.\nβ::T: controls the weight of the dominance dimension in the feedback matrix distance function. If β < 0, the indifference dimension    recieves more where. If β > 0, the dominance dimension recieves more weight\nS::Array{T, 2}: feedback matrix allowing self-connections and interconnections between alternatives. Self-connections range from zero to 1, where sij < 1 represents decay. Interconnections     between options i and j where i ≠ j are inhibitory if sij < 0.\nC::Array{T, 2}: contrast weight matrix for comparing attended alternative to other alternatives.   The element c_ij is the contrast weight when comparing options i and j.\n\nConstructors\n\nMDFT(σ, α, τ, γ, κ, ϕ1, ϕ2, β, C)\n\nMDFT(;\n    n_alternatives,\n    σ,\n    α,\n    τ,\n    γ,\n    κ,\n    ϕ1,\n    ϕ2,\n    β,\n    C = make_default_contrast(n_alternatives)\n)\n\nExample\n\nAn example of the similarity effect. When choosing between options 1 and 2, the model predicts equal preference  because the options fall along the diagonal of attribute space, signifying a 1 to 1 trade-off of equally weighted  attributes. Option 3 is introduced to the choice set, which is similar to (and competitive with) option 1 and disimilar to option 2. In this case, the model predicts a reversal of preference between options 1 and 2.\n\nusing SequentialSamplingModels\n\nmodel = MDFT(;\n    n_alternatives = 3,\n    σ = 0.1,\n    α = .50,\n    τ = 0.0,\n    γ = 1.0,\n    κ = [6.0, 5.0],\n    ϕ1 = 0.01,\n    ϕ2 = 0.10,\n    β = 10.0\n)\n# value matrix where rows correspond to alternatives, and columns correspond to attributes\nM = [\n    1.0 3.0\n    3.0 1.0\n    0.9 3.1\n]\n\nchoices, rts = rand(model, 10_000, M)\nprobs = map(c -> mean(choices .== c), 1:3)\n\nReferences\n\nEvans, N. J., Holmes, W. R., & Trueblood, J. S. (2019). Response-time data provide critical constraints on dynamic models of multi-alternative, multi-attribute choice. Psychonomic Bulletin & Review, 26, 901-933.\n\nHotaling, J. M., Busemeyer, J. R., & Li, J. (2010). Theoretical developments in decision field theory: Comment on tsetsos, usher, and chater (2010). Psychological Review, 117 , 1294-1298.\n\nRoe, Robert M., Jermone R. Busemeyer, and James T. Townsend. \"Multi-attribute Decision Field Theory: A dynamic connectionst model of decision making.\" Psychological review 108.2 (2001): 370.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.MLBA","page":"API","title":"SequentialSamplingModels.MLBA","text":"MLBA{T <: Real, T1 <: Union{<: T, Vector{<: T}}} <: AbstractMLBA{T,T1}\n\nFields\n\nν::Vector{T}: a vector of drift rates, which is a function of β₀, λₚ, λₙ, γ. ν ∈ ℝⁿ.\nβ₀::T: baseline input for drift rate. β₀ ∈ ℝ. \nλₚ::T: decay constant for attention weights of positive differences. λₚ ∈ ℝ⁺.\nλₙ::T: decay constant for attention weights of negative differences. λₙ ∈ ℝ⁺.\nγ::T: risk aversion exponent for subjective values. γ ∈ ℝ⁺.\nσ::T1: a scalar or vector of drift rate standard deviation. σ ∈ ℝ⁺.\nA::T: max start point. A ∈ ℝ⁺.\nk::T: A + k = b, where b is the decision threshold. k ∈ ℝ⁺.\nτ::T: an encoding-response offset. τ ∈ [0, min_rt].\n\nConstructors\n\nMLBA(ν, β₀, λₚ, λₙ, γ, σ, A, k, τ)\n\nMLBA(;\n    n_alternatives = 3,\n    ν = fill(0.0, n_alternatives),\n    β₀ = 5.0,\n    λₚ = 0.20,\n    λₙ = 0.40,\n    γ = 5.0,\n    τ = 0.3,\n    A = 1.0,\n    k = 1.0,\n    σ = 1.0\n)\n\nExample\n\nusing SequentialSamplingModels\n\ndist = MLBA(\n    λₚ = 0.20,\n    λₙ = 0.40,\n    β₀ = 5,\n    γ = 5,\n    τ = 0.3,\n    A = 0.8,\n    k = 0.5\n)\n\nM = [\n    1 4\n    2 2\n    4 1\n]\n\nchoice, rt = rand(dist, 1000, M)\nlike = pdf.(dist, choice, rt, (M,))\nloglike = logpdf.(dist, choice, rt, (M,))\n\nReferences\n\nTrueblood, J. S., Brown, S. D., & Heathcote, A. (2014). The multiattribute linear ballistic accumulator model of context effects in multialternative choice. Psychological Review, 121(2), 179.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.PoissonRace","page":"API","title":"SequentialSamplingModels.PoissonRace","text":"PoissonRace{T<:Real} <: AbstractPoissonRace\n\nParameters\n\nν::T: gamma scale parameter. ν ∈ ℝ⁺.\nα::T: threshold. α ∈ ℝ⁺\nτ::T: a encoding-response offset. τ ∈ [0, min_rt].\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nPoissonRace(ν, α, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nPoissonRace(;ν=[.05,.06], α=[5,5], τ=.3)\n\nExample\n\nusing SequentialSamplingModels\ndist = PoissonRace(ν=[.05,.06], α=[5,5], τ=.3)\nchoice,rt = rand(dist, 10)\nlike = pdf.(dist, choice, rt)\nloglike = logpdf.(dist, choice, rt)\n\nReferences\n\nLaBerge, D. A. (1962). A recruitment model of simple behavior. Psychometrika, 27, 375-395.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.RDM","page":"API","title":"SequentialSamplingModels.RDM","text":"RDM{T<:Real} <: AbstractRDM\n\nAn object for the racing diffusion model.\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nRDM(ν, k, A, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nRDM(;ν=[1,2], k=.3, A=.7, τ=.2)\n\nParameters\n\nν::T: a vector of drift rates. ν ∈ ℝⁿ.\nA::T: the maximum starting point diffusion process, sampled from Uniform distribution. A ∈ ℝ⁺\nk::T: k = b - A where b is the decision threshold, and A is the maximum starting point. k ∈ ℝ⁺\nτ::T: a encoding-motor time offset. τ ∈ [0, min_rt].\n\nExample\n\nusing SequentialSamplingModels\ndist = RDM(;ν=[1,2], k=.3, A=.7, τ=.2)\nchoice,rt = rand(dist, 10)\nlike = pdf.(dist, choice, rt)\nloglike = logpdf.(dist, choice, rt)\n\nReferences\n\nTillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability:  The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27, 911-936.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.SSM1D","page":"API","title":"SequentialSamplingModels.SSM1D","text":"SSM1D <: ContinuousUnivariateDistribution\n\nAn abstract type for sequential sampling models characterized by a single choice reaction time distribution. Sub-types of SSM1D output a vector of reaction times.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.SSM2D","page":"API","title":"SequentialSamplingModels.SSM2D","text":"SSM2D = Distribution{Multivariate, Mixed}\n\nAn abstract type for sequential sampling models characterized by a multivariate choice-reaction time distribution. Sub-types of SSM2D output a NamedTuple consisting of a vector of choices and reaction times. \n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.ShiftedLogNormal","page":"API","title":"SequentialSamplingModels.ShiftedLogNormal","text":"ShiftedLogNormal{T <: Real} <: AbstractShiftedLogNormal\n\nA special case of the lognormal race (LNR) model for a single response. The first passage time is lognormally distributed.\n\nParameters\n\nν::T: mean finishing time in log-space. ν ∈ ℝ. \nσ::T: standard deviation parameter in log-space. σ ∈ ℝ⁺.\nτ::T: a encoding-response offset. τ ∈ [0, min_rt].\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nShiftedLogNormal(ν, σ, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nShiftedLogNormal(; ν = -1, σ=.5, τ = .20)\n\nExample\n\nusing SequentialSamplingModels\ndist = ShiftedLogNormal(ν = -1, σ=.5, τ = .20)\nrts = rand(dist, 10)\nlike = pdf.(dist, rts)\nloglike = logpdf.(dist, rts)\n\nReferences\n\nHeathcote, A., & Bohlscheid, E. Analysis and Modeling of Response Time using the Shifted Lognormal Distribution.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.Wald","page":"API","title":"SequentialSamplingModels.Wald","text":"Wald{T<:Real} <: AbstractWald\n\nA model object for the Wald model, also known as the inverse Gaussian model.\n\nParameters\n\nν: drift rate. ν ∈ ℝ⁺. \nα: decision threshold. α ∈ ℝ⁺\nτ: a encoding-response offset. τ ∈ [0, min_rt]\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nWald(ν, α, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nWald(;ν=1.5, α=.50, τ=0.20)\n\nExample\n\nusing SequentialSamplingModels\ndist = Wald(ν=3.0, α=.5, τ=.130)\nrt = rand(dist, 10)\nlike = pdf.(dist, rt)\nloglike = logpdf.(dist, rt)\n\nReferences\n\nAnders, R., Alario, F., & Van Maanen, L. (2016). The shifted Wald distribution for response time data analysis. Psychological methods, 21(3), 309.\n\nFolks, J. L., & Chhikara, R. S. (1978). The inverse Gaussian distribution and its statistical application—a review. Journal of the Royal Statistical Society Series B: Statistical Methodology, 40(3), 263-275.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.WaldMixture","page":"API","title":"SequentialSamplingModels.WaldMixture","text":"WaldMixture{T<:Real} <: AbstractWald\n\nParameters\n\nυ: drift rate. ν ∈ ℝ⁺. \nη: standard deviation of drift rate. ν ∈ ℝ⁺.\nα: decision threshold. α ∈ ℝ⁺.\nτ: a encoding-response offset. τ ∈ [0, min_rt]\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nWaldMixture(ν, η, α, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nWaldMixture(;ν=3.0, η=.2, α=.5, τ=.130)\n\nExample\n\nusing SequentialSamplingModels\ndist = WaldMixture(;ν=3.0, η=.2, α=.5, τ=.130)\nrt = rand(dist, 10)\nlike = pdf.(dist, rt)\nloglike = logpdf.(dist, rt)\n\nReferences\n\nSteingroever, H., Wabersich, D., & Wagenmakers, E. J. (2020).  Modeling across-trial variability in the Wald drift rate parameter.  Behavior Research Methods, 1-17.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.aDDM","page":"API","title":"SequentialSamplingModels.aDDM","text":"aDDM{T<:Real} <: AbstractaDDM\n\nAn object for the attentional diffusion model. \n\nParameters\n\nν::Vector{T}: relative decision values (i.e., drift rates). ν ∈ ℝⁿ.\nσ::T: standard deviation of noise in evidence accumulation. σ ∈ ℝ.\nΔ::T: constant of evidence accumulation speed (evidence per ms). Δ ∈ ℝ.\nα::T: evidence threshold. α ∈ ℝ.  \nz::T: initial evidence. z ∈ [0, α] \nθ::T: bias towards attended alternative (lower indicates more bias)\nτ::T: non-decision time. τ ∈ [0, min_rt]\n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\naDDM(ν, σ, Δ, θ, α, z, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\naDDM(;ν=[5.0,4.0], α=1.0, z=α*.5, θ=.3, σ=.02, Δ=.0004, τ=0.0)\n\nExample\n\nusing SequentialSamplingModels\nusing StatsBase\n\nmutable struct Transition\n    state::Int \n    n::Int\n    mat::Array{Float64,2} \n end\n\n function Transition(mat)\n    n = size(mat,1)\n    state = rand(1:n)\n    return Transition(state, n, mat)\n end\n \n function fixate(transition)\n     (;mat,n,state) = transition\n     w = @view mat[state,:]\n     next_state = sample(1:n, Weights(w))\n     transition.state = next_state\n     return next_state\n end\n\n model = aDDM()\n \n tmat = Transition([.98 .015 .005;\n                    .015 .98 .005;\n                    .45 .45 .1])\n\n choices,rts = rand(model, 100, tmat; fixate)\n\nReferences\n\nKrajbich, I., Armel, C., & Rangel, A. (2010). Visual fixations and the computation and comparison of  value in simple choice. Nature neuroscience, 13(10), 1292-1298.\n\n\n\n\n\n","category":"type"},{"location":"api/#SequentialSamplingModels.maaDDM","page":"API","title":"SequentialSamplingModels.maaDDM","text":"maaDDM{T<:Real} <: AbstractaDDM\n\nAn object for the multi-attribute attentional drift diffusion model. \n\nConstructors\n\nTwo constructors are defined below. The first constructor uses positional arguments, and is therefore order dependent:\n\nmaaDDM(ν, σ, Δ, θ, ϕ, ω, α, z, τ)\n\nThe second constructor uses keywords with default values, and is not order dependent: \n\nmaaDDM(;\n    ν = [4.0 5.0; 5.0 4.0],\n    α = 1.0,\n    z = 0.0,\n    θ = 0.3,\n    ϕ = 0.50,\n    ω = 0.70,\n    σ = 0.02,\n    Δ = 0.0004,\n    τ = 0.0,\n)\n\nIn this version of the model, the non-attended attribute of the non-attended alternative is doubly discounted. For example, the mean drift rate for the attribute 1 of alternative 1 is given by:\n\n    Δ * (ω * (ν[1,1] - θ * ν[2,1]) + (1 - ω) * ϕ * (ν[1,2] - θ * ν[2,2]))\n\nKeywords\n\nν::T: drift rates where rows are alternatives and columns are attributes. ν ∈ ℝⁿᵐ.\nσ::T: standard deviation of noise in evidence accumulation. σ ∈ ℝ.\nΔ::T: constant of evidence accumulation speed (evidence per ms). Δ ∈ ℝ.\nθ::T: bias away from unattended alternative (lower indicates more bias). θ ∈ [0,1].\nϕ::T: bias away from unattended attribute. ϕ ∈ [0,1]. \nω::T: attribute weight. ω ∈ [0,1].\nα::T: evidence threshold. α ∈ ℝ⁺. \nz::T: initial evidence. z ∈ [0, α]\nτ::T: non-decision time. τ ∈ [0, min_rt].\n\nExample\n\nusing SequentialSamplingModels\nusing StatsBase\n\nmutable struct Transition\n    state::Int \n    n::Int\n    mat::Array{Float64,2} \n end\n\n function Transition(mat)\n    n = size(mat,1)\n    state = rand(1:n)\n    return Transition(state, n, mat)\n end\n \n function attend(transition)\n     (;mat,n,state) = transition\n     w = @view mat[state,:]\n     next_state = sample(1:n, Weights(w))\n     transition.state = next_state\n     return next_state\n end\n\nν = [4.0 5.0; 5.0 4.0]\nα = 1.0 \nz = 0.0\nθ = .3\nϕ = .50\nω = .70\nσ = .02\nΔ = .0004\nτ = 0.0\n\ndist = maaDDM(; ν, σ, Δ, θ, ϕ, ω, α, z, τ)\n\ntmat = Transition([.98 .015 .0025 .0025;\n                .015 .98 .0025 .0025;\n                .0025 .0025 .98 .015;\n                .0025 .0025 .015 .98])\n\n choices,rts = rand(dist, 100, attend, tmat)\n\nReferences\n\nYang, X., & Krajbich, I. (2023). A dynamic computational model of gaze and choice in multi-attribute decisions.  Psychological Review, 130(1), 52.\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractLCA, Int64}","page":"API","title":"Base.rand","text":"rand(dist::AbstractLCA, n_sim::Int; Δt = 0.001)\n\nGenerate n_sim random choice-rt pairs for the Leaky Competing Accumulator.\n\nArguments\n\ndist: model object for the Leaky Competing Accumulator.\nn_sim::Int: the number of simulated choice-rt pairs \n\nKeywords\n\nΔt = 0.001: time step size\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractLCA}","page":"API","title":"Base.rand","text":"rand(dist::AbstractLCA; Δt = 0.001)\n\nGenerate a random choice-rt pair for the Leaky Competing Accumulator.\n\nArguments\n\ndist: model object for the Leaky Competing Accumulator. \nΔt = 0.001: time step size \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractMLBA, AbstractArray}","page":"API","title":"Base.rand","text":"rand(rng::AbstractRNG, d::AbstractMLBA, M::AbstractArray)\n\nGenerates a single choice-rt pair of simulated data from the Multi-attribute Linear Ballistic Accumulator.\n\nArguments\n\ndist::AbstractMLBA: an object for the multi-attribute linear ballistic accumulator\nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractMLBA, Int64, AbstractArray}","page":"API","title":"Base.rand","text":"rand(rng::AbstractRNG, d::AbstractMLBA, n_trials::Int, M::AbstractArray)\n\nGenerates n_trials choice-rt pair of simulated data from the Multi-attribute Linear Ballistic Accumulator.\n\nArguments\n\ndist::AbstractMLBA: an object for the multi-attribute linear ballistic accumulator\nn_trials::Int: the number of trials to simulate\nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractaDDM, Int64, Vararg{Any}}","page":"API","title":"Base.rand","text":"rand(\n    rng::AbstractRNG,\n    dist::AbstractaDDM,\n    n_sim::Int,\n    fixate::Function, \n    args...;\n    rand_state! = _rand_state!,\n    Δt = .001,\n    kwargs...\n)\n\nGenerate n_sim simulated trials from the attention diffusion model.\n\nArguments\n\nrng: a random number generator\ndist: an attentional diffusion model object\nn_sim::Int: the number of simulated trials\nfixate: a function of the visual fixation process which returns 1 for alternative    and 2 for alternative 2\nargs...: optional positional arguments for the fixate function\n\nKeywords\n\nrand_state! = _rand_state!: initialize first state with equal probability \n\nkwargs...: optional keyword arguments for the fixate function\nΔt = .001: time step\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractaDDM, Vararg{Any}}","page":"API","title":"Base.rand","text":"rand(\n    rng::AbstractRNG, \n    dist::AbstractaDDM, \n    fixate::Function, args...; \n    rand_state! = _rand_state!, \n    Δt = .001,\n    kwargs...\n)\n\nGenerate a single simulated trial from the attentional diffusion model.\n\nArguments\n\nrng: a random number generator\ndist: an attentional diffusion model object\nfixate: a function of the visual fixation process which returns 1 for alternative    and 2 for alternative 2\nargs...: optional positional arguments for the fixate function\n\nKeywords\n\nkwargs...: optional keyword arguments for the fixate function\nΔt = .001: time step\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, AbstractstDDM}","page":"API","title":"Base.rand","text":"rand(dist::AbstractstDDM)\n\nGenerate a random choice-rt pair for starting-time diffusion decision model.\n\nArguments\n\nrng: a random number generator\ndist: model object for the starting-time diffusion decision model. \nΔt: time-step for simulation\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, ClassicMDFT, Int64, AbstractArray}","page":"API","title":"Base.rand","text":"rand(\n    rng::AbstractRNG,\n    dist::AbstractMDFT,\n    n_sim::Int,\n    M::AbstractArray;\n    Δt = 0.001\n)\n\nGenerate n_sim random choice-rt pairs for the Multiattribute Decision Field Theory (MDFT).\n\nArguments\n\nrng::AbstractRNG: a random number generator which is a subtype of AbstractRNG\ndist::AbstractMDFT: model object for the Multiattribute Decision Field Theory (MDFT).\nn_sim::Int: the number of simulated choice-rt pairs\nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\nKeywords\n\nΔt = 0.001: time step size\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, DDM}","page":"API","title":"Base.rand","text":"rand(dist::DDM)\n\nGenerate a random rt for the Diffusion Decision Model (negative coding)\n\nArguments\n\ndist: model object for the Diffusion Decision Model. \n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, MDFT, Int64, AbstractArray}","page":"API","title":"Base.rand","text":"rand(\n    rng::AbstractRNG,\n    dist::MDFT,\n    n_sim::Int,\n    M::AbstractArray;\n    Δt = 0.001\n)\n\nGenerate n_sim random choice-rt pairs for the Multi-attribute Decision Field Theory (MDFT).\n\nArguments\n\nrng::AbstractRNG: a random number generator which is a subtype of AbstractRNG\ndist::MDFT: model object for the Multi-attribute Decision Field Theory (MDFT).\nn_sim::Int: the number of simulated choice-rt pairs\nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\nKeywords\n\nΔt = 0.001: time step size\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.rand-Tuple{Random.AbstractRNG, MultivariateDistribution{SequentialSamplingModels.Mixed}, Int64}","page":"API","title":"Base.rand","text":"rand(rng::AbstractRNG, d::SSM2D, N::Int; kwargs...)\n\nDefault method for Generating n_sim random choice-rt pairs from a sequential sampling model  with more than one choice option.\n\nArguments\n\nd::SSM2D: a 2D sequential sampling model.\nn_trials::Int: the number of simulated choices and rts  \n\nKeywords\n\nkwargs...: optional keyword arguments \n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.cdf-Tuple{MultivariateDistribution{SequentialSamplingModels.Mixed}, Int64, Real, Vararg{Any}}","page":"API","title":"Distributions.cdf","text":"cdf(d::SSM2D, choice::Int, ub=10)\n\nComputes the cumulative density for a given choice. The cumulative density is based on  an analytic formula, a numeric integration of pdf, or Monte Carlo simulation, depending on which is  available for a given model. \n\nArguments\n\nd::SSM2D: a 2D sequential sampling model.\nchoice::Int: the number of simulated choices and rts  \nub::Real: upper bound of integration\nargs...: optional arguments passed to rand\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.cdf-Tuple{Random.AbstractRNG, AbstractaDDM, Int64, Any, Vararg{Any}}","page":"API","title":"Distributions.cdf","text":"cdf(\n    rng::AbstractRNG, \n    d::AbstractaDDM, \n    choice::Int, \n    fixate::Function, \n    ub, \n    args...; \n    n_sim=10_000, \n    kwargs...\n)\n\nComputes the approximate cumulative probability density of AbstractaDDM using Monte Carlo simulation.\n\nArguments\n\ndist: an attentional diffusion model object\nchoice: the choice on which the cumulative density is computed\nfixate: a function of the visual fixation process which returns 1 for alternative    and 2 for alternative 2\nub::Int: the upper bound of the integral\nargs...: optional positional arguments for the fixate function\n\nKeywords\n\nn_sim::Int=10_000: the number of simulated trials\n\nrand_state! = _rand_state!: initialize first state with equal probability \n\nkwargs...: optional keyword arguments for the fixate function\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.cdf-Tuple{SSM1D, Real}","page":"API","title":"Distributions.cdf","text":"cdf(d::SSM1D, choice::Int, ub=10)\n\nComputes the cumulative density for a given choice. The cumulative density is based on  an analytic formula, a numeric integration of pdf, or Monte Carlo simulation, depending on which is  available for a given model. \n\nArguments\n\nd::SSM1D: a 1D sequential sampling model.\nub: upper bound of integration\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{AbstractMLBA, Int64, Real, AbstractArray}","page":"API","title":"Distributions.logpdf","text":"logpdf(d::AbstractMLBA, c::Int, rt::Real,  M::AbstractArray)\n\nComputes default log probability density for multi-alternative linear ballistic accumulator. \n\nArguments\n\ndist::AbstractMLBA: an object for the multi-attribute linear ballistic accumulator\nc::Int: choice index\nrt::Real: reaction time in seconds \nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.logpdf-Tuple{MultivariateDistribution{SequentialSamplingModels.Mixed}, NamedTuple}","page":"API","title":"Distributions.logpdf","text":"logpdf(d::SSM2D, data::NamedTuple)\n\nComputes the likelihood for a 2D sequential sampling model. \n\nArguments\n\nd::SSM2D: an object for a 2D sequential sampling model \ndata::NamedTuple: a NamedTuple of data containing choice and reaction time \n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{AbstractMLBA, Int64, Real, AbstractArray}","page":"API","title":"Distributions.pdf","text":"pdf(d::AbstractMLBA, c::Int, rt::Real,  M::AbstractArray)\n\nComputes default probability density for multi-alternative linear ballistic accumulator. \n\nArguments\n\ndist::AbstractMLBA: an object for the multi-attribute linear ballistic accumulator\nc::Int: choice index\nrt::Real: reaction time in seconds \nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.pdf-Tuple{MultivariateDistribution{SequentialSamplingModels.Mixed}, NamedTuple, Vararg{Any}}","page":"API","title":"Distributions.pdf","text":"pdf(d::SSM2D, data::NamedTuple)\n\nComputes the probability density for a 2D sequential sampling model. \n\nArguments\n\nd::SSM2D: an object for a 2D sequential sampling model \ndata::NamedTuple: a NamedTuple of data containing choice and reaction time \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.compute_choice_probs-Tuple{NamedTuple}","page":"API","title":"SequentialSamplingModels.compute_choice_probs","text":"compute_choice_probs(data::NamedTuple; choice_set=unique(data.choice))\n\nReturns the choice probabilities for a 2D SSM. \n\nArguments\n\ndata::NamedTuple: a data structure containing discrete choices in the key choice and corresponding \n\nreaction times in key rt\n\nKeywords\n\n`choice_set: a vector of possible choices. \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.compute_quantiles-Tuple{Matrix{<:Real}}","page":"API","title":"SequentialSamplingModels.compute_quantiles","text":"compute_quantiles(data::Array{<:Real,2}; percentiles=.1:.1:.90)\n\nReturns the marginal quantiles for a continous multivariate SSM. \n\ndata::Array{<:Real,2}: an array of continous observations\n\nKeywords\n\npercentiles=.1:.1:.90: percentiles at which to evaluate the quantiles \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.compute_quantiles-Tuple{NamedTuple}","page":"API","title":"SequentialSamplingModels.compute_quantiles","text":"compute_quantiles(data::NamedTuple; choice_set=unique(data.choice), percentiles=.1:.1:.90)\n\nReturns the quantiles for each choice of a 2D SSM. Note there is a chance that a given choice will  have no observations, and thus no quantiles. Such cases will need to be removed or handled in post processing.\n\nArguments\n\ndata::NamedTuple: a data structure containing discrete choices in the key choice and corresponding \n\nreaction times in key rt\n\nKeywords\n\npercentiles=.1:.1:.90: percentiles at which to evaluate the quantiles \nchoice_set=unique(choice): a vector of possible choices. \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.compute_quantiles-Tuple{Vector{<:Real}}","page":"API","title":"SequentialSamplingModels.compute_quantiles","text":"compute_quantiles(data::Vector{<:Real}; percentiles=.1:.1:.90)\n\nReturns the quantiles associated with a vector of reaction times for a single choice SSM.\n\ndata::Vector{<:Real}: a vector of reaction times     \n\nKeywords\n\npercentiles=.1:.1:.90: percentiles at which to evaluate the quantiles \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.n_options-Tuple{DDM}","page":"API","title":"SequentialSamplingModels.n_options","text":"n_options(dist::DDM)\n\nReturns 2 for the number of choice options\n\nArguments\n\nd::DDM: a model object for the drift diffusion model\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.n_options-Tuple{MultivariateDistribution{SequentialSamplingModels.Mixed}}","page":"API","title":"SequentialSamplingModels.n_options","text":"n_options(dist::SSM2D)\n\nReturns the number of choice options based on the length of the drift rate vector ν.\n\nArguments\n\nd::SSM2D: a sub-type of SSM2D\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.n_options-Tuple{SSM1D}","page":"API","title":"SequentialSamplingModels.n_options","text":"n_options(dist::SSM1D)\n\nReturns 1 for the number of choice options\n\nArguments\n\nd::SSM1D: a sub-type of SSM1D\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{AbstractCDDM}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(model::AbstractCDDM; Δt=.001)\n\nReturns a matrix containing evidence samples of the racing diffusion model decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::AbstractCDDM;: a circular drift diffusion model object\n\nKeywords\n\nΔt=.001: size of time step of decision process in seconds\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{MDFT, AbstractArray}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(model::MDFT, M::AbstractArray; Δt = 0.001, _...)\n\nReturns a matrix containing evidence samples of the MDFT decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::MDFT: an MDFT model object\nM::AbstractArray: an alternative × attribute value matrix representing the value of the stimuli \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{MultivariateDistribution{SequentialSamplingModels.Mixed}, Vararg{Any}}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(model::SSM2D, args...; Δt = .001, kwargs...)\n\nReturns a matrix containing evidence samples from a 2D SSM. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::SSM2D: a subtype of a 2D SSM \nargs...: optional positional arguments \n\nKeywords\n\nΔt = .001: size of time step of decision process in seconds\nkwargs...: optional keyword arguments\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{Random.AbstractRNG, AbstractLBA}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(model::AbstractLBA; n_steps=100, _...)\n\nReturns a matrix containing evidence samples of the LBA decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::AbstractLBA: a subtype of AbstractLBA\n\nKeywords\n\nΔt = 0.001: the time step\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{Random.AbstractRNG, AbstractLNR}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(model::AbstractLNR; n_steps=100, _...)\n\nReturns a matrix containing evidence samples of the LBA decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::AbstractLNR: a subtype of AbstractLNR\n\nKeywords\n\nΔt = 0.001: the time step\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{Random.AbstractRNG, AbstractMLBA, AbstractArray}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(rng::AbstractRNG, model::AbstractMLBA, M::AbstractArray; n_steps = 100)\n\nReturns a matrix containing evidence samples of the MLBA decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::AbstractMLBA: a subtype of AbstractMLBA\n\nKeywords\n\nn_steps=100: number of time steps at which evidence is recorded\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{Random.AbstractRNG, AbstractaDDM, Vararg{Any}}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(\n    rng::AbstractRNG, \n    model::AbstractaDDM; \n    fixate, \n    args=(), \n    kwargs=(), \n    Δt = .001,\n    rand_state! = _rand_state!\n)\n\nReturns a matrix containing evidence samples from a subtype of an attentional drift diffusion model decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nrng::AbstractRNG: random number generator \nmodel::AbstractaDDM: an drift diffusion  model object\n\nKeywords\n\nfixate: a function of the visual fixation process which returns 1 for alternative    and 2 for alternative 2\nargs=(): a set of optional positional arguments for the attend function \nkwargs=(): a set of optional keyword arguments for the attend function \nΔt = .001: time step \n\nrand_state! = _rand_state!: initialize first state with equal probability \n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{Random.AbstractRNG, AbstractstDDM}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(rng::AbstractRNG, model::AbstractstDDM; Δt)\n\nReturns a matrix containing evidence samples of the stDDM decision process. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nrng: a random number generator\nmodel::AbstractstDDM: a starting-time diffusion decision model diffusion model object\nΔt: time-step for simulation\n\n\n\n\n\n","category":"method"},{"location":"api/#SequentialSamplingModels.simulate-Tuple{SSM1D, Vararg{Any}}","page":"API","title":"SequentialSamplingModels.simulate","text":"simulate(model::SSM1D, args...; Δt = .001, kwargs...)\n\nReturns a matrix containing evidence samples from a 2D SSM. In the matrix, rows  represent samples of evidence per time step and columns represent different accumulators.\n\nArguments\n\nmodel::SSM1D: a subtype of a 2D SSM \nargs...: optional positional arguments \n\nKeywords\n\nΔt = .001: size of time step of decision process in seconds\nkwargs...: optional keyword arguments\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.loglikelihood-Tuple{MultivariateDistribution{SequentialSamplingModels.Mixed}, NamedTuple}","page":"API","title":"StatsAPI.loglikelihood","text":"loglikelihood(d::SSM2D, data::NamedTuple)\n\nComputes the summed log likelihood for a 2D sequential sampling model. \n\nArguments\n\nd::SSM2D: an object for a 2D sequential sampling model \ndata::NamedTuple: a NamedTuple of data containing choice and reaction time \n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.loglikelihood-Tuple{SSM1D, AbstractVector{<:Real}}","page":"API","title":"StatsAPI.loglikelihood","text":"loglikelihood(d::SSM1D, data::AbstractArray{T, 1})\n\nComputes the summed log likelihood for a 1D sequential sampling model. \n\nArguments\n\nd::SSM2D: an object for a 2D sequential sampling model \ndata::AbstractVector{<:Real}: a vector of reaction times\n\n\n\n\n\n","category":"method"},{"location":"wald/#Wald-Model","page":"Wald","title":"Wald Model","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"The Wald model, also known as the inverse Gaussian, a sequential sampling model for single choice decisions. It is formally equivalent to a drift diffusion model with one decision threshold and no starting point or across Plots drift rate variability.","category":"page"},{"location":"wald/#Example","page":"Wald","title":"Example","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"In this example, we will demonstrate how to use the Wald model in a generic single choice decision task. ","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"wald/#Load-Packages","page":"Wald","title":"Load Packages","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"The first step is to load the required packages.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"wald/#Create-Model-Object","page":"Wald","title":"Create Model Object","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"In the code below, we will define parameters for the Wald Model and create a model object to store the parameter values. ","category":"page"},{"location":"wald/#Drift-Rate","page":"Wald","title":"Drift Rate","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"The parameter nu represents the evidence accumulation rate.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"ν = 3.0","category":"page"},{"location":"wald/#Threshold","page":"Wald","title":"Threshold","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"The parameter alpha the amount of evidence required to make a decision.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"α = 0.50","category":"page"},{"location":"wald/#Non-Decision-Time","page":"Wald","title":"Non-Decision Time","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"τ = 0.130","category":"page"},{"location":"wald/#Wald-Constructor","page":"Wald","title":"Wald Constructor","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"Now that values have been asigned to the parameters, we will pass them to Wald to generate the model object.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"dist = Wald(ν, α, τ)","category":"page"},{"location":"wald/#Simulate-Model","page":"Wald","title":"Simulate Model","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"rts = rand(dist, 1000)","category":"page"},{"location":"wald/#Compute-PDF","page":"Wald","title":"Compute  PDF","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"pdf.(dist, rts)","category":"page"},{"location":"wald/#Compute-Log-PDF","page":"Wald","title":"Compute Log PDF","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"logpdf.(dist, rts)","category":"page"},{"location":"wald/#Compute-CDF","page":"Wald","title":"Compute CDF","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"The cumulative probability density Pr(T leq t) is computed by passing the model and a value t to cdf.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"cdf(dist, .4)","category":"page"},{"location":"wald/#Plot-Simulation","page":"Wald","title":"Plot Simulation","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"The code below overlays the PDF on reaction time histogram.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"histogram(dist)\nplot!(dist; t_range=range(.130, 1, length=100))","category":"page"},{"location":"wald/#References","page":"Wald","title":"References","text":"","category":"section"},{"location":"wald/","page":"Wald","title":"Wald","text":"Anders, R., Alario, F., & Van Maanen, L. (2016). The shifted Wald distribution for response time data analysis. Psychological methods, 21(3), 309.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"Folks, J. L., & Chhikara, R. S. (1978). The inverse Gaussian distribution and its statistical application—a review. Journal of the Royal Statistical Society: Series B (Methodological), 40(3), 263-275.","category":"page"},{"location":"wald/","page":"Wald","title":"Wald","text":"Steingroever, H., Wabersich, D., & Wagenmakers, E. J. (2021). Modeling across-Plots variability in the Wald drift rate parameter. Behavior Research Methods, 53, 1060-1076.","category":"page"},{"location":"maaDDM/#Attentional-Drift-Diffusion-Model","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The multi-attribute attentional drift diffusion model (MAADDM; Yang & Krajbich, 2023) describes how attentional processes drive drive decision making. Much like the ADDM, in the MAADDM preference for the currently attended option accrues faster than preference for non-attended options. However, the MAADDM has been extended to model shifts in attention for alternatives with two attributes. As with other sequential sampling models, the first option to hit a decision threshold determines the resulting choice and reaction time.","category":"page"},{"location":"maaDDM/#Example","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Example","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"using SequentialSamplingModels\nusing StatsBase\nusing Plots \nusing Random","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"In this example, we will develope a MAADDM for binary choice and generate its predictions. Unlike many other sequential sampling models, it is necessary to specify the attentional process, or supply fixation patterns from eye tracking data. ","category":"page"},{"location":"maaDDM/#Load-Packages","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Load Packages","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The first step is to load the required packages.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"using SequentialSamplingModels\nusing StatsBase\nusing Plots \n\nRandom.seed!(9854)","category":"page"},{"location":"maaDDM/#Define-Transition-Type","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Define Transition Type","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"To represent the transition of attention from one option to the other, we will definite a Transition type and constructor. The fields of the Transition type are:","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"state: an index for the current state\nn: the number of states\nmat: an ntimes n transition matrix","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The constructor accepts a transition matrix, extracts the number of states, and initializes the first state randomly with equal probability.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"mutable struct Transition\n    state::Int \n    n::Int\n    mat::Array{Float64,2} \n end\n\nfunction Transition(mat)\n    n = size(mat,1)\n    state = rand(1:n)\n    return Transition(state, n, mat)\n end","category":"page"},{"location":"maaDDM/#Define-Transition-Matrix","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Define Transition Matrix","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The transition matrix is defined below in the constructor for Transition. As shown in the table below, the model's attention can be in one of three states: option 1, option 2, or non-option, which is any area except the two options.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"  Option 1  Option 1 \n  Attribute 1 Attribute 2 Attribute 1 Attribute 2\nOption 1 Attribute 1 0.980 0.015 0.0025 0.0025\n Attribute 2 0.015 0.980 0.0025 0.0025\nOption 1 Attribute 1 0.0025 0.0025 0.980 0.015\n Attribute 2 0.0025 0.0025 0.015 0.980","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The transition matrix above embodies the following assumptions:","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Once the model attends to an option, it dwells on the option for some time.\nThere is not a bias for one option over the other.\nThere is a larger chance of transitioning between attributes within the same alternative than transitioning between alternatives\nTransitions are Markovian in that they only depend on the previous state.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":" tmat = Transition([.98 .015 .0025 .0025;\n                    .015 .98 .0025 .0025;\n                    .0025 .0025 .98 .015;\n                    .0025 .0025 .015 .98])\n","category":"page"},{"location":"maaDDM/#Fixate-Function","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Fixate Function","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The function below generates the next attention location based on the previous location. ","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":" function fixate(transition)\n     (;mat,n,state) = transition\n     w = @view mat[state,:]\n     next_state = sample(1:n, Weights(w))\n     transition.state = next_state\n     return next_state\n end","category":"page"},{"location":"maaDDM/#Create-Model-Object","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Create Model Object","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The code snippets assign values to parameters of the MAADDM and create a model object.","category":"page"},{"location":"maaDDM/#Drift-Rate-Components","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Drift Rate Components","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"In the decision making task, there are two alternatives with two attributes each. This leads to four components of the drift rates: nu_11 nu_12nu_21nu_22 where the first index corresponds to alternative and the second index corresponds to attribute.  To form the drift rate, each component is weighted by non-attention bias and then a difference is computed.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"ν = [4.0 5.0; 5.0 4.0]","category":"page"},{"location":"maaDDM/#Threshold","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Threshold","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The threshold hold represents the amount of evidence required to make a decision. This parameter is typically fixed at alpha = 1.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"α = 1.0","category":"page"},{"location":"maaDDM/#Starting-Point","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Starting Point","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The starting point of the evidence accumulation process is denoted z and is typically fixed to 0.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"z = 0.0","category":"page"},{"location":"maaDDM/#Non-Attend-Bias-Alternative","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Non-Attend Bias Alternative","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The non-attend bias parameter theta determines how much the non-attended option contributes to the  evidence accumulation process. In the standard DDM, theta=1. ","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"θ = 0.30","category":"page"},{"location":"maaDDM/#Non-Attend-Bias-Attribute","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Non-Attend Bias Attribute","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The non-attend bias parameter psi determines how much the non-attended option contributes to the  evidence accumulation process. In the standard DDM, psi=1. ","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"ϕ = .50","category":"page"},{"location":"maaDDM/#Attribute-Weight","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Attribute Weight","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The parameter omega denotes the weight of the first attribute.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"ω = .70","category":"page"},{"location":"maaDDM/#Diffusion-Noise","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Diffusion Noise","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Diffusion noise, sigma represents intra-trial noise during the evidence accumulation process.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"σ = 0.02","category":"page"},{"location":"maaDDM/#Drift-Rate-Scalar","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Drift Rate Scalar","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"The drift rate scalar controls how quickly evidence accumulates for each option. ","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Δ = 0.0004 ","category":"page"},{"location":"maaDDM/#Model-Object","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Model Object","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Finally, we pass the parameters to the maaDDM constructor to initialize the model.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"dist = maaDDM(; ν, α, z, θ, ϕ, ω, σ, Δ)","category":"page"},{"location":"maaDDM/#Simulate-Model","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Simulate Model","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. The rand function accepts the model object, the number of simulated trials, the fixate function, and the transition matrix object. ","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":" choices,rts = rand(dist, 10_000, tmat; fixate)","category":"page"},{"location":"maaDDM/#Plot-Simulation","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Plot Simulation","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Finally, we can generate histograms of the reaction times for each decision option. ","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"histogram(dist; model_args=(;tmat), model_kwargs=(;fixate))\nplot!(dist; model_args=(;tmat), model_kwargs=(;fixate), t_range=range(.130, 5, length=100), xlims=(0,7))","category":"page"},{"location":"maaDDM/#References","page":"Muti-attribute Attentional Drift Diffusion Model","title":"References","text":"","category":"section"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Yang, X., & Krajbich, I. (2023). A dynamic computational model of gaze and choice in multi-attribute decisions. Psychological Review, 130(1), 52.","category":"page"},{"location":"maaDDM/","page":"Muti-attribute Attentional Drift Diffusion Model","title":"Muti-attribute Attentional Drift Diffusion Model","text":"Fisher, G. (2021). A multiattribute attentional drift diffusion model. Organizational Behavior and Human Decision Processes, 165, 167-182.","category":"page"},{"location":"amortized_point_estimation/#Neural-Parameter-Estimation","page":"Point Estimation","title":"Neural Parameter Estimation","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Our goal is to illustrate how to use NeuralEstimators.jl to perform neural parameter estimation of the Leaky Competing Accumulator (LCA; Usher & McClelland, 2001). In our example below, we estimate the mean of the posterior distributions. Neural parameter estimation uses neural networks to perform parameter estimation by learning the mapping between simulated data and model parameters (for a detailed review, see Zammit-Mangion et al., 2024). Neural parameter estimation is particularly useful for models with computationally intractable likelihoods, such as the LCA. Many neural estimation teachniques are amortized, meaning one incurs a large initial computational cost to train the neural estimator, but estimating the parameters with the trained network is fast and computationally efficient. One benefit of amortized approaches is that the trained neural estimator can be saved and reused across multiple datasets, or used for computationally intensive parameter recovery simulations to understand the quality of parameter estimates under ideal conditions. ","category":"page"},{"location":"amortized_point_estimation/#Full-Code","page":"Point Estimation","title":"Full Code","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"For those who are interested only in the code, you can click on the ▶ icon below to reveal a full copy-and-pastable version of the example.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"<details>\n<summary><b>Full Code</b></summary>","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"using Distributions\nusing Flux\nusing NeuralEstimators\nusing Plots\nusing SequentialSamplingModels\nRandom.seed!(123)\n\n# Function to sample parameters from priors\nfunction sample(K::Integer)\n    ν1 = rand(Gamma(2, 1/1.2f0), K)  # Drift rate 1\n    ν2 = rand(Gamma(2, 1/1.2f0), K)  # Drift rate 2\n    α = rand(Gamma(10, 1/6f0), K)    # Threshold\n    β = rand(Beta(1, 5f0), K)        # Lateral inhibition\n    λ = rand(Beta(1, 5f0), K)        # Leak rate\n    τ = rand(Gamma(1.5, 1/5.0f0), K) # Non-decision time\n    \n    # Stack parameters into a matrix (d×K)\n    θ = vcat(ν1', ν2', α', β', λ', τ')\n    \n    return θ\nend\n\n# Function to simulate data from the LCA model\nfunction simulate(θ, n_trials_per_param)\n    # Simulate data for each parameter vector\n    simulated_data = map(eachcol(θ)) do param\n        # Extract parameters for this model\n        ν1, ν2, α, β, λ, τ = param\n        ν = [ν1, ν2]   # Two-choice LCA\n        \n        # Create LCA model with SSM\n        model = LCA(; ν, α, β, λ, τ)\n        \n        # Generate choices and reaction times\n        choices, rts = rand(model, n_trials_per_param)\n        \n        # Return as a transpose matrix where each column is a trial \n        return Float32.([choices rts]')\n    end\n    return simulated_data\nend\n\n# Create neural network architecture for parameter recovery\nfunction create_neural_estimator(;\n    ν_bounds = (0.1, 6.0),\n    α_bounds = (0.3, 4.5),\n    β_bounds = (0.0, 0.8),\n    λ_bounds = (0.0, 0.8),\n    τ_bounds = (0.100, 2.0)\n)\n    # Unpack defined parameter Bounds\n    ν_min, ν_max = ν_bounds              # Drift rates\n    α_min, α_max = α_bounds              # Threshold\n    β_min, β_max = β_bounds              # Lateral inhibition\n    λ_min, λ_max = λ_bounds              # Leak rate\n    τ_min, τ_max = τ_bounds              # Non-decision time\n\n    # Input dimension: 2 (choice and RT for each trial)\n    n = 2\n    # Output dimension: 6 parameters\n    d = 6  # ν[1], ν[2], α, β, λ, τ\n    # Width of hidden layers\n    w = 128\n    \n    # Inner network - processes each trial independently\n    ψ = Chain(\n        Dense(n, w, relu),\n        Dense(w, w, relu),\n        Dense(w, w, relu)\n    )\n    \n    # Final layer with parameter constraints\n    final_layer = Parallel(\n        vcat,\n        Dense(w, 1, x -> ν_min + (ν_max - ν_min) * σ(x)),     # ν1\n        Dense(w, 1, x -> ν_min + (ν_max - ν_min) * σ(x)),     # ν2\n        Dense(w, 1, x -> α_min + (α_max - α_min) * σ(x)),     # α\n        Dense(w, 1, x -> β_min + (β_max - β_min) * σ(x)),     # β\n        Dense(w, 1, x -> λ_min + (λ_max - λ_min) * σ(x)),     # λ\n        Dense(w, 1, x -> τ_min + (τ_max - τ_min) * σ(x))      # τ\n    )\n    \n    # Outer network - maps aggregated features to parameters\n    ϕ = Chain(\n        Dense(w, w, relu),\n        Dense(w, w, relu),\n        final_layer\n    )\n    \n    # Combine into a DeepSet\n    network = DeepSet(ψ, ϕ)\n    \n    # Initialize neural Bayes estimator\n    estimator = PointEstimator(network)\n    \n    return estimator\nend\n\n# Create the neural estimator\nestimator = create_neural_estimator()\n\n# Train network\ntrained_estimator = train(\n    estimator,\n    sample,                     # Parameter sampler function\n    simulate,                   # Data simulator function\n    m = 100,                    # Number of trials per parameter vector\n    K = 10000,                  # Number of training parameter vectors\n    K_val = 2000,               # Number of validation parameter vectors\n    loss = Flux.mae,            # Mean absolute error loss\n    epochs = 60,                # Number of training epochs\n    epochs_per_Z_refresh = 1,   # Refresh data every epoch\n    epochs_per_θ_refresh = 5,   # Refresh parameters every 5 epochs\n    batchsize = 16,             # Batch size for training\n    verbose = true\n)\n\n# Generate test data\nn_test = 500\nθ_test = sample(n_test)\nZ_test = simulate(θ_test, 500)\n\n# Assess the estimator\nparameter_names = [\"ν1\", \"ν2\", \"α\", \"β\", \"λ\", \"τ\"]\nassessment = assess(\n    trained_estimator, \n    θ_test, \n    Z_test; \n    parameter_names = parameter_names\n)\n\n# Calculate performance metrics\nbias_results = bias(assessment)\nrmse_results = rmse(assessment)\nprintln(\"Bias: \", bias_results)\nprintln(\"RMSE: \", rmse_results)\n\n# Extract data from assessment\ndf = assessment.df\n\n# Create recovery plots for each parameter\nparams = unique(df.parameter)\np_plots = []\n\nfor param in params\n    param_data = filter(row -> row.parameter == param, df)\n    \n    # Calculate correlation coefficient\n    truth = param_data.truth\n    estimate = param_data.estimate\n    correlation = cor(truth, estimate)\n    \n    # Create plot\n    p = scatter(\n        truth, \n        estimate,\n        xlabel=\"Ground Truth\",\n        ylabel=\"Estimated\",\n        title=param,\n        legend=false\n    )\n    \n    # Add diagonal reference line\n    plot!(p, [minimum(truth), maximum(truth)], \n          [minimum(truth), maximum(truth)], \n          line=:dash, color=:black)\n    \n    # Get current axis limits after plot is created\n    x_min, x_max = xlims(p)\n    y_min, y_max = ylims(p)\n    \n    # Position text at the top-left corner of the plot\n    annotate!(p, x_min + 0.1, y_max, text(\"R = $(round(correlation, digits=3))\", :left, 10))\n    \n    push!(p_plots, p)\nend\n\n# Combine plots\np_combined = plot(p_plots..., layout=(3,2), size=(800, 600))\ndisplay(p_combined)\n\n# Generate \"observed\" data\nν = [2.5, 2.0]\nα = 1.5\nβ = 0.2\nλ = 0.1\nτ = 0.3\n\n# Create model and generate data\ntrue_model = LCA(; ν, α, β, λ, τ)\nobserved_choices, observed_rts = rand(true_model, 100)\n\n# Format the data\nobserved_data = Float32.([observed_choices observed_rts]')\n\n# Recover parameters\nrecovered_params = NeuralEstimators.estimate(trained_estimator, [observed_data])\n\n# Compare true and recovered parameters\nprintln(\"True parameters: \", [ν[1], ν[2], α, β, λ, τ])\nprintln(\"Recovered parameters: \", recovered_params)","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"</details>","category":"page"},{"location":"amortized_point_estimation/#Example","page":"Point Estimation","title":"Example","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"We'll estimate parameters of the LCA model, which is particularly challenging due to its complex dynamics, where parameters like leak rate (λ) and lateral inhibition (β) can be difficult to recover (Miletić et al., 2017). This example draws from a more in-depth case that highlights many of the steps one ought to consider when utilizing amortized inference for cognitive modeling; see Principled Amortized Bayesian Workflow for Cognitive Modeling.","category":"page"},{"location":"amortized_point_estimation/#Load-Packages","page":"Point Estimation","title":"Load Packages","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"using Distributions\nusing Flux\nusing NeuralEstimators\nusing Plots\nusing SequentialSamplingModels\nRandom.seed!(123)","category":"page"},{"location":"amortized_point_estimation/#Define-Parameter-Sampling","page":"Point Estimation","title":"Define Parameter Sampling","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Unlike traditional Bayesian inference methods, neural parameter estimation requires us to define two functions so that the neural network can learn the mapping between simulated data and parameters. One function samples parameters from a prior distribution, and the other generates simulated data based on a sampled parameter vector. While traditional methods like MCMC also sample from the prior, those samples are used directly during inference rather than to create a separate training dataset. ","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"(Image: )","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Schematic of neural parameter estimation. Once trained, the neural network provides a direct mapping from observed data (Z) to parameter estimates (θ̂), enabling rapid inference without the computational burden of traditional methods.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"In neural parameter estimation, we use the prior to sample a wide range of parameters and simulate corresponding data, which we then use to train a model (e.g., a neural network) to approximate a point estimate or the posterior. We use the following function to sample a range of parameters for training:","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Function to sample parameters from priors\nfunction sample(K::Integer)\n    ν1 = rand(Gamma(2, 1/1.2f0), K)  # Drift rate 1\n    ν2 = rand(Gamma(2, 1/1.2f0), K)  # Drift rate 2\n    α = rand(Gamma(10, 1/6f0), K)    # Threshold\n    β = rand(Beta(1, 5f0), K)        # Lateral inhibition\n    λ = rand(Beta(1, 5f0), K)        # Leak rate\n    τ = rand(Gamma(1.5, 1/5.0f0), K) # Non-decision time\n    # Stack parameters into a matrix (d×K)\n    θ = vcat(ν1', ν2', α', β', λ', τ')\n    return θ\nend","category":"page"},{"location":"amortized_point_estimation/#Define-Data-Simulator","page":"Point Estimation","title":"Define Data Simulator","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Neural estimators learn the mapping from data to parameters through simulation. Here we define a function to simulate LCA model data. To do so we will use the LCA.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Function to simulate data from the LCA model\nfunction simulate(θ, n_trials_per_param)\n    # Simulate data for each parameter vector\n    simulated_data = map(eachcol(θ)) do param\n        # Extract parameters for this model\n        ν1, ν2, α, β, λ, τ = param\n        ν = [ν1, ν2]   # Two-choice LCA\n        # Create LCA model with SSM\n        model = LCA(; ν, α, β, λ, τ)\n        # Generate choices and reaction times\n        choices, rts = rand(model, n_trials_per_param)\n        # Return as a transpose matrix where each column is a trial \n        return Float32.([choices rts]')\n    end\n    return simulated_data\nend","category":"page"},{"location":"amortized_point_estimation/#Define-Neural-Network-Architecture","page":"Point Estimation","title":"Define Neural Network Architecture","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"For LCA parameter recovery, we use a DeepSet architecture which respects the permutation invariance of trial data. For more details on the method see NeuralEstimators.jl documentation. To construct the network architecture we will use the Flux.jl package.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Create neural network architecture for parameter recovery\nfunction create_neural_estimator(;\n    ν_bounds = (0.1, 6.0),\n    α_bounds = (0.3, 4.5),\n    β_bounds = (0.0, 0.8),\n    λ_bounds = (0.0, 0.8),\n    τ_bounds = (0.100, 2.0)\n)\n    # Unpack defined parameter Bounds\n    ν_min, ν_max = ν_bounds              # Drift rates\n    α_min, α_max = α_bounds              # Threshold\n    β_min, β_max = β_bounds              # Lateral inhibition\n    λ_min, λ_max = λ_bounds              # Leak rate\n    τ_min, τ_max = τ_bounds              # Non-decision time\n\n    # Input dimension: 2 (choice and RT for each trial)\n    n = 2\n    # Output dimension: 6 parameters\n    d = 6  # ν[1], ν[2], α, β, λ, τ\n    # Width of hidden layers\n    w = 128\n    \n    # Inner network - processes each trial independently\n    ψ = Chain(\n        Dense(n, w, relu),\n        Dense(w, w, relu),\n        Dense(w, w, relu)\n    )\n    \n    # Final layer with parameter constraints\n    final_layer = Parallel(\n        vcat,\n        Dense(w, 1, x -> ν_min + (ν_max - ν_min) * σ(x)),     # ν1\n        Dense(w, 1, x -> ν_min + (ν_max - ν_min) * σ(x)),     # ν2\n        Dense(w, 1, x -> α_min + (α_max - α_min) * σ(x)),     # α\n        Dense(w, 1, x -> β_min + (β_max - β_min) * σ(x)),     # β\n        Dense(w, 1, x -> λ_min + (λ_max - λ_min) * σ(x)),     # λ\n        Dense(w, 1, x -> τ_min + (τ_max - τ_min) * σ(x))      # τ\n    )\n    \n    # Outer network - maps aggregated features to parameters\n    ϕ = Chain(\n        Dense(w, w, relu),\n        Dense(w, w, relu),\n        final_layer\n    )\n    \n    # Combine into a DeepSet\n    network = DeepSet(ψ, ϕ)\n    \n    # Initialize neural Bayes estimator\n    estimator = PointEstimator(network)\n    \n    return estimator\nend","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"The result of our constructed neural network is a point estimator that corresponds to a Bayes estimator, which is a functional of the posterior distribution. Under the specified loss function, this point estimate corresponds to the posterior mean. For details on the theoretical foundations of neural Bayes estimators, see Sainsbury-Dale et al. (2024).","category":"page"},{"location":"amortized_point_estimation/#Training-the-Neural-Estimator","page":"Point Estimation","title":"Training the Neural Estimator","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Neural estimators, like all deep learning methods, require a training phase during which they learn the mapping from data to parameters. Here, we train the estimator by simulating data on the fly: the sampler provides new parameter vectors from the prior, and the simulator generates corresponding data conditional on those parameters. Since we use online training and the network never sees the same simulated dataset twice, overfitting is less likely. For more details on training, see the API for arguments here.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Create the neural estimator\nestimator = create_neural_estimator()\n\n# Train network\ntrained_estimator = train(\n    estimator,\n    sample,                     # Parameter sampler function\n    simulate,                   # Data simulator function\n    m = 100,                    # Number of trials per parameter vector\n    K = 10000,                  # Number of training parameter vectors\n    K_val = 2000,               # Number of validation parameter vectors\n    loss = Flux.mae,            # Mean absolute error loss\n    epochs = 60,                # Number of training epochs\n    epochs_per_Z_refresh = 1,   # Refresh data every epoch\n    epochs_per_θ_refresh = 5,   # Refresh parameters every 5 epochs\n    batchsize = 16,             # Batch size for training\n    verbose = true\n)","category":"page"},{"location":"amortized_point_estimation/#Assessing-Estimator-Performance","page":"Point Estimation","title":"Assessing Estimator Performance","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"We can assess the performance of our trained estimator on held-out test data:","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Generate test data\nn_test = 500\nθ_test = sample(n_test)\nZ_test = simulate(θ_test, 500)\n\n# Assess the estimator\nparameter_names = [\"ν1\", \"ν2\", \"α\", \"β\", \"λ\", \"τ\"]\nassessment = assess(\n    trained_estimator, \n    θ_test, \n    Z_test; \n    parameter_names = parameter_names\n)\n\n# Calculate performance metrics\nbias_results = bias(assessment)\nrmse_results = rmse(assessment)\nprintln(\"Bias: \", bias_results)\nprintln(\"RMSE: \", rmse_results)","category":"page"},{"location":"amortized_point_estimation/#Visualizing-Parameter-Recovery","page":"Point Estimation","title":"Visualizing Parameter Recovery","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"A key advantage of neural estimation is the ability to quickly conduct inference after training. For example, we can visualize the recovery of parameters. While NeuralEstimators provides built-in visualization capabilities through the AlgebraOfGraphics.jl, we will demonstrate custom plotting below:","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Extract data from assessment\ndf = assessment.df\n\n# Create recovery plots for each parameter\nparams = unique(df.parameter)\np_plots = []\n\nfor param in params\n    param_data = filter(row -> row.parameter == param, df)\n    \n    # Calculate correlation coefficient\n    truth = param_data.truth\n    estimate = param_data.estimate\n    correlation = cor(truth, estimate)\n    \n    # Create plot\n    p = scatter(\n        truth, \n        estimate,\n        xlabel=\"Ground Truth\",\n        ylabel=\"Estimated\",\n        title=param,\n        legend=false\n    )\n    \n    # Add diagonal reference line\n    plot!(p, [minimum(truth), maximum(truth)], \n          [minimum(truth), maximum(truth)], \n          line=:dash, color=:black)\n    \n    # Get current axis limits after plot is created\n    x_min, x_max = xlims(p)\n    y_min, y_max = ylims(p)\n    \n    # Position text at the top-left corner of the plot\n    annotate!(p, x_min + 0.1, y_max, text(\"R = $(round(correlation, digits=3))\", :left, 10))\n    \n    push!(p_plots, p)\nend\n\n# Combine plots\np_combined = plot(p_plots..., layout=(3,2), size=(800, 600))\ndisplay(p_combined)","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"(Image: )","category":"page"},{"location":"amortized_point_estimation/#Using-the-Trained-Estimator","page":"Point Estimation","title":"Using the Trained Estimator","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Once trained, the estimator can instantly recover parameters from new data via a forward pass:","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"# Generate \"observed\" data\nν = [2.5, 2.0]\nα = 1.5\nβ = 0.2\nλ = 0.1\nτ = 0.3\n\n# Create model and generate data\ntrue_model = LCA(; ν, α, β, λ, τ)\nobserved_choices, observed_rts = rand(true_model, 100)\n\n# Format the data\nobserved_data = Float32.([observed_choices observed_rts]')\n\n# Recover parameters\nrecovered_params = NeuralEstimators.estimate(trained_estimator, [observed_data])\n\n# Compare true and recovered parameters\nprintln(\"True parameters: \", [ν[1], ν[2], α, β, λ, τ])\nprintln(\"Recovered parameters: \", recovered_params)","category":"page"},{"location":"amortized_point_estimation/#Notes-on-Performance","page":"Point Estimation","title":"Notes on Performance","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Neural estimators are particularly effective for models with computationally intractable likelihoods like the LCA model. However, certain parameters (particularly β and λ) can be difficult to recover, even with advanced neural network architectures (Miletić et al., 2017). This is a property of the LCA model rather than a limitation of the estimation technique. ","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Additional details can be found in the NeuralEstimators.jl documentation.","category":"page"},{"location":"amortized_point_estimation/#References","page":"Point Estimation","title":"References","text":"","category":"section"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Miletić, S., Turner, B. M., Forstmann, B. U., & van Maanen, L. (2017). Parameter recovery for the leaky competing accumulator model. Journal of Mathematical Psychology, 76, 25-50.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Sainsbury-Dale, Matthew, Andrew Zammit-Mangion, and Raphaël Huser. \"Likelihood-free parameter estimation with neural Bayes estimators.\" The American Statistician 78.1 (2024): 1-14.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Radev, S. T., Schmitt, M., Schumacher, L., Elsemüller, L., Pratz, V., Schälte, Y., ... & Bürkner, P. C. (2023). BayesFlow: Amortized Bayesian workflows with neural networks. arXiv preprint arXiv:2306.16015.","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Usher, M., & McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing accumulator model. Psychological Review, 108 3, 550–592. https://doi.org/10.1037/0033-295X.108.3.550","category":"page"},{"location":"amortized_point_estimation/","page":"Point Estimation","title":"Point Estimation","text":"Zammit-Mangion, Andrew, Matthew Sainsbury-Dale, and Raphaël Huser. \"Neural methods for amortized inference.\" Annual Review of Statistics and Its Application 12 (2024).","category":"page"},{"location":"loo_compare/#Computing-Model-Comparison-using-PSIS-LOO","page":"PSIS-LOO","title":"Computing Model Comparison using PSIS-LOO","text":"","category":"section"},{"location":"loo_compare/#Overview","page":"PSIS-LOO","title":"Overview","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"We are often interested in comparing how well different models account for the same data. In this tutorial, we will compare models based on their expected log pointwise predictive density (ELPD), which we will estimate using Pareto smoothed importance sampling leave-one-out cross-validation (PSIS-LOO).","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"First, we'll simulate data from a LBA with fixed parameters. Then, we'll define three LBA models with different fixed values for the k parameter. Finally, we'll use ParetoSmooth.jl to perform model comparison via PSIS-LOO.","category":"page"},{"location":"loo_compare/#Load-Packages","page":"PSIS-LOO","title":"Load Packages","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Before proceeding, we will load the required packages.","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"using Random\nusing SequentialSamplingModels\nusing LinearAlgebra\nusing ParetoSmooth\nusing Turing","category":"page"},{"location":"loo_compare/#Data-Generating-Model","page":"PSIS-LOO","title":"Data-Generating Model","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"The next step is to generate simulated data for comparing the models. Here, we'll use an LBA as the true data-generating model:","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Random.seed!(5000)\n\ndist = LBA(ν=[3.0, 2.0], A=0.8, k=0.3, τ=0.3)\ndata = map(_ -> rand(dist), 1:1000)","category":"page"},{"location":"loo_compare/#Specify-Turing-Models","page":"PSIS-LOO","title":"Specify Turing Models","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"The following code block defines the model along with its prior distributions using Turing.jl. We'll use this model with different fixed values for the k parameter.","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"@model function model(data, k; min_rt=minimum(x -> x.rt, data))\n    # Priors\n    ν ~ MvNormal(fill(3.0, 2), I * 2)\n    A ~ truncated(Normal(0.8, 0.4), 0.0, Inf)\n    τ ~ Uniform(0.0, min_rt)\n\n    # Likelihood\n    for i in 1:length(data)\n        data[i] ~ LBA(; ν, A, k, τ)\n    end\nend","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Note that iterating over the data with a for loop necessary to produce correct PSIS-LOO estimates. ","category":"page"},{"location":"loo_compare/#Estimate-the-Parameters","page":"PSIS-LOO","title":"Estimate the Parameters","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Now we'll estimate the parameters using three different fixed k values:","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"chain_lba1 = sample(model(data, 2.0), NUTS(), 1000)\nchain_lba2 = sample(model(data, 0.3), NUTS(), 1000)\nchain_lba3 = sample(model(data, 1.0), NUTS(), 1000)","category":"page"},{"location":"loo_compare/#Compute-PSIS-LOO","page":"PSIS-LOO","title":"Compute PSIS-LOO","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Next we will use the psis_loo function to compute the PSIS-LOO for each model:","category":"page"},{"location":"loo_compare/#Model-1","page":"PSIS-LOO","title":"Model 1","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"loo1 = psis_loo(model_LBA(data, 2.0), chain_lba1)","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"[ Info: No source provided for samples; variables are assumed to be from a Markov Chain. If the samples are independent, specify this with keyword argument `source=:other`.\nResults of PSIS-LOO-CV with 1000 Monte Carlo samples and 1000 data points. Total Monte Carlo SE of 0.14.\n┌───────────┬────────┬──────────┬───────┬─────────┐\n│           │  total │ se_total │  mean │ se_mean │\n├───────────┼────────┼──────────┼───────┼─────────┤\n│   cv_elpd │ 359.33 │    29.11 │  0.36 │    0.03 │\n│ naive_lpd │ 364.34 │    28.90 │  0.36 │    0.03 │\n│     p_eff │   5.01 │     0.32 │  0.01 │    0.00 │\n└───────────┴────────┴──────────┴───────┴─────────┘","category":"page"},{"location":"loo_compare/#Model-2","page":"PSIS-LOO","title":"Model 2","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"loo2 = psis_loo(model_LBA(data, 0.3), chain_lba2)","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Results of PSIS-LOO-CV with 1000 Monte Carlo samples and 1000 data points. Total Monte Carlo SE of 0.077.\n┌───────────┬────────┬──────────┬───────┬─────────┐\n│           │  total │ se_total │  mean │ se_mean │\n├───────────┼────────┼──────────┼───────┼─────────┤\n│   cv_elpd │ 378.04 │    28.87 │  0.38 │    0.03 │\n│ naive_lpd │ 381.63 │    28.71 │  0.38 │    0.03 │\n│     p_eff │   3.59 │     0.26 │  0.00 │    0.00 │\n└───────────┴────────┴──────────┴───────┴─────────┘","category":"page"},{"location":"loo_compare/#Model-3","page":"PSIS-LOO","title":"Model 3","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"loo3 = psis_loo(model_LBA(data, 1.0), chain_lba3)","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Results of PSIS-LOO-CV with 1000 Monte Carlo samples and 1000 data points. Total Monte Carlo SE of 0.14.\n┌───────────┬────────┬──────────┬───────┬─────────┐\n│           │  total │ se_total │  mean │ se_mean │\n├───────────┼────────┼──────────┼───────┼─────────┤\n│   cv_elpd │ 359.33 │    29.11 │  0.36 │    0.03 │\n│ naive_lpd │ 364.34 │    28.90 │  0.36 │    0.03 │\n│     p_eff │   5.01 │     0.32 │  0.01 │    0.00 │\n└───────────┴────────┴──────────┴───────┴─────────┘","category":"page"},{"location":"loo_compare/#Compare-Models","page":"PSIS-LOO","title":"Compare Models","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Finally, we can compare the models using the loo_compare function:","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"loo_compare((lba1 = loo1, lba2 = loo2, lba3 = loo3))","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"┌──────┬─────────┬────────┬────────┐\n│      │ cv_elpd │ cv_avg │ weight │\n├──────┼─────────┼────────┼────────┤\n│ lba2 │    0.00 │   0.00 │   1.00 │\n│ lba3 │  -18.71 │  -0.02 │   0.00 │\n│ lba1 │  -24.53 │  -0.02 │   0.00 │\n└──────┴─────────┴────────┴────────┘","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Here we indeed correctly identified the generative model we simulated. It is of note that some researchers have criticized using model comparison metrics such as leave-one-out cross-validation. See Gronau et al. (2019) for more information.","category":"page"},{"location":"loo_compare/#References","page":"PSIS-LOO","title":"References","text":"","category":"section"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Gronau, Q. F., & Wagenmakers, E. J. (2019). Limitations of Bayesian leave-one-out cross-validation for model selection. Computational brain & behavior, 2, 1-11.","category":"page"},{"location":"loo_compare/","page":"PSIS-LOO","title":"PSIS-LOO","text":"Vehtari, A., Gelman, A. & Gabry, J. Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Stat Comput 27, 1413–1432 (2017).","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"using SequentialSamplingModels\nusing Plots \nusing Random\nM = [\n    1.0 3.0 # A \n    3.0 1.0 # B\n    0.9 3.1 # S\n]","category":"page"},{"location":"mlba/#Multi-attribute-Linear-Ballistic-Accumulator","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Multi-attribute Linear Ballistic Accumulator (MLBA; Trueblood et al., 2014) is an extention of the LBA for multi-attribute deicisions. Alternatives in multi-attribute decisions vary along multiple dimensions. For example, jobs may differ in terms of benefits, salary, flexibility, and work-life balance. As with other sequential sampling models, MLBA assumes that evidence (or preference) accumulates dynamically until the evidence for one alternative reaches a threshold, and triggers the selection of the winning alternative. MLBA incorporates three additional core assumptions:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Drift rates based on a weighted sum of pairwise comparisons\nThe comparison weights are an inverse function of similarity of two alternatives on a given attribute.\nObjective values are mapped to subjective values, which can display extremeness aversion","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"As with MDFT, the MLBA excells in  accounting for context effects in preferential decision making. A context effect occurs when the preference relationship between two alternatives changes when a third alternative is included in the choice set. In such cases, the preferences may reverse or the decision maker may violate rational choice principles.  ","category":"page"},{"location":"mlba/#Similarity-Effect","page":"Multi-attribute Linear Ballistic Accumulator","title":"Similarity Effect","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"In what follows, we will illustrate the use of MLBA with a demonstration of the similarity effect.  Consider the choice between two jobs, A and B. The main criteria for evaluating the two jobs are salary and flexibility. Job A is high on salary but low on flexibility, whereas job B is low on salary. In the plot below, jobs A and B are located on the line of indifference, y = 3 - x. However, because salary recieves more attention, job A is slightly prefered over job B.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"scatter(\n    M[:, 1],\n    M[:, 2],\n    grid = false,\n    leg = false,\n    lims = (0, 4),\n    xlabel = \"Flexibility\",\n    ylabel = \"Salary\",\n    markersize = 6,\n    markerstrokewidth = 2\n)\nannotate!(M[1, 1] + 0.10, M[1, 2] + 0.25, \"A\")\nannotate!(M[2, 1] + 0.10, M[2, 2] + 0.25, \"B\")\nannotate!(M[3, 1] + 0.10, M[3, 2] + 0.25, \"S\")\nplot!(0:0.1:4, 4:-0.1:0, color = :black, linestyle = :dash)","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Suppose an job S, which is similar to A is added to the set of alternatives. Job S inhibits job A more than job B because S and A are close in attribute space. As a result, the preference for job A over job B is reversed. Formally, this is stated as:  ","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Pr(A mid AB)  Pr(B mid AB)","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Pr(A mid ABS)  Pr(B mid ABS)","category":"page"},{"location":"mlba/#Load-Packages","page":"Multi-attribute Linear Ballistic Accumulator","title":"Load Packages","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The first step is to load the required packages.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"mlba/#Create-Model-Object","page":"Multi-attribute Linear Ballistic Accumulator","title":"Create Model Object","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"In the code below, we will define parameters for the MLBA and create a model object to store the parameter values. ","category":"page"},{"location":"mlba/#Drift-Rate-Parameters","page":"Multi-attribute Linear Ballistic Accumulator","title":"Drift Rate Parameters","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"In sequential sampling models, the drift rate is the average speed with which evidence accumulates towards a decision threshold. In the MLBA, the drift rate is determined by comparing attributes between alternatives. The drift rate for alternative i is defined as:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"nu_i = beta_0 + sum_ine j v_ij","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"where beta_0 is the basline additive constant, and v_ij is the comparative value between alternatives i and j. A given alternative i is compared to another alternative j ne i as a weighted sum of differences across attributes k in 12dots n_a:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"v_ij = sum_k=1^n_a w_ijk (u_ik - u_jk)","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The attention weight between alternatives i and j on attribute k is an inverse function of similarity, and decays exponentially with distance:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"w_ijk = e^-lambda u_ik - u_jk","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Similarity between alternatives is not necessarily symmetrical, giving rise to two decay rates:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"lambda = begincases \n      lambda_p  u_ik geq u_jk\n      lambda_n  mathrm otherwise\nendcases","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The subjective value mathbfu = u_1u_2 is found by bending the line of indifference passing through the objective stimulus mathbfs in attribute space, such that (fracxa)^gamma + (fracxb)^gamma = 1. When gamma  1, the model produces extremeness aversion. ","category":"page"},{"location":"mlba/#Baseline-Drift-Rate","page":"Multi-attribute Linear Ballistic Accumulator","title":"Baseline Drift Rate","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The baseline drift rate parameter beta_0 is a constant added to drift rate:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"β₀ = 5.0","category":"page"},{"location":"mlba/#Similarity-Based-Weighting","page":"Multi-attribute Linear Ballistic Accumulator","title":"Similarity-Based Weighting","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Attention weights are an inverse function of similarity between alternatives on a given attribute. The decay rate for positive differences is:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"λₚ = 0.20","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The decay rate for negative differences is:","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"λₙ = 0.40","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The comparisons are asymmetrical when lambda_p ne lambda_n. ","category":"page"},{"location":"mlba/#Extremeness-Aversion","page":"Multi-attribute Linear Ballistic Accumulator","title":"Extremeness Aversion","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The parameter for extremeness aversion is: ","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"γ = 5","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"gamma = 1 indicates objective treatment of stimuli, whereas gamma  1 indicates extreness aversion, i.e. 22 is prefered to 31 even though both fall along the line of indifference.","category":"page"},{"location":"mlba/#Standard-Deviation-of-Drift-Rates","page":"Multi-attribute Linear Ballistic Accumulator","title":"Standard Deviation of Drift Rates","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The standard deviation of the drift rate distribution is given by sigma, which is commonly fixed to 1 for each accumulator.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"σ = [1.0,1.0]","category":"page"},{"location":"mlba/#Maximum-Starting-Point","page":"Multi-attribute Linear Ballistic Accumulator","title":"Maximum Starting Point","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The starting point of each accumulator is sampled uniformly between 0A.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"A = 1.0","category":"page"},{"location":"mlba/#Threshold-Maximum-Starting-Point","page":"Multi-attribute Linear Ballistic Accumulator","title":"Threshold - Maximum Starting Point","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Evidence accumulates until accumulator reaches a threshold alpha = k +A. The threshold is parameterized this way to faciliate parameter estimation and to ensure that A le alpha.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"k = 1.0","category":"page"},{"location":"mlba/#Non-Decision-Time","page":"Multi-attribute Linear Ballistic Accumulator","title":"Non-Decision Time","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"τ = 0.30","category":"page"},{"location":"mlba/#MLBA-Constructor","page":"Multi-attribute Linear Ballistic Accumulator","title":"MLBA Constructor","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Now that values have been asigned to the parameters, we will pass them to MLBA to generate the model object. We will begin with the choice between job A and job B.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"dist = MLBA(;\n    n_alternatives = 2,\n    β₀,\n    λₚ,\n    λₙ,\n    γ,\n    τ,\n    A,\n    k,\n)","category":"page"},{"location":"mlba/#Simulate-Model","page":"Multi-attribute Linear Ballistic Accumulator","title":"Simulate Model","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Now that the model is defined, we will generate 10,000 choices and reaction times using rand. ","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"M₂ = [\n    1.0 3.0 # A \n    3.0 1.0 # B\n]\n    \nchoices,rts = rand(dist, 10_000, M₂)\nprobs2 = map(c -> mean(choices .== c), 1:2)","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Here, we see that job A is prefered over job B.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Next, we will simulate the choice between jobs A, B, and S.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"dist = MLBA(;\n    n_alternatives = 3,\n    β₀,\n    λₚ,\n    λₙ,\n    γ,\n    τ,\n    A,\n    k,\n)\n\nM₃ = [\n    1.0 3.0 # A \n    3.0 1.0 # B\n    0.9 3.1 # S\n]\n\nchoices,rts = rand(dist, 10_000, M₃)\nprobs3 = map(c -> mean(choices .== c), 1:3)","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"In this case, the preferences have reversed: job B is now preferred over job A. ","category":"page"},{"location":"mlba/#Compute-Choice-Probability","page":"Multi-attribute Linear Ballistic Accumulator","title":"Compute Choice Probability","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"cdf(dist, 1, Inf, M₃)","category":"page"},{"location":"mlba/#Plot-Simulation","page":"Multi-attribute Linear Ballistic Accumulator","title":"Plot Simulation","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"The code below plots a histogram for each alternative.","category":"page"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"histogram(dist; model_args = (M₃,))","category":"page"},{"location":"mlba/#References","page":"Multi-attribute Linear Ballistic Accumulator","title":"References","text":"","category":"section"},{"location":"mlba/","page":"Multi-attribute Linear Ballistic Accumulator","title":"Multi-attribute Linear Ballistic Accumulator","text":"Trueblood, J. S., Brown, S. D., & Heathcote, A. (2014). The multiattribute linear ballistic accumulator model of context effects in multialternative choice. Psychological Review, 121(2), 179.","category":"page"},{"location":"rdm/#Racing-Diffusion-Model","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The Racing Diffusion Model (RDM; Tillman, Van Zandt, & Logan, 2020) is a sequential sampling model in which evidence for options races independently. The RDM is similar to the Linear Ballistic Accumulator (LBA), except it assumes that noise occurs during the within-trial evidence accumulation process (but the drift rate is constant across trials).","category":"page"},{"location":"rdm/#Example","page":"Racing Diffusion Model (RDM)","title":"Example","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"In this example, we will demonstrate how to use the RDM in a generic two alternative forced choice task.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"using SequentialSamplingModels\nusing Plots\nusing Random","category":"page"},{"location":"rdm/#Load-Packages","page":"Racing Diffusion Model (RDM)","title":"Load Packages","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The first step is to load the required packages.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"rdm/#Create-Model-Object","page":"Racing Diffusion Model (RDM)","title":"Create Model Object","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"In the code below, we will define parameters for the RDM and create a model object to store the parameter values.","category":"page"},{"location":"rdm/#Drift-Rates","page":"Racing Diffusion Model (RDM)","title":"Drift Rates","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The drift rates control the speed with which information accumulates. Typically, there is one drift rate per option.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"ν = [1.0,0.50]","category":"page"},{"location":"rdm/#Maximum-Starting-Point","page":"Racing Diffusion Model (RDM)","title":"Maximum Starting Point","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The starting point of each accumulator is sampled uniformly between 0A.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"A = 0.80","category":"page"},{"location":"rdm/#Threshold-Maximum-Starting-Point","page":"Racing Diffusion Model (RDM)","title":"Threshold - Maximum Starting Point","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"Evidence accumulates until accumulator reaches a threshold alpha = k +A. The threshold is parameterized this way to faciliate parameter estimation and to ensure that A le alpha.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"k = 0.50","category":"page"},{"location":"rdm/#Non-Decision-Time","page":"Racing Diffusion Model (RDM)","title":"Non-Decision Time","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"Non-decision time is an additive constant representing encoding and motor response time.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"τ  = 0.30","category":"page"},{"location":"rdm/#RDM-Constructor","page":"Racing Diffusion Model (RDM)","title":"RDM Constructor","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"Now that values have been assigned to the parameters, we will pass them to RDM to generate the model object.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"dist = RDM(;ν, k, A, τ)","category":"page"},{"location":"rdm/#Simulate-Model","page":"Racing Diffusion Model (RDM)","title":"Simulate Model","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":" choices,rts = rand(dist, 10_000)\n ","category":"page"},{"location":"rdm/#Compute-PDF","page":"Racing Diffusion Model (RDM)","title":"Compute PDF","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"rdm/#Compute-Log-PDF","page":"Racing Diffusion Model (RDM)","title":"Compute Log PDF","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"rdm/#Compute-Choice-Probability","page":"Racing Diffusion Model (RDM)","title":"Compute Choice Probability","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"cdf(dist, 1, Inf)","category":"page"},{"location":"rdm/#Plot-Simulation","page":"Racing Diffusion Model (RDM)","title":"Plot Simulation","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"histogram(dist; xlims=(0,2.5))\nplot!(dist; t_range=range(.301, 2.5, length=100))","category":"page"},{"location":"rdm/#References","page":"Racing Diffusion Model (RDM)","title":"References","text":"","category":"section"},{"location":"rdm/","page":"Racing Diffusion Model (RDM)","title":"Racing Diffusion Model (RDM)","text":"Tillman, G., Van Zandt, T., & Logan, G. D. (2020). Sequential sampling models without random between-trial variability: The racing diffusion model of speeded decision making. Psychonomic Bulletin & Review, 27, 911-936.","category":"page"},{"location":"turing_hierarchical/#Hierarchical-Models","page":"Hierarchical Models","title":"Hierarchical Models","text":"","category":"section"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"In this example, we will fit a model with random factors and estimate individual parameters. This tutorial will build on the previous ones, so make sure you have followed them first. Let's start by loading all the packages and setting a reproducible seed.","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"using Turing\nusing SequentialSamplingModels\nusing Random\nusing LinearAlgebra\nusing Distributions\nusing DataFrames\nusing StatsPlots\nusing StatsModels\nusing CSV\nusing Optim\n\nRandom.seed!(6)","category":"page"},{"location":"turing_hierarchical/#Generate-Data","page":"Hierarchical Models","title":"Generate Data","text":"","category":"section"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"We will use the LBA distribution to simulate data for 10 participants in two conditions with 100 trials per condition (repeated measures design). The drift rates for condition A are sampled from normal distributions, and the drift rates for condition B are set by sampling a departure from (i.e., the difference with) condition A. In other words, each participant has different drift rates for condition A (the intercept, i.e., the baseline condition) and a different \"effect\" magnitude of condition B (the offset from condition A to condition B).","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"# Generate data with different drifts for two conditions A vs. B\ndf = DataFrame()\nparams = DataFrame()\nfor participant in 1:10\n    # Intercept (condition A)\n    drifts = [rand(Normal(1.5, 0.2)), rand(Normal(0.5, 0.1))]\n    param = join(round.(drifts, digits=2), \", \")  # Format and save params\n    df1 = DataFrame(rand(LBA(ν=drifts, A=0.5, k=0.5, τ=0.3), 100))\n    df1[!, :condition] = repeat([\"A\"], nrow(df1))\n    df1[!, :participant] = repeat([participant], nrow(df1))\n\n    # Effect of condition B\n    drifts2 = [rand(Normal(0.5, 0.15)), rand(Normal(0.5, 0.05))]\n    param = [param, join(round.(drifts2, digits=2), \", \")]\n    df2 = DataFrame(rand(LBA(ν=drifts .+ drifts2, A=0.5, k=0.5, τ=0.3), 100))\n    df2[!, :condition] = repeat([\"B\"], nrow(df2))\n    df2[!, :participant] = repeat([participant], nrow(df1))\n\n    # Assemble and store parameters (to compare with estimation)\n    df = vcat(df, df1, df2)\n    params = vcat(params, DataFrame(permutedims(param), [:drift_intercept, :drift_condition]))\nend","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"We can visualize the individual distributions for the two type of responses and for the conditions (condition A in red and B in blue).","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"density(layout=(2, 1), ylims=(0, 5), xlims=(0, 3), legend=false)\nfor p in unique(df.participant)\n    for (i, cond) in enumerate([\"A\", \"B\"])\n        density!(df.rt[(df.choice.==1).&(df.condition.==cond).&(df.participant.==p)],\n            subplot=1, color=[:blue, :red][i], title=\"Choice = 1\")\n        density!(df.rt[(df.choice.==2).&(df.condition.==cond).&(df.participant.==p)],\n            subplot=2, color=[:blue, :red][i], title=\"Choice = 2\", xlabel=\"Reaction Time (s)\")\n    end\nend\nplot!()","category":"page"},{"location":"turing_hierarchical/#Model-Specification","page":"Hierarchical Models","title":"Model Specification","text":"","category":"section"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"First, we will transform our predictor data into an model matrix. This essentially transform our favor column with \"A\" and \"B\" to a binary vector.","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"We will also transform our outcome data (RTs and choice) into a list of tuples (see this example for more explanation).","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"# Format input data\nf = @formula(rt ~ 1 + condition)\nf = apply_schema(f, schema(f, df))\n_, predictors = coefnames(f)\nX = modelmatrix(f, df)\n\n# Format the data to match the input type\ndata = [(choice=df.choice[i], rt=df.rt[i]) for i in 1:nrow(df)]","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"Now, the model is a bit more complex:","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"@model function model_lba(data; min_rt=0.2, condition=nothing, participant=nothing)\n\n    # Priors for auxiliary parameters\n    A ~ truncated(Normal(0.8, 0.4), 0.0, Inf)\n    k ~ truncated(Normal(0.2, 0.2), 0.0, Inf)\n    tau ~ Uniform(0.0, min_rt)\n\n    # Priors for population-level coefficients\n    drift_intercept_1 ~ Normal(0, 1)\n    drift_intercept_2 ~ Normal(0, 1)\n    drift_condition_1 ~ Normal(0, 1)\n    drift_condition_2 ~ Normal(0, 1)\n\n    # Prior for random intercepts (requires thoughtful specification)\n    # Group-level intercepts' SD\n    drift_intercept_random_sd ~ truncated(Cauchy(0, 0.1), 0.0, Inf)\n    # Group-level intercepts\n    drift_intercept_random_1 ~ filldist(\n        Normal(0, drift_intercept_random_sd),\n        length(unique(participant))\n    )\n    drift_intercept_random_2 ~ filldist(\n        Normal(0, drift_intercept_random_sd),\n        length(unique(participant))\n    )\n\n    for i in 1:length(data)\n        # Formula for intercept\n        drifts_intercept_1 = drift_intercept_1 .+ drift_intercept_random_1[participant[i]]\n        drifts_intercept_2 = drift_intercept_2 .+ drift_intercept_random_2[participant[i]]\n\n        # Combine with condition\n        drifts_1 = drift_intercept_1 + drift_condition_1 * condition[i]\n        drifts_2 = drift_intercept_2 + drift_condition_2 * condition[i]\n        data[i] ~ LBA(; τ=tau, A=A, k=k, ν=[drifts_1, drifts_2])\n    end\nend","category":"page"},{"location":"turing_hierarchical/","page":"Hierarchical Models","title":"Hierarchical Models","text":"Note that for now, these types of model are very slow to run in Turing.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"using SequentialSamplingModels\nusing Plots \nusing Random\nM = [\n    1.0 3.0 # A \n    3.0 1.0 # B\n    0.9 3.1 # S\n]","category":"page"},{"location":"mdft/#Multi-attribute-Decision-Field-Theory","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Multi-attribute Decision Field Theory (MDFT; Roe, Busemeyer, & Townsend, 2001) models how people choose between alternatives with multiple dimensions, such as cars, phones, or jobs. As an example, jobs may differ in terms of benefits, salary, flexibility, and work-life balance. As with other sequential sampling models, MDFT assumes that evidence (or preference) accumulates dynamically until the evidence for one alternative reaches a threshold, and triggers the selection of the winning alternative. MDFT incorporates three additional core assumptions:","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Attention switches between attributes, and alternatives are compared on the currently attended attribute\nAs two alternatives become closer to each other in attribute space, their mutual inhibition increases\nEvidence for each alternative gradually decays across time","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"One of MDFT's strong suits is accounting for context effects in preferential decision making. A context effect occurs when the preference relationship between two alternatives changes when a third alternative is included in the choice set. In such cases, the preferences may reverse or the decision maker may violate rational choice principles.  ","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Note that this version of MDFT uses stochastic differential equations (see Evans et al., 2019). For the random walk version, see ClassicMDFT. ","category":"page"},{"location":"mdft/#Similarity-Effect","page":"Multi-attribute Decision Field Theory","title":"Similarity Effect","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"In what follows, we will illustrate the use of MDFT with a demonstration of the similarity effect.  Consider the choice between two jobs, A and B. The main criteria for evaluating the two jobs are salary and flexibility. Job A is high on salary but low on flexibility, whereas job B is low on salary. In the plot below, jobs A and B are located on the line of indifference, y = 3 - x. However, because salary recieves more attention, job A is slightly prefered over job B.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"scatter(\n    M[:, 1],\n    M[:, 2],\n    grid = false,\n    leg = false,\n    lims = (0, 4),\n    xlabel = \"Flexibility\",\n    ylabel = \"Salary\",\n    markersize = 6,\n    markerstrokewidth = 2\n)\nannotate!(M[1, 1] + 0.10, M[1, 2] + 0.25, \"A\")\nannotate!(M[2, 1] + 0.10, M[2, 2] + 0.25, \"B\")\nannotate!(M[3, 1] + 0.10, M[3, 2] + 0.25, \"S\")\nplot!(0:0.1:4, 4:-0.1:0, color = :black, linestyle = :dash)","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Suppose an job S, which is similar to A is added to the set of alternatives. Job S inhibits job A more than job B because S and A are close in attribute space. As a result, the preference for job A over job B is reversed. Formally, this is stated as:  ","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Pr(A mid AB)  Pr(B mid AB)","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Pr(A mid ABS)  Pr(B mid ABS)","category":"page"},{"location":"mdft/#Load-Packages","page":"Multi-attribute Decision Field Theory","title":"Load Packages","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The first step is to load the required packages.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"mdft/#Create-Model-Object","page":"Multi-attribute Decision Field Theory","title":"Create Model Object","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"In the code below, we will define parameters for the MDFT and create a model object to store the parameter values. ","category":"page"},{"location":"mdft/#Drift-Rate-Scalar","page":"Multi-attribute Decision Field Theory","title":"Drift Rate Scalar","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"In MDFT, the drift rate is determined by the contrast between alternatives along the attended attribute. These evaluations are scaled by the parameter gamma:","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"γ = 1.0","category":"page"},{"location":"mdft/#Threshold","page":"Multi-attribute Decision Field Theory","title":"Threshold","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The threshold alpha represents the amount of evidence required to make a decision.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"α = .50","category":"page"},{"location":"mdft/#Dominance-Weight","page":"Multi-attribute Decision Field Theory","title":"Dominance Weight","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"In MDFT, alternatives are compared along the dominance dimension (diagonal) and indifference dimension (off-diagonal) in attribute space. The relative weight of the dominance dimension is controlled by parameter beta","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"β = 10","category":"page"},{"location":"mdft/#Lateral-Inhibition","page":"Multi-attribute Decision Field Theory","title":"Lateral Inhibition","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"In MDFT, alternatives inhibit each other as an inverse function of thier distance in attribute space: the closer they are, the more inhibititory the relationship. Lateral inhibition is controled via a alternative times alternative feedback matrix in which the diagonal elements (e.g., self-inhibition) represents decay or leakage, and the non-diagonal elements represent lateral inhibition between different alternatives. The values of the feedback matrix are controled by a Gaussian distance function with two parameters: phi_1 and phi_2. ","category":"page"},{"location":"mdft/#Inhibition-Strength","page":"Multi-attribute Decision Field Theory","title":"Inhibition Strength","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The distance gradient parameter phi_1 controls the strength of lateral inhibition between alternatives:","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"ϕ1 = .01","category":"page"},{"location":"mdft/#Maximum-Inhibition","page":"Multi-attribute Decision Field Theory","title":"Maximum Inhibition","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Maximimum inhibition and decay is controlled by parameter phi_2:","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"ϕ2 = .10","category":"page"},{"location":"mdft/#Diffusion-Noise","page":"Multi-attribute Decision Field Theory","title":"Diffusion Noise","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Diffusion noise is the amount of within trial noise in the evidence accumulation process. ","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"σ = .10","category":"page"},{"location":"mdft/#Non-Decision-Time","page":"Multi-attribute Decision Field Theory","title":"Non-Decision Time","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"τ = 0.30","category":"page"},{"location":"mdft/#Attention-Switching-Rates","page":"Multi-attribute Decision Field Theory","title":"Attention Switching Rates","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The rate at which attention shifts from one attribute to the other is controlled by the following rate parameters:","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"κ = [6, 5]","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The second rate is lower than the first rate to reflect more attention to the second dimension (i.e., salary).","category":"page"},{"location":"mdft/#MDFT-Constructor","page":"Multi-attribute Decision Field Theory","title":"MDFT Constructor","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Now that values have been asigned to the parameters, we will pass them to MDFT to generate the model object. We will begin with the choice between job A and job B.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"dist = MDFT(;\n    n_alternatives = 2,\n    σ,\n    α,\n    τ,\n    γ,\n    κ,\n    ϕ1,\n    ϕ2,\n    β,\n)","category":"page"},{"location":"mdft/#Simulate-Model","page":"Multi-attribute Decision Field Theory","title":"Simulate Model","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Now that the model is defined, we will generate 10,000 choices and reaction times using rand. ","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"M₂ = [\n    1.0 3.0 # A \n    3.0 1.0 # B\n]\n    \nchoices,rts = rand(dist, 10_000, M₂; Δt = .001)\nprobs2 = map(c -> mean(choices .== c), 1:2)","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Here, we see that job A is prefered over job B. Also note, in the code block above, rand has a keyword argument Δt which controls the precision of the time discrete approximation. The default value is Δt = .001.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Next, we will simulate the choice between jobs A, B, and S.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"dist = MDFT(;\n    n_alternatives = 3,\n    σ,\n    α,\n    τ,\n    γ,\n    κ,\n    ϕ1,\n    ϕ2,\n    β,\n)\n\nM₃ = [\n    1.0 3.0 # A \n    3.0 1.0 # B\n    0.9 3.1 # S\n]\n\nchoices,rts = rand(dist, 10_000, M₃)\nprobs3 = map(c -> mean(choices .== c), 1:3)","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"In this case, the preferences have reversed: job B is now preferred over job A. ","category":"page"},{"location":"mdft/#Compute-Choice-Probability","page":"Multi-attribute Decision Field Theory","title":"Compute Choice Probability","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"cdf(dist, 1, Inf, M₃)","category":"page"},{"location":"mdft/#Plot-Simulation","page":"Multi-attribute Decision Field Theory","title":"Plot Simulation","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"The code below plots a histogram for each alternative.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"histogram(dist; model_args = (M₃,))","category":"page"},{"location":"mdft/#References","page":"Multi-attribute Decision Field Theory","title":"References","text":"","category":"section"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Evans, N. J., Holmes, W. R., & Trueblood, J. S. (2019). Response-time data provide critical constraints on dynamic models of multi-alternative, multi-attribute choice. Psychonomic Bulletin & Review, 26, 901-933.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Hotaling, J. M., Busemeyer, J. R., & Li, J. (2010). Theoretical developments in decision field theory: Comment on tsetsos, usher, and chater (2010). Psychological Review, 117 , 1294-1298.","category":"page"},{"location":"mdft/","page":"Multi-attribute Decision Field Theory","title":"Multi-attribute Decision Field Theory","text":"Roe, Robert M., Jermone R. Busemeyer, and James T. Townsend. \"Multi-attribute Decision Field Theory: A dynamic connectionst model of decision making.\" Psychological review 108.2 (2001): 370.","category":"page"},{"location":"predictive_distributions/#Prior-and-Posterior-Predictive-Distributions","page":"Predictive Distributions","title":"Prior and Posterior Predictive Distributions","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"This tutorial explains the steps required for constructing and plotting prior and posterior predictive distributions of a sequential sampling models (SSMs). The primary function we will be using is predict_distribution, which allows you to generate prior or posterior predictive distributions from a given model. ","category":"page"},{"location":"predictive_distributions/#Example","page":"Predictive Distributions","title":"Example","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"The first step is to load the required packages and set the seed for the random number generator.","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"using Distributions\nusing Plots\nusing Random\nusing SequentialSamplingModels\nusing Turing \nRandom.seed!(1124)","category":"page"},{"location":"predictive_distributions/#Generate-Simulated-Data","page":"Predictive Distributions","title":"Generate Simulated Data","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"We will use the Wald model as a simple example to illustrate how to create predictive distributions. The Wald model describes the evidence accumulation process underlying single detection decisions, such as respending when a stimulus appears. In the code block below, we will generate 50 data points.","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"n_samples = 50\nrts = rand(Wald(ν=1.5, α=.8, τ=.3), n_samples)","category":"page"},{"location":"predictive_distributions/#Define-Turing-Model","page":"Predictive Distributions","title":"Define Turing Model","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"Next, we will develop a Turing model for generating prior and posterior predictive distributions. You may develop the Turing model as usual, with one minor exception: you must return a NamedTuple of parameters. In the example below, nu and alpha are estimated, but tau is fixed. You may use any combination of estimated and fixed parameters.  ","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"@model function wald_model(rts)\n    ν ~ truncated(Normal(1.5, 1), 0, Inf)\n    α ~ truncated(Normal(.8, 1), 0, Inf)\n    τ = 0.3\n    rts ~ Wald(ν, α, τ)\n    return (;ν, α, τ)\nend","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"In the next code block, we will pass the data and create a model object.","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"model = wald_model(rts)","category":"page"},{"location":"predictive_distributions/#Generate-Prior-Predictive-Distribution","page":"Predictive Distributions","title":"Generate Prior Predictive Distribution","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"Generating a prior predictive distribution involves two steps: (1) sample from the prior, and (2) predict data or a statistic with the model evaluated at the prior samples. Below, we will sample 1,000 parameter vectors from the model. ","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"prior_chain = sample(model, Prior(), 1000)","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"For the next step, we will generate predictions from the model using the parameters sampled from the prior distribution. When Turing is loaded, SequentialSamplingModels automatically loads predict_distribution into your session. The signature for predict_distribution is as follows:","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"predict_distribution(dist, args...; model, func, n_samples, kwargs...)","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"func computes a statistic from simulated data of the model and has the general form func(sim_data, args...; kwargs...). Thus, the only constraint is that func must recieve the simulated data as its first argument. args... and kwargs... are optionally pased to func. The remaining inputs are the model type dist, the Turing model object model, and the number of simulated observations n_samples.","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"As a simple illustration, we will compute the prior predictive mean by calling the following two functions. The first function creates a new function to sample from the predictive distribution and the second function generated_quantities performs the sampling.","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"pred_model = predict_distribution(Wald; model, func=mean, n_samples)\nprior_preds = generated_quantities(pred_model, prior_chain)","category":"page"},{"location":"predictive_distributions/#Generate-Posterior-Predictive-Distribution","page":"Predictive Distributions","title":"Generate Posterior Predictive Distribution","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"Generating a posterior predictive distribution involves a similar process. First, we will estimate the parameters from the data to obtain a chain of posterior samples. Next, we will generate the posterior predictive distribution using generated_quantities:","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"post_chain = sample(model, NUTS(1000, .85), 1000)\npost_preds = generated_quantities(pred_model, post_chain)","category":"page"},{"location":"predictive_distributions/#Plot-the-Distributions","page":"Predictive Distributions","title":"Plot the Distributions","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"Now that we have generated the predictive distributions, we can compare them to the data by plotting them as a histogram. The histogram below reveals two insights: first, the data are centered near the prior and posterior predictive distributions, indicating they predict the data accurately; second, the posterior distribution is concentrated more closely around the data, indicating the information gain acquired during parameter estimation. ","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"histogram(prior_preds[:], xlims=(0,4), xlabel=\"Mean RT\", ylabel=\"Density\", norm=true, \n    color=:grey, label=\"prior\", grid=false)\nhistogram!(post_preds[:], alpha=.7, color=:darkred, norm=true, label=\"posterior\", grid=false)\nvline!([mean(rts)], linestyle=:dash, color=:black, linewidth=2, label=\"data\")","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"(Image: )","category":"page"},{"location":"predictive_distributions/#Posterior-Predictive-Distribution-of-Quantiles","page":"Predictive Distributions","title":"Posterior Predictive Distribution of Quantiles","text":"","category":"section"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"One goal of SSMs is to accurately characterize the distribution of reaction times. The previous example only evaluated one aspective of the model–-namely, the predicted mean. Given the interest in characterizing the shape of the RT distribution, we need a different method. One method for evaluating the model's ability to capture the shape of the distribution is to compare the quantiles. In the example below, the quantiles of the data and model are evaluated at the deciles: 12dots 9. If the model matches the data accurately, the quantiles will fall along the identity line.  ","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"pred_quantiles = predict_distribution(Wald; model, func=compute_quantiles, n_samples=20)\npost_quantile_preds = generated_quantities(pred_quantiles, post_chain)\nq_data = compute_quantiles(rts)\nplot_quantiles(q_data, post_quantile_preds)","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"(Image: )","category":"page"},{"location":"predictive_distributions/","page":"Predictive Distributions","title":"Predictive Distributions","text":"The posterior predictive quantile-quantile plot above shows that the model fits the reaction time distribution well. This close match is to be expected, as we generated the data from the same model. ","category":"page"},{"location":"stDDM/#Starting-time-Drift-Diffusion-Model-(stDDM)","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The relative starting time drift diffusion model (stDDM) characterizes the contributions of multiple unique attributes to the rate of evidence accumulation. Compared to the DDM, which assumes a constant evidence accumulation rate within each trial, the stDDM allows different attributes to enter the evidence accumulation process at various time points relative to one another. By doing so, the stDDM quantifies both the weights given to each attribute and their onset times (Amasino et al., 2019; Barakchian et al., 2021; Chen et al., 2022; Maier et al., 2020; Sullivan and Huettel, 2021).","category":"page"},{"location":"stDDM/#Example","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Example","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"In this example, we will demonstrate how to use the stDDM in a generic two-alternative forced-choice task with two arbitrary attributes.","category":"page"},{"location":"stDDM/#Load-Packages","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Load Packages","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The first step is to load the required packages.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(8741)","category":"page"},{"location":"stDDM/#Create-Model-Object","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Create Model Object","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"In the code below, we will define parameters for the stDDM and create a model object to store the parameter values. ","category":"page"},{"location":"stDDM/#Drift-Rate","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Drift Rate","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The drift rate controls the speed and direction in which information accumulates. Here, each drift coefficient indicates the weighting strengths given to the first and second attributes (e.g., taste and health, payoff and delay, self and other), respectively, to the total drift rate in a given trial, where the drift rate accumulates relative evidence in favor of an option.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"ν = [2.5,2.0]","category":"page"},{"location":"stDDM/#Diffusion-Noise","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Diffusion Noise","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Diffusion noise is the amount of within trial noise in the evidence accumulation process. ","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"σ = 1.0","category":"page"},{"location":"stDDM/#starting-time","page":"Starting-time Drift Diffusion Model (stDDM)","title":"starting time","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The starting time parameter s denotes how much earlier one attribute begins to affect the evidence accumulation process relative to the other(s). If s is negative, attribute 1 evidence is accumulated before attribute 2 evidence; if s is positive, attribute 1 evidence is accumulated after attribute 2 evidence. The absolute value of s indicates the difference in starting times for the two attributes.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"s = 0.10 ","category":"page"},{"location":"stDDM/#Starting-Point","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting Point","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"An indicator of an an initial bias towards a decision. The z parameter is relative to a (i.e. it ranges from 0 to 1).","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"z = 0.50","category":"page"},{"location":"stDDM/#Drift-Rates-Dispersion","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Drift Rates Dispersion","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Dispersion parameters of the drift rate are drawn from a multivariate normal distribution, with the mean vector ν describing the distribution of actual drift rates from specific trials. The standard deviation or across-trial variability is captured by the η vector, and the corresponding correlation between the two attributes is denoted by ρ.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"η = [1.0,1.0]\nρ = 0.3","category":"page"},{"location":"stDDM/#Threshold","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Threshold","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The threshold α represents the amount of evidence required to make a decision.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"α = 1.5","category":"page"},{"location":"stDDM/#Non-Decision-Time","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Non-Decision Time","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Non-decision time is an additive constant representing encoding and motor response time. ","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"τ = 0.30","category":"page"},{"location":"stDDM/#stDDM-Constructor","page":"Starting-time Drift Diffusion Model (stDDM)","title":"stDDM Constructor","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Now that values have been asigned to the parameters, we will pass them to stDDM to generate the model object.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"dist = stDDM(;ν, σ, s, z, η, ρ, α, τ,)","category":"page"},{"location":"stDDM/#Simulate-Model","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Simulate Model","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. ","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"stDDM/#Compute-Choice-Probability","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Compute Choice Probability","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"cdf(dist, 1, Inf)","category":"page"},{"location":"stDDM/#Plot-Simulation","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Plot Simulation","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"histogram(dist)\nplot!(dist; t_range=range(.301, 3.0, length=100))","category":"page"},{"location":"stDDM/#References","page":"Starting-time Drift Diffusion Model (stDDM)","title":"References","text":"","category":"section"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Amasino, D.R., Sullivan, N.J., Kranton, R.E. et al. Amount and time exert independent influences on intertemporal choice. Nat Hum Behav 3, 383–392 (2019). https://doi.org/10.1038/s41562-019-0537-2","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Barakchian, Z., Beharelle, A.R. & Hare, T.A. Healthy decisions in the cued-attribute food choice paradigm have high test-retest reliability. Sci Rep, (2021). https://doi.org/10.1038/s41598-021-91933-6","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Chen, HY., Lombardi, G., Li, SC. et al. Older adults process the probability of winning sooner but weigh it less during lottery decisions. Sci Rep, (2022). https://doi.org/10.1038/s41598-022-15432-y","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Maier, S.U., Raja Beharelle, A., Polanía, R. et al. Dissociable mechanisms govern when and how strongly reward attributes affect decisions. Nat Hum Behav 4, 949–963 (2020). https://doi.org/10.1038/s41562-020-0893-y","category":"page"},{"location":"stDDM/","page":"Starting-time Drift Diffusion Model (stDDM)","title":"Starting-time Drift Diffusion Model (stDDM)","text":"Sullivan, N.J., Huettel, S.A. Healthful choices depend on the latency and rate of information accumulation. Nat Hum Behav 5, 1698–1706 (2021). https://doi.org/10.1038/s41562-021-01154-0","category":"page"},{"location":"turing_simple/#A-Simple-Turing-Model","page":"Simple Bayesian Model","title":"A Simple Turing Model","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"It is possible to use Turing.jl to perform Bayesian parameter estimation on models defined in SequentialSamplingModels.jl. Below, we show you how to estimate the parameters for the Linear Ballistic Accumulator (LBA) and to use it to estimate effects.","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"Note that you can easily swap the LBA model from this example for other SSM models simply by changing the names of the parameters.","category":"page"},{"location":"turing_simple/#Load-Packages","page":"Simple Bayesian Model","title":"Load Packages","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"The first step is to load the required packages. You will need to install each package in your local environment in order to run the code locally. We will also set a random number generator so that the results are reproducible.","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"using Turing\nusing SequentialSamplingModels\nusing Random\nusing LinearAlgebra\nusing StatsPlots\nusing Random\n\nRandom.seed!(45461)","category":"page"},{"location":"turing_simple/#Generate-Data","page":"Simple Bayesian Model","title":"Generate Data","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"We will use the LBA distribution to simulate data (100 trials) with fixed parameters (those we want to recover only from the data using Bayesian modeling).","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"# Generate some data with known parameters\ndist = LBA(ν=[3.0, 2.0], A = .8, k = .2, τ = .3)\ndata = rand(dist, 100)","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"The rand() function will sample random draws from the distribution, and store that into a named tuple of 2 vectors (one for choice and one for rt). The individual vectors can be accessed by their names using data.choice and data.rt.","category":"page"},{"location":"turing_simple/#Specify-Turing-Model","page":"Simple Bayesian Model","title":"Specify Turing Model","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"The code snippet below defines a model in Turing. The model function accepts a tuple containing a vector of choices and a vector of reaction times. The sampling statements define the prior distributions for each parameter. The non-decision time parameter tau must be founded by the minimum reaction time, min_rt. The last sampling statement defines the likelihood of the data given the sampled parameter values.","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"# Specify LBA model\n@model function model(data; min_rt = minimum(data.rt))\n    # Priors\n    ν ~ MvNormal(zeros(2), I * 2)\n    A ~ truncated(Normal(.8, .4), 0.0, Inf)\n    k ~ truncated(Normal(.2, .2), 0.0, Inf)\n    τ  ~ Uniform(0.0, min_rt)\n\n    # Likelihood\n    data ~ LBA(;ν, A, k, τ )\nend","category":"page"},{"location":"turing_simple/#Estimate-the-Parameters","page":"Simple Bayesian Model","title":"Estimate the Parameters","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"Finally, we perform parameter estimation with sample(), which takes the model, and details about the sampling algorithm:","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"model(data): the Turing model with data passed\nNUTS(1000, .65): a sampler object for the No U-Turn Sampler for 1000 warmup samples.\nMCMCThreads(): instructs Turing to run each chain on a separate thread\nn_iterations: the number of iterations performed after warmup\nn_chains: the number of chains","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"# Estimate parameters\nchain = sample(model(data), NUTS(1000, .85), MCMCThreads(), 1000, 4)","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"Chains MCMC chain (1000×17×4 Array{Float64, 3}):\n\nIterations        = 1001:1:2000\nNumber of chains  = 4\nSamples per chain = 1000\nWall duration     = 8.09 seconds\nCompute duration  = 29.97 seconds\nparameters        = ν[1], ν[2], A, k, τ\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\n\nSummary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n        ν[1]    2.8193    0.4348    0.0119   1351.1694   1590.9543    1.0023       45.0871\n        ν[2]    1.6437    0.3820    0.0103   1375.9971   1509.2023    1.0015       45.9155\n           A    0.7280    0.1761    0.0049   1270.3337   1012.5202    1.0026       42.3897\n           k    0.2399    0.1178    0.0033   1156.3022    886.1148    1.0028       38.5846\n           τ    0.2808    0.0281    0.0008   1192.9074    714.0924    1.0040       39.8060\n\nQuantiles\n  parameters      2.5%     25.0%     50.0%     75.0%     97.5% \n      Symbol   Float64   Float64   Float64   Float64   Float64 \n\n        ν[1]    2.0183    2.5259    2.7910    3.0938    3.7300\n        ν[2]    0.9455    1.3753    1.6333    1.8883    2.4329\n           A    0.3969    0.6108    0.7166    0.8416    1.1063\n           k    0.0562    0.1503    0.2244    0.3161    0.5013\n           τ    0.2202    0.2630    0.2836    0.3018    0.3273","category":"page"},{"location":"turing_simple/#Posterior-Summary","page":"Simple Bayesian Model","title":"Posterior Summary","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"We can compute a description of the posterior distributions.","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"# Summarize posteriors\nsummarystats(chain)","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"Summary Statistics\n  parameters      mean       std      mcse    ess_bulk    ess_tail      rhat   ess_per_sec \n      Symbol   Float64   Float64   Float64     Float64     Float64   Float64       Float64 \n\n        ν[1]    2.8193    0.4348    0.0119   1351.1694   1590.9543    1.0023       45.0871\n        ν[2]    1.6437    0.3820    0.0103   1375.9971   1509.2023    1.0015       45.9155\n           A    0.7280    0.1761    0.0049   1270.3337   1012.5202    1.0026       42.3897\n           k    0.2399    0.1178    0.0033   1156.3022    886.1148    1.0028       38.5846\n           τ    0.2808    0.0281    0.0008   1192.9074    714.0924    1.0040       39.8060","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"As you can see, based on the mean values of the posterior distributions, the original parameters (ν=[3.0, 2.0], A = .8, k = .2, τ = .3) are successfully recovered from the data (the accuracy would increase with more data).","category":"page"},{"location":"turing_simple/#Evaluation","page":"Simple Bayesian Model","title":"Evaluation","text":"","category":"section"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"It is important to verify that the chains converged. We see that the chains converged according to hatr leq 105, and the trace plots below show that the chains look like \"hairy caterpillars\", which indicates the chains did not get stuck. As expected, the posterior distributions are close to the data generating parameter values.","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"plot(chain)","category":"page"},{"location":"turing_simple/","page":"Simple Bayesian Model","title":"Simple Bayesian Model","text":"(Image: )","category":"page"},{"location":"aDDM/#Attentional-Drift-Diffusion-Model","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The attentional drift diffusion model (ADDM; Krajbich, Armel, & Rangel, 2010) describes how attentional processes drive drive decision making. In the ADDM, preference for the currently attended option accrues faster than preference for non-attended options. As with other sequential sampling models, the first option to hit a decision threshold determines the resulting choice and reaction time.","category":"page"},{"location":"aDDM/#Example","page":"Attentional Drift Diffusion Model","title":"Example","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"using SequentialSamplingModels\nusing StatsBase\nusing Plots\nusing Random","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"In this example, we will develope a ADDM for binary choice and generate its predictions. Unlike many other sequential sampling models, it is necessary to specify the attentional process, or supply fixation patterns from eye tracking data. ","category":"page"},{"location":"aDDM/#Load-Packages","page":"Attentional Drift Diffusion Model","title":"Load Packages","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The first step is to load the required packages.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"using SequentialSamplingModels\nusing StatsBase\nusing Plots\n\nRandom.seed!(5487)","category":"page"},{"location":"aDDM/#Define-Transition-Type","page":"Attentional Drift Diffusion Model","title":"Define Transition Type","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"To represent the transition of attention from one option to the other, we will definite a Transition type and constructor. The fields of the Transition type are:","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"state: an index for the current state\nn: the number of states\nmat: an ntimes n transition matrix","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The constructor accepts a transition matrix, extracts the number of states, and initializes the first state randomly with equal probability.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"mutable struct Transition\n    state::Int \n    n::Int\n    mat::Array{Float64,2} \n end\n\nfunction Transition(mat)\n    n = size(mat,1)\n    state = rand(1:n)\n    return Transition(state, n, mat)\n end","category":"page"},{"location":"aDDM/#Define-Transition-Matrix","page":"Attentional Drift Diffusion Model","title":"Define Transition Matrix","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The transition matrix is defined below in the constructor for Transition. As shown in the table below, the model's attention can be in one of three states: option 1, option 2, or non-option, which is any area except the two options. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":" option 1 option 2 non-option\noption 1 0.98 0.015 0.005\noption 2 0.015 0.98 0.005\nnon-option 0.45 0.45 0.10","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The transition matrix above embodies the following assumptions:","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Once the model attends to an option, it dwells on the option for some time.\nThere is not a bias for one option over the other.\nThe chance of fixating on a non-option is small, and such fixations are brief when they do occur.\nTransitions are Markovian in that they only depend on the previous state.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"tmat = Transition([.98 .015 .005;\n                    .015 .98 .005;\n                    .45 .45 .1])","category":"page"},{"location":"aDDM/#Attend-Function","page":"Attentional Drift Diffusion Model","title":"Attend Function","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The function below generates the next attention location based on the previous location. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":" function fixate(transition)\n     (;mat,n,state) = transition\n     w = @view mat[state,:]\n     next_state = sample(1:n, Weights(w))\n     transition.state = next_state\n     return next_state\n end","category":"page"},{"location":"aDDM/#Create-Model-Object","page":"Attentional Drift Diffusion Model","title":"Create Model Object","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The code snippets assign values to parameters of the ADDM and create a model object.","category":"page"},{"location":"aDDM/#Drift-Rate-Components","page":"Attentional Drift Diffusion Model","title":"Drift Rate Components","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The ADDM has two drift rates components corresponding to the utlity of each option. To form the drift rate, each component is weighted by non-attention bias and then a difference is computed.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"ν = [6.0,5.0]","category":"page"},{"location":"aDDM/#Threshold","page":"Attentional Drift Diffusion Model","title":"Threshold","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The threshold hold represents the amount of evidence required to make a decision. This parameter is typically fixed at alpha = 1.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"α = 1.0","category":"page"},{"location":"aDDM/#Starting-Point","page":"Attentional Drift Diffusion Model","title":"Starting Point","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The starting point of the evidence accumulation process is denoted z and is typically fixed to 0.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"z = 0.0","category":"page"},{"location":"aDDM/#Non-Attend-Bias","page":"Attentional Drift Diffusion Model","title":"Non-Attend Bias","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The non-attend bias parameter theta determines how much the non-attended option contributes to the  evidence accumulation process. In the standard DDM, theta=1. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"θ = 0.30","category":"page"},{"location":"aDDM/#Diffusion-Noise","page":"Attentional Drift Diffusion Model","title":"Diffusion Noise","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Diffusion noise, sigma represents intra-trial noise during the evidence accumulation process.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"σ = 0.02","category":"page"},{"location":"aDDM/#Drift-Rate-Scalar","page":"Attentional Drift Diffusion Model","title":"Drift Rate Scalar","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"The drift rate scalar controls how quickly evidence accumulates for each option. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Δ = 0.0004 ","category":"page"},{"location":"aDDM/#Model-Object","page":"Attentional Drift Diffusion Model","title":"Model Object","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Finally, we pass the parameters to the aDDM constructor to initialize the model.","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":" model = aDDM(; ν, α, z, θ, σ, Δ)","category":"page"},{"location":"aDDM/#Simulate-Model","page":"Attentional Drift Diffusion Model","title":"Simulate Model","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand. The rand function accepts the model object, the number of simulated trials, the fixate function, and the transition matrix object. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":" choices,rts = rand(model, 10_000, tmat; fixate)","category":"page"},{"location":"aDDM/#Plot-Simulation","page":"Attentional Drift Diffusion Model","title":"Plot Simulation","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Finally, we can generate histograms of the reaction times for each decision option. ","category":"page"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"histogram(model; model_args=(;tmat), model_kwargs=(;fixate))\nplot!(model; model_args=(;tmat), model_kwargs=(;fixate), t_range=range(0.0, 5, length=100), xlims=(0,5))","category":"page"},{"location":"aDDM/#References","page":"Attentional Drift Diffusion Model","title":"References","text":"","category":"section"},{"location":"aDDM/","page":"Attentional Drift Diffusion Model","title":"Attentional Drift Diffusion Model","text":"Krajbich, I., Armel, C., & Rangel, A. (2010). Visual fixations and the computation and comparison of value in simple choice. Nature neuroscience, 13(10), 1292-1298.","category":"page"},{"location":"basic_plot_example/#Basic-Example","page":"Basic Example","title":"Basic Example","text":"","category":"section"},{"location":"basic_plot_example/","page":"Basic Example","title":"Basic Example","text":"SequentialSamplingModels.jl automatically loads plotting functionality for SSMs when Plots is active in your Julia session . As a simple starting point, the code block below illustrates some basic functionality:","category":"page"},{"location":"basic_plot_example/","page":"Basic Example","title":"Basic Example","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(85)\n\nν = [1.0,0.50]\nk = 0.50\nA = 1.0\nτ = 0.30\n\ndist = RDM(;ν, k, A, τ)\nhistogram(dist; xlims=(0,2.5))\nplot!(dist; t_range=range(.301, 2.5, length=100))","category":"page"},{"location":"basic_plot_example/","page":"Basic Example","title":"Basic Example","text":"You can overwrite the default plot options by passing keyword arguments. The code block below provides an example:","category":"page"},{"location":"basic_plot_example/","page":"Basic Example","title":"Basic Example","text":"using SequentialSamplingModels\nusing Plots\nusing Random \nRandom.seed!(85)\n\nν = [1.0,0.50]\nk = 0.50\nA = 1.0\nτ = 0.30\n\ndist = RDM(;ν, k, A, τ)\nhistogram(dist; xlims=(0,2.5))\nplot!(dist; t_range=range(.301, 2.5, length=100), color=:darkorange)","category":"page"},{"location":"poisson_race/#Poisson-Race","page":"Poisson Race","title":"Poisson Race","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The Poisson race model is one of the first sequential sampling models, with origins dating back to 1962. In this model, evidence accumulates in discrete steps until the first accumulator reaches a threshold. The time between increments follows an exponential distribution. The first passage time follows a gamma distribution because it is the sum of exponential random variables.  ","category":"page"},{"location":"poisson_race/#Example","page":"Poisson Race","title":"Example","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"In this example, we will demonstrate how to use the Poisson race model in a generic two alternative forced choice task.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"using SequentialSamplingModels\nusing Plots \nusing Random","category":"page"},{"location":"poisson_race/#Load-Packages","page":"Poisson Race","title":"Load Packages","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The first step is to load the required packages.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"using SequentialSamplingModels\nusing Plots \nusing Random\n\nRandom.seed!(65)","category":"page"},{"location":"poisson_race/#Create-Model-Object","page":"Poisson Race","title":"Create Model Object","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"In the code below, we will define parameters for the Poisson race and create a model object to store the parameter values.","category":"page"},{"location":"poisson_race/#Mean-processing-time","page":"Poisson Race","title":"Mean processing time","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The parameter nu represents the mean processing of each count. Note that nu = frac1lambda, where lambda is the rate parameter. ","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"ν = [.04, .05]","category":"page"},{"location":"poisson_race/#Threshold","page":"Poisson Race","title":"Threshold","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The parameter alpha is a vector of thresholds. Each threshold is an integer because it represents a discrete count.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"α = [4,4]","category":"page"},{"location":"poisson_race/#Non-Decision-Time","page":"Poisson Race","title":"Non-Decision Time","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"Non-decision time is an additive constant representing encoding and motor response time.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"τ = 0.30","category":"page"},{"location":"poisson_race/#Poisson-race-Constructor","page":"Poisson Race","title":"Poisson race Constructor","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"Now that values have been asigned to the parameters, we will pass them to LNR to generate the model object.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"dist = PoissonRace(;ν, α, τ)","category":"page"},{"location":"poisson_race/#Simulate-Model","page":"Poisson Race","title":"Simulate Model","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"Now that the model is defined, we will generate 10000 choices and reaction times using rand.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":" choices,rts = rand(dist, 10_000)","category":"page"},{"location":"poisson_race/#Compute-PDF","page":"Poisson Race","title":"Compute PDF","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The PDF for each observation can be computed as follows:","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"pdf.(dist, choices, rts)","category":"page"},{"location":"poisson_race/#Compute-Log-PDF","page":"Poisson Race","title":"Compute Log PDF","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"Similarly, the log PDF for each observation can be computed as follows:","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"logpdf.(dist, choices, rts)","category":"page"},{"location":"poisson_race/#Compute-Choice-Probability","page":"Poisson Race","title":"Compute Choice Probability","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The choice probability Pr(C=c) is computed by passing the model and choice index to cdf along with a large value for time as the second argument.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"cdf(dist, 1, Inf)","category":"page"},{"location":"poisson_race/#Plot-Simulation","page":"Poisson Race","title":"Plot Simulation","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"The code below overlays the PDF on reaction time histograms for each option.","category":"page"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"histogram(dist)\nplot!(dist; t_range=range(.301, 1, length=100))","category":"page"},{"location":"poisson_race/#References","page":"Poisson Race","title":"References","text":"","category":"section"},{"location":"poisson_race/","page":"Poisson Race","title":"Poisson Race","text":"LaBerge, D. A. (1962). A recruitment model of simple behavior. Psychometrika, 27, 375-395.","category":"page"},{"location":"developer_guide/#Style-Guide","page":"Developer Guide","title":"Style Guide","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"The code written in SequentialSamplingModels.jl follows the guidlines presented in the .JuliaFormatter.toml file, which is inspired by blue style. You may run the formatter locally by loading SequentialSamplingModels into your session and running JuliaFormatter.format(SequentialSamplingModels). All PRs undergo a formatting check, which will provide suggestions if you forget to run the formatter locally.  ","category":"page"},{"location":"developer_guide/#Documentation","page":"Developer Guide","title":"Documentation","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"Each model should adhere to the following guidelines. Include additional details as necessary.","category":"page"},{"location":"developer_guide/#Docstrings","page":"Developer Guide","title":"Docstrings","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"Provide docstrings for methods and types which are part of the API. For example, the doc strings for each model should adhere to the following format:","category":"page"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"  LNR{T<:Real} <: AbstractLNR\n\n  Parameters\n  ≡≡≡≡≡≡≡≡≡≡\n\n    •  ν: a vector of means in log-space\n\n    •  σ: a vector of standard deviation parameter in log-space\n\n    •  τ: a encoding-response offset\n\n  Constructors\n  ≡≡≡≡≡≡≡≡≡≡≡≡\n\n  Two constructors are defined below. The first constructor uses positional arguments, and is therefore order\n  dependent:\n\n  LNR(ν, σ, τ)\n\n  The second constructor uses keywords with default values, and is not order dependent:\n\n  LNR(; ν = [-1, -2], σ = fill(1.0, length(ν)), τ = 0.20)\n\n  Example\n  ≡≡≡≡≡≡≡\n\n  using SequentialSamplingModels\n  dist = LNR(ν = [-2,-3], σ = [1.0,1.0], τ = .3)\n  choice,rt = rand(dist, 10)\n  like = pdf.(dist, choice, rt)\n  loglike = logpdf.(dist, choice, rt)\n\n  References\n  ≡≡≡≡≡≡≡≡≡≡\n\n  Rouder, J. N., Province, J. M., Morey, R. D., Gomez, P., & Heathcote, A. (2015). The lognormal race: A\n  cognitive-process model of choice and latency with desirable psychometric properties. Psychometrika, 80(2), 491-513.","category":"page"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"For the benefit of other developers, err on the side of providing doc strings for internal methods. The doc strings should provide the function signature, a high level explanation of the function, and a description of arguments and keywords. Please include references as appropriate. ","category":"page"},{"location":"developer_guide/#Model-Example","page":"Developer Guide","title":"Model Example","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"Provide a detailed model walk through for the online documentation under the section Models. The walk through should include a description of the model, an explanation of the model parameters, and a demonstration showing the pdf overlayed on the histogram (if applicable). Please use existing model examples as a template. ","category":"page"},{"location":"developer_guide/#API","page":"Developer Guide","title":"API","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"Only export (make public) types and methods that are intended for users. Other methods are implementational details for interal use. ","category":"page"},{"location":"developer_guide/#Unit-Tests","page":"Developer Guide","title":"Unit Tests","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"Provide unit tests for most (if not all) methods. When possible, programatically test a method over a wide range of inputs. If you find a bug, write a unit test for the bug to prevent regressions. When possible, compare methods to those defined in established and trusted packages in other languages.  ","category":"page"},{"location":"developer_guide/#Parameter-Naming-Conventions","page":"Developer Guide","title":"Parameter Naming Conventions","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"To ensure consistency across models, please use the following variable names:","category":"page"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"use ν for drift rates\nuse α for decision boundaries\nuse Δt for a discrete time step\nuse σ for within-trial noise of drift rate  \nuse τ for non-decision time\nuse z for evidence starting point\nuse η for across-trial noise of drift rate","category":"page"},{"location":"developer_guide/#Other-Conventions","page":"Developer Guide","title":"Other Conventions","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"Use variable names that are descriptive unless there is a strong mathematical convention for a particular variable name. When appropriate, use verbs to describe functions. For example, use summarize(model) instead of summary(model). Use lower case for variables, and capitalize the first letter of package names, types, and constructors. Use underscore to separate words. For example, name a file developer_guide.md instead of developerguide.md.","category":"page"},{"location":"developer_guide/#Contributing","page":"Developer Guide","title":"Contributing","text":"","category":"section"},{"location":"developer_guide/","page":"Developer Guide","title":"Developer Guide","text":"If you are interested in contributing, please open an issue and propose changes or additions you think would be beneficial. After discussion and approval, create a fork of the repository, and submit the changes via a pull request.  ","category":"page"},{"location":"#SequentialSamplingModels.jl","page":"Home","title":"SequentialSamplingModels.jl","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides a unified interface for simulating and evaluating popular sequential sampling models (SSMs), which integrates with the following packages:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Distributions.jl: functions for probability distributions\nNeuralEstimators.jl: amortized inference using neural networks\nPigeons.jl: Bayesian parameter estimation and Bayes factors\nPlots.jl: extended plotting tools for SSMs\nTuring.jl: Bayesian parameter estimation","category":"page"},{"location":"#Background","page":"Home","title":"Background","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"SSMs, also known as an evidence accumulation models, are a broad class of dynamic models of human decision making in which evidence for each option accumulates until the evidence for one option reaches a decision threshold. Models within this class make different assumptions about the nature of the evidence accumulation process. An example of the evidence accumulation process is illustrated below for the Racing Diffusion Model (RDM):","category":"page"},{"location":"","page":"Home","title":"Home","text":"# using Plots\n# using Random \n# using SequentialSamplingModels \n\n# Random.seed!(50)\n# model = RDM(ν = [1.0,1.5,2.0])\n# α = model.A + model.k\n# times, evidence = simulate(model)\n# color = [RGB(.251, .388, .847) RGB(.584, .345, .689) RGB(.796, .235, .20) ]\n# animation = @animate for i ∈ 1:length(times)\n#     plot(times[1:i], evidence[1:i,:], xlims = extrema(times); color,\n#     ylims = (-.5, α + .1), ticks = :none, linewidth = 1.5)\n#     hline!([α], color = :black, linestyle = :dash, leg = false)\n# end\n# gif(animation, \"rdm.gif\", fps = 30)","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: )","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"You can install a stable version of SequentialSamplingModels by running the following in the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add SequentialSamplingModels","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package can then be loaded with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using SequentialSamplingModels","category":"page"},{"location":"#Quick-Example","page":"Home","title":"Quick Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The example belows shows how to perform three common tasks:","category":"page"},{"location":"","page":"Home","title":"Home","text":"generate simulated data\nevaluate the log likelihood of data\nplot the predictions of the model","category":"page"},{"location":"","page":"Home","title":"Home","text":"using SequentialSamplingModels\nusing Plots\nusing Random\n\nRandom.seed!(2054)\n\n# Create LBA distribution with known parameters\ndist = LBA(; ν=[2.75,1.75], A=0.8, k=0.5, τ=0.25)\n# Sample 10,000 simulated data from the LBA\nsim_data = rand(dist, 10_000)\n# compute log likelihood of simulated data \nlogpdf(dist, sim_data)\n# Plot the RT distribution for each choice\nhistogram(dist)\nplot!(dist; t_range=range(.3,2.5, length=100), xlims=(0, 2.5))","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Evans, N. J. & Wagenmakers, E.-J. Evidence accumulation models: Current limitations and future directions. Quantitative Methods for Psychololgy 16, 73–90 (2020).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Forstmann, B. U., Ratcliff, R., & Wagenmakers, E. J. (2016). Sequential sampling models in cognitive neuroscience: Advantages, applications, and extensions. Annual Review of Psychology, 67, 641-666.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Jones, M., & Dzhafarov, E. N. (2014). Unfalsifiability and mutual translatability of major modeling schemes for choice reaction time. Psychological Review, 121(1), 1.","category":"page"}]
}
