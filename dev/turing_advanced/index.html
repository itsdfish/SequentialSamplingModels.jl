<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced Model Specification · SequentialSamplingModels</title><meta name="title" content="Advanced Model Specification · SequentialSamplingModels"/><meta property="og:title" content="Advanced Model Specification · SequentialSamplingModels"/><meta property="twitter:title" content="Advanced Model Specification · SequentialSamplingModels"/><meta name="description" content="Documentation for SequentialSamplingModels."/><meta property="og:description" content="Documentation for SequentialSamplingModels."/><meta property="twitter:description" content="Documentation for SequentialSamplingModels."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="https://fonts.googleapis.com/css?family=Montserrat|Source+Code+Pro&amp;display=swap" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="SequentialSamplingModels logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">SequentialSamplingModels</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-2-1" type="checkbox"/><label class="tocitem" for="menuitem-2-1"><span class="docs-label">Single Choice Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../ex_gaussian/">Ex-Gaussian</a></li><li><a class="tocitem" href="../shifted_lognormal/">Shifted Log Normal</a></li><li><a class="tocitem" href="../wald/">Wald</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Multi-choice Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><input class="collapse-toggle" id="menuitem-2-2-1" type="checkbox"/><label class="tocitem" for="menuitem-2-2-1"><span class="docs-label">Single Attribute Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../DDM/">Drift Diffusion Model (DDM)</a></li><li><a class="tocitem" href="../lca/">Leaky Competing Accumulator (LCA)</a></li><li><a class="tocitem" href="../lba/">Linear Ballistic Accumulator (LBA)</a></li><li><a class="tocitem" href="../lnr/">Log Normal Race (LNR)</a></li><li><a class="tocitem" href="../poisson_race/">Poisson Race</a></li><li><a class="tocitem" href="../rdm/">Racing Diffusion Model (RDM)</a></li><li><a class="tocitem" href="../stDDM/">Starting-time Drift Diffusion Model (stDDM)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2-2"><span class="docs-label">Multi-attribute Models</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../maaDDM/">Muti-attribute Attentional Drift Diffusion Model</a></li><li><a class="tocitem" href="../mdft/">Multi-attribute Decision Field Theory</a></li><li><a class="tocitem" href="../mlba/">Multi-attribute Linear Ballistic Accumulator</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Alternative Geometries</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../cddm/">Circular Drift Diffusion Model (CDDM)</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Parameter Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../mode_estimation/">Mode Estimation</a></li><li><a class="tocitem" href="../turing_simple/">Simple Bayesian Model</a></li><li class="is-active"><a class="tocitem" href>Advanced Model Specification</a><ul class="internal"><li><a class="tocitem" href="#Generate-Data"><span>Generate Data</span></a></li><li><a class="tocitem" href="#Exclude-Outliers"><span>Exclude Outliers</span></a></li><li><a class="tocitem" href="#Visualize-Data"><span>Visualize Data</span></a></li><li><a class="tocitem" href="#Format-Predictors"><span>Format Predictors</span></a></li><li><a class="tocitem" href="#Specify-Turing-Model"><span>Specify Turing Model</span></a></li><li><a class="tocitem" href="#Prior-Predictive-Check"><span>Prior Predictive Check</span></a></li><li><a class="tocitem" href="#Parameters-Estimation"><span>Parameters Estimation</span></a></li><li><a class="tocitem" href="#Posterior-Predictive-Check"><span>Posterior Predictive Check</span></a></li></ul></li><li><a class="tocitem" href="../turing_hierarchical/">Hierarchical Models</a></li><li><input class="collapse-toggle" id="menuitem-3-5" type="checkbox"/><label class="tocitem" for="menuitem-3-5"><span class="docs-label">Amortized Neural Estimation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../amortized_point_estimation/">Point Estimation</a></li><li><a class="tocitem" href="../amortized_bayesian_parameter_estimation/">Bayesian Parameter Estimation</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">Model Comparison</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../bayes_factor/">Bayes Factors</a></li><li><a class="tocitem" href="../loo_compare/">PSIS-LOO</a></li></ul></li><li><a class="tocitem" href="../predictive_distributions/">Predictive Distributions</a></li><li><input class="collapse-toggle" id="menuitem-6" type="checkbox"/><label class="tocitem" for="menuitem-6"><span class="docs-label">Plotting</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../basic_plot_example/">Basic Example</a></li><li><a class="tocitem" href="../layout/">Changing the Layout</a></li><li><a class="tocitem" href="../plot_model/">Plot Model Process</a></li></ul></li><li><a class="tocitem" href="../issues/">Help and Issues</a></li><li><a class="tocitem" href="../performance_tips/">Performance Tips</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../developer_guide/">Developer Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Parameter Estimation</a></li><li class="is-active"><a href>Advanced Model Specification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced Model Specification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/itsdfish/SequentialSamplingModels.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/itsdfish/SequentialSamplingModels.jl/blob/master/docs/src/turing_advanced.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Estimate-Effect-on-Drift-Rate"><a class="docs-heading-anchor" href="#Estimate-Effect-on-Drift-Rate">Estimate Effect on Drift Rate</a><a id="Estimate-Effect-on-Drift-Rate-1"></a><a class="docs-heading-anchor-permalink" href="#Estimate-Effect-on-Drift-Rate" title="Permalink"></a></h1><p>This advanced example illustrates how to estimate the effect of an experimental condition on the drift rate parameter. The drift rate could be manipulated in various ways. For example, the drift rate could be manipulated by varying the similarity of visual stimuli, or emphasizing speed or accuracy in task instructions.</p><h2 id="Generate-Data"><a class="docs-heading-anchor" href="#Generate-Data">Generate Data</a><a id="Generate-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-Data" title="Permalink"></a></h2><p>In this example, we will get closer to real use-cases by starting with the data stored in a <code>DataFrame</code>. This dataframe will be a combination of data generated from two different distributions with different parameters, corresponding to two experimental conditions (e.g., Speed vs. Accuracy).</p><pre><code class="language-julia hljs">using Turing
using SequentialSamplingModels
using Random
using LinearAlgebra
using Distributions
using DataFrames
using StatsPlots
using StatsModels
using KernelDensity

# Generate data with different drifts for two conditions A vs. B
Random.seed!(6)

n_obs = 50
df1 = DataFrame(rand(LBA(ν=[1.5, 0.5], A=0.5, k=0.2, τ=0.3), n_obs))
df2 = DataFrame(rand(LBA(ν=[2.5, 1.5], A=0.5, k=0.2, τ=0.3), n_obs))
df = vcat(df1, df2)
df.condition = repeat([&quot;A&quot;, &quot;B&quot;], inner=n_obs)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">100-element Vector{String}:
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 &quot;A&quot;
 ⋮
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;
 &quot;B&quot;</code></pre><p>These 2 conditions <em>A</em> and <em>B</em> differ on their drift rates (<code>[1.5, 0.5]</code> vs. <code>[2.5, 1.5]</code>). In other words, the <em>effect</em> of condition <em>B</em> over condition <em>A</em> (the baseline condition, i.e., the <em>intercept</em>) is <code>[1, 1]</code> (because both drift rates increase by 1 between condition <em>A</em> and <em>B</em>).</p><h2 id="Exclude-Outliers"><a class="docs-heading-anchor" href="#Exclude-Outliers">Exclude Outliers</a><a id="Exclude-Outliers-1"></a><a class="docs-heading-anchor-permalink" href="#Exclude-Outliers" title="Permalink"></a></h2><p>Next, we are going to remove outliers, i.e., implausible RTs (RTs that likely do not reflect the processes of interest). In our case, we consider that RTs shorter than 0.2 seconds are too short for the cognitive process of interest to unfold, and that RTs longer than 3 seconds are too long to carry meaningful information.</p><pre><code class="language-julia hljs"># Remove outliers
df = df[(df.rt .&gt; 0.2).&amp;(df.rt .&lt; 3), :]
first(df)</code></pre><div><div style = "float: left;"><span>DataFrameRow (3 columns)</span></div><div style = "clear: both;"></div></div><div class = "data-frame" style = "overflow-x: scroll;"><table class = "data-frame" style = "margin-bottom: 6px;"><thead><tr class = "header"><th class = "rowLabel" style = "font-weight: bold; text-align: right;">Row</th><th style = "text-align: left;">choice</th><th style = "text-align: left;">rt</th><th style = "text-align: left;">condition</th></tr><tr class = "subheader headerLastRow"><th class = "rowLabel" style = "font-weight: bold; text-align: right;"></th><th title = "Int64" style = "text-align: left;">Int64</th><th title = "Float64" style = "text-align: left;">Float64</th><th title = "String" style = "text-align: left;">String</th></tr></thead><tbody><tr><td class = "rowLabel" style = "font-weight: bold; text-align: right;">1</td><td style = "text-align: right;">2</td><td style = "text-align: right;">2.00801</td><td style = "text-align: left;">A</td></tr></tbody></table></div><p>Note that standard outlier detection methods, such as <em>z</em>-scores (mean +- SD), are not necessarily appropriate for RTs, given the skewed nature of their distribution. Their asymmetric distribution is in fact accounted for by the models that we use. The outlier exclusion done here is more theory-driven (i.e., excluding extreme trials that likely do not reflect well the cognitive processes of interest) than data-driven (to better fit the model). That said, outlier exclusion should always be explicitly documented and justified.</p><div class="admonition is-info" id="Note-cc2f91bd753b3bda"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-cc2f91bd753b3bda" title="Permalink"></a></header><div class="admonition-body"><p>For users coming from other languages, note the usage of the <a href="https://julialang.org/blog/2017/01/moredots/">vectorization dot</a> <code>.</code> in front of the <code>&lt;</code> and <code>&gt;</code> symbols. This means that we want to apply the logical test for all individual elements of the <code>rt</code> vector.</p></div></div><h2 id="Visualize-Data"><a class="docs-heading-anchor" href="#Visualize-Data">Visualize Data</a><a id="Visualize-Data-1"></a><a class="docs-heading-anchor-permalink" href="#Visualize-Data" title="Permalink"></a></h2><p>We can visualize the RT distribution for each response choice by looping through the conditions.</p><pre><code class="language-julia hljs"># Make histogram
histogram(layout=(2, 1), xlabel=&quot;Reaction Time&quot;, ylims=(0, 60), xlims=(0, 2), legend=false)
for (i, cond) in enumerate([&quot;A&quot;, &quot;B&quot;])
    histogram!(df.rt[(df.choice.==1).&amp;(df.condition.==cond)], subplot=1, color=[:blue, :red][i], alpha=0.5, bins=range(0, 3, length=25))
    histogram!(df.rt[(df.choice.==2).&amp;(df.condition.==cond)], subplot=2, color=[:blue, :red][i], alpha=0.5, bins=range(0, 2, length=25))
end
plot!()</code></pre><img src="2bb61476.svg" alt="Example block output"/><h2 id="Format-Predictors"><a class="docs-heading-anchor" href="#Format-Predictors">Format Predictors</a><a id="Format-Predictors-1"></a><a class="docs-heading-anchor-permalink" href="#Format-Predictors" title="Permalink"></a></h2><p>One additional step that we need to do here is to transform the dataframe into an input suited for modelling with Turing. For that, we will leverage the features of <code>StatsModels</code> to build an input matrix based on a formula.</p><pre><code class="language-julia hljs"># Format input data
f = @formula(rt ~ 1 + condition)
f = apply_schema(f, schema(f, df))

_, predictors = coefnames(f)
X = modelmatrix(f, df)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">100×2 Matrix{Float64}:
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 1.0  0.0
 ⋮    
 1.0  1.0
 1.0  1.0
 1.0  1.0
 1.0  1.0
 1.0  1.0
 1.0  1.0
 1.0  1.0
 1.0  1.0
 1.0  1.0</code></pre><p>In this case, the model matrix is pretty simple: the key part is the second column that is simply a binary vector indicating whenever <code>condition == &quot;B&quot;</code>. However, using formulas is a good way of dealing with more complex model specifications.</p><h2 id="Specify-Turing-Model"><a class="docs-heading-anchor" href="#Specify-Turing-Model">Specify Turing Model</a><a id="Specify-Turing-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Specify-Turing-Model" title="Permalink"></a></h2><p>In this model, the priors for the parameters that we want to vary between conditions are split, with one prior for their intercept (condition A) and another for the effect of condition B (relative to the intercept).</p><p>Because the <em>drift</em> parameters is a vector of length 2, the priors for both the intercept and condition effect drifts have themselves to be a vector of 2 distributions, which is done via <code>filldist(prior_distribution, 2)</code>.</p><p>Next, we need to specify these parameters as the result of a (linear) equation. Note that:</p><ul><li>We have added a keyword argument, <code>condition</code>, to let the user pass the condition data vector.</li><li>Since we&#39;re computing parameters as the results of an equation, we need to use a <code>for</code> loop that loops through all the observations.</li><li>Because the priors for the drift is a <code>filldist</code> (i.e., a vector of distributions), we need to broadcast the addition (<code>.+</code> instead of <code>+</code>).</li></ul><pre><code class="language-julia hljs">@model function model_lba(data; min_rt=0.2, condition=nothing)
    # Priors for auxiliary parameters
    A ~ truncated(Normal(0.8, 0.4), 0.0, Inf)
    k ~ truncated(Normal(0.2, 0.2), 0.0, Inf)
    tau ~ Uniform(0.0, min_rt)

    # Priors for coefficients
    drift_intercept ~ filldist(Normal(0, 1), 2)
    drift_condition ~ filldist(Normal(0, 1), 2)

    for i in 1:length(data)
        drifts = drift_intercept .+ drift_condition * condition[i]
        data[i] ~ LBA(; τ=tau, A=A, k=k, ν=drifts)
    end
end</code></pre><p>Importantly, although we have the data as a dataframe, we will need to convert to a tuple, as it is the shape that the <code>LBA()</code> distribution expects. However, since we&#39;re iterating on each observation, we need to come up with an indexable version of the data: a <strong>vector of tuples</strong>.</p><pre><code class="language-julia hljs"># Format the data to match the input type
data = [(choice=df.choice[i], rt=df.rt[i]) for i in 1:nrow(df)]</code></pre><h2 id="Prior-Predictive-Check"><a class="docs-heading-anchor" href="#Prior-Predictive-Check">Prior Predictive Check</a><a id="Prior-Predictive-Check-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Predictive-Check" title="Permalink"></a></h2><h3 id="Sample-from-Priors"><a class="docs-heading-anchor" href="#Sample-from-Priors">Sample from Priors</a><a id="Sample-from-Priors-1"></a><a class="docs-heading-anchor-permalink" href="#Sample-from-Priors" title="Permalink"></a></h3><p>Before we fit the model, we want to inspect our priors to make sure that they are okay. To do that, we sample the model parameters from priors only. Note that <code>condition</code> is supplied as the 2nd column of the model matrix.</p><pre><code class="language-julia hljs">chain = sample(model_lba(data; min_rt=minimum(df.rt), condition=X[:, 2]), Prior(), 1000)
plot(chain; size=(800, 1200))</code></pre><h3 id="Plot-Prior-Predictive-Check"><a class="docs-heading-anchor" href="#Plot-Prior-Predictive-Check">Plot Prior Predictive Check</a><a id="Plot-Prior-Predictive-Check-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-Prior-Predictive-Check" title="Permalink"></a></h3><p>The next step is to generate predictions from this model (i.e., from the priors). For this, we need to pass a dataset with empty (<code>missing</code>) values. Since the <code>data</code> used above was a vector (of tuples) of length 1000, we will create a vector of <code>(missing)</code> of the same length.</p><p>We can then use the <code>predict()</code> method to generate predictions from this model. However, because the most of <code>SequentialSamplingModels</code> distributions return a tuple (choice and RT), the predicted output has the two types of variables mixed together. We can delineate the two by taking every 2nd values to get the predicted choice and RTs, respectively.</p><pre><code class="language-julia hljs">datamissing = [(missing) for i in 1:nrow(df)]

pred = predict(model_lba(datamissing; min_rt=minimum(df.rt), condition=X[:, 2]), chain)

priorpred_choice = Array(pred)[:, 1:2:end]
priorpred_rt = Array(pred)[:, 2:2:end]</code></pre><p>These objects have arrays of size 10,000 x 1000 : with 10,000 draws for each of the 1000 observations.</p><p>We can plot the predicted distributions by looping through a number of draws (e.g., 100), and then plotting the density for each condition and each choice.</p><pre><code class="language-julia hljs">plot(layout=(2, 1), xlabel=&quot;Reaction Time&quot;, xlims = (0, 3), ylim=(0, 5), legend = false)
for i in 1:100
    choice = priorpred_choice[i, :]
    rt = priorpred_rt[i, :]
    for (j, cond) in enumerate([0, 1])
        U1 = kde(rt[(choice .== 1) .&amp; (X[:, 2] .== cond)], boundary=(0, 5))
        plot!(U1.x, U1.density, subplot=1, color = [:red, :blue][j], alpha=0.1)
        U2 = kde(rt[(choice .== 2) .&amp; (X[:, 2] .== cond)], boundary=(0, 5))
        plot!(U2.x, U2.density, subplot=2, color = [:red, :blue][j], alpha=0.1)
    end
end
plot!()</code></pre><p>We can see that the bulk of the predicted RTs fall within 0 - 1.5 seconds, which is realistic, but that the same time it&#39;s all over the place, which means that the priors are not too informative.</p><h2 id="Parameters-Estimation"><a class="docs-heading-anchor" href="#Parameters-Estimation">Parameters Estimation</a><a id="Parameters-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Parameters-Estimation" title="Permalink"></a></h2><pre><code class="language-julia hljs">chain = sample(model_lba(data; min_rt=minimum(df.rt), condition=X[:, 2]), NUTS(), 1000)

summarystats(chain)</code></pre><pre><code class="language-julia hljs">plot(chain; size = (800,1200))</code></pre><h2 id="Posterior-Predictive-Check"><a class="docs-heading-anchor" href="#Posterior-Predictive-Check">Posterior Predictive Check</a><a id="Posterior-Predictive-Check-1"></a><a class="docs-heading-anchor-permalink" href="#Posterior-Predictive-Check" title="Permalink"></a></h2><p>Next, we will run a posterior predictive check by first sampling from the posteriors. For that, we will re-use the code for the prior predictive check, including the <code>datamissing</code> empty data.</p><pre><code class="language-julia hljs"># Sample from posteriors
pred = predict(model_lba(datamissing; min_rt=minimum(df.rt), condition=X[:, 2]), chain)
pred_choice = Array(pred)[:, 1:2:end]
pred_rt = Array(pred)[:, 2:2:end]</code></pre><p>Next, we will plot the predicted distributions on top of the observed distribution of data (the thick black lines).</p><pre><code class="language-julia hljs"># Observed density
plot(layout=(2, 1), xlabel=&quot;Reaction Time&quot;, xlims=(0, 2.5), legend=false)
for cond in [&quot;A&quot;, &quot;B&quot;]
    d_A = kde(df.rt[(df.choice.==1).&amp;(df.condition.==cond)], boundary=(0, 5))
    plot!(d_A.x, d_A.density, subplot=1, color=:black, linewidth=3)
    d_B = kde(df.rt[(df.choice.==2).&amp;(df.condition.==cond)], boundary=(0, 5))
    plot!(d_B.x, d_B.density, subplot=2, color=:black, linewidth=3)
end

# Predicted densities
for i in 1:100
    choice = pred_choice[i, :]
    rt = pred_rt[i, :]
    for (j, cond) in enumerate([0, 1])
        U1 = kde(rt[(choice.==1).&amp;(X[:, 2].==cond)], boundary=(0, 5))
        plot!(U1.x, U1.density, subplot=1, color=[:red, :blue][j], alpha=0.05)
        U2 = kde(rt[(choice.==2).&amp;(X[:, 2].==cond)], boundary=(0, 5))
        plot!(U2.x, U2.density, subplot=2, color=[:red, :blue][j], alpha=0.05)
    end
end
plot!()</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../turing_simple/">« Simple Bayesian Model</a><a class="docs-footer-nextpage" href="../turing_hierarchical/">Hierarchical Models »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Thursday 31 July 2025 23:20">Thursday 31 July 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
